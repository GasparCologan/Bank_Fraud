{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c189c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.stats as ss\n",
    "import sklearn\n",
    "import category_encoders as ce\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier)\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, roc_auc_score, \n",
    "                             ConfusionMatrixDisplay, auc, silhouette_score, recall_score, precision_score, \n",
    "                             make_scorer, fbeta_score, f1_score, precision_recall_curve, accuracy_score)\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c850c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = pd.read_csv(\"../data/Base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e351ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede meter pipeline aquí\n",
    "X_train0 = pd.read_csv(\"../data/X_train0.csv\")\n",
    "X_train0 = X_train0.drop('Unnamed: 0', axis=1)\n",
    "X_train1 = pd.read_csv(\"../data/X_train1.csv\")\n",
    "X_train1 = X_train1.drop('Unnamed: 0', axis=1)\n",
    "X_val = pd.read_csv(\"../data/X_validacion.csv\")\n",
    "X_val = X_val.drop('Unnamed: 0', axis=1)\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "y_train0 = pd.read_csv(\"../data/y_train0.csv\")\n",
    "y_train0 = y_train0.drop('Unnamed: 0', axis=1)\n",
    "y_train1 = pd.read_csv(\"../data/y_train1.csv\")\n",
    "y_train1 = y_train1.drop('Unnamed: 0', axis=1)\n",
    "y_val = pd.read_csv(\"../data/y_validacion.csv\")\n",
    "y_val = y_val.drop('Unnamed: 0', axis=1)\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\")\n",
    "y_test = y_test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d746c1",
   "metadata": {},
   "source": [
    "## Selección de threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467bf9f9",
   "metadata": {},
   "source": [
    "Elegimos el threshold óptimo para maximizar el F2 score, es decir, el Fscore con beta igual a dos, para cada modelo. De esta forma, damos prioridad a la exhaustividad, ya que en este problema es preferible dar un falso positivo que un falso positivo, porque lo importante es detectar la mayor cantidad posible de fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3e4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:382: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6683, number of negative: 33415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 40098, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB:\n",
      "   Mejor F2-score: 0.206\n",
      "   Mejor Threshold: 0.990\n",
      "\n",
      "LogisticRegression:\n",
      "   Mejor F2-score: 0.260\n",
      "   Mejor Threshold: 0.525\n",
      "\n",
      "XGBClassifier:\n",
      "   Mejor F2-score: 0.288\n",
      "   Mejor Threshold: 0.535\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "   Mejor F2-score: 0.146\n",
      "   Mejor Threshold: 0.000\n",
      "\n",
      "RandomForestClassifier:\n",
      "   Mejor F2-score: 0.279\n",
      "   Mejor Threshold: 0.485\n",
      "\n",
      "AdaBoostClassifier:\n",
      "   Mejor F2-score: 0.263\n",
      "   Mejor Threshold: 0.505\n",
      "\n",
      "GradientBoostingClassifier:\n",
      "   Mejor F2-score: 0.302\n",
      "   Mejor Threshold: 0.495\n",
      "\n",
      "LGBMClassifier:\n",
      "   Mejor F2-score: 0.302\n",
      "   Mejor Threshold: 0.545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya tienes tus datos de entrenamiento y validación: X_train, X_val, y_train, y_val\n",
    "\n",
    "# Define your thresholds\n",
    "thresholds = np.linspace(0, 1, 100)  # You can adjust the range and number of thresholds\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "# Inicializa una lista para almacenar los resultados de F2-score y thresholds\n",
    "f2_scores = []\n",
    "beta = 2  # Puedes ajustar este valor según tus preferencias\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    \n",
    "    # Crea un pipeline con el clasificador\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Obtén las probabilidades de las clases\n",
    "    y_prob = pipe.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Inicializa listas para almacenar los resultados de F2-score para cada threshold\n",
    "    f2_scores_classifier = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Aplica el threshold a las predicciones\n",
    "        y_pred = (y_prob > threshold).astype(int)\n",
    "        \n",
    "        # Calcula el F2-score\n",
    "        f2 = fbeta_score(y_val, y_pred, beta=beta)\n",
    "        f2_scores_classifier.append(f2)\n",
    "    \n",
    "    # Encuentra el mejor F2-score y su correspondiente threshold\n",
    "    best_f2_score = max(f2_scores_classifier)\n",
    "    best_threshold = thresholds[f2_scores_classifier.index(best_f2_score)]\n",
    "    \n",
    "    # Almacena los resultados\n",
    "    f2_scores.append({\n",
    "        'classifier': classifier_name,\n",
    "        'best_f2_score': best_f2_score,\n",
    "        'best_threshold': best_threshold\n",
    "    })\n",
    "\n",
    "    # Grafica la curva de precision-recall\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_prob)\n",
    "    plt.plot(recall, precision, label=classifier_name)\n",
    "\n",
    "# Muestra la leyenda y etiquetas del gráfico\n",
    "plt.legend()\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall para Diferentes Clasificadores')\n",
    "plt.show()\n",
    "\n",
    "# Muestra el mejor F2-score y threshold para cada clasificador\n",
    "for result in f2_scores:\n",
    "    print(f\"{result['classifier']}:\")\n",
    "    print(f\"   Mejor F2-score: {result['best_f2_score']:.3f}\")\n",
    "    print(f\"   Mejor Threshold: {result['best_threshold']:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb3677",
   "metadata": {},
   "source": [
    "Nos quedamos con el Threshold de 0.525 porque es el que mejor métrica nos da utilizando el LGBM Clasiffier. Con ese threshold, pasamos a comparar todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c755d29b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "Model Score: 0.840\n",
      "F-2 Score: 0.170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.91    197860\n",
      "           1       0.04      0.64      0.08      2140\n",
      "\n",
      "    accuracy                           0.84    200000\n",
      "   macro avg       0.52      0.74      0.50    200000\n",
      "weighted avg       0.99      0.84      0.91    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Model Score: 0.957\n",
      "F-2 Score: 0.260\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.11      0.38      0.18      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.55      0.68      0.58    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model Score: 0.948\n",
      "F-2 Score: 0.287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    197860\n",
      "           1       0.11      0.49      0.18      2140\n",
      "\n",
      "    accuracy                           0.95    200000\n",
      "   macro avg       0.55      0.72      0.58    200000\n",
      "weighted avg       0.98      0.95      0.97    200000\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model Score: 0.874\n",
      "F-2 Score: 0.143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    197860\n",
      "           1       0.04      0.45      0.07      2140\n",
      "\n",
      "    accuracy                           0.87    200000\n",
      "   macro avg       0.52      0.66      0.50    200000\n",
      "weighted avg       0.98      0.87      0.92    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:382: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Model Score: 0.964\n",
      "F-2 Score: 0.271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.13      0.37      0.20      2140\n",
      "\n",
      "    accuracy                           0.97    200000\n",
      "   macro avg       0.56      0.67      0.59    200000\n",
      "weighted avg       0.98      0.97      0.98    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "Model Score: 0.954\n",
      "F-2 Score: 0.004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    197860\n",
      "           1       0.75      0.00      0.01      2140\n",
      "\n",
      "    accuracy                           0.99    200000\n",
      "   macro avg       0.87      0.50      0.50    200000\n",
      "weighted avg       0.99      0.99      0.98    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Model Score: 0.961\n",
      "F-2 Score: 0.299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.14      0.43      0.21      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.56      0.70      0.59    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 6683, number of negative: 33415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 40098, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "Model Score: 0.954\n",
      "F-2 Score: 0.300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    197860\n",
      "           1       0.12      0.47      0.20      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.56      0.72      0.59    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "beta = 2\n",
    "threshold = 0.525  # Nuevo umbral\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Obtener las probabilidades de las clases\n",
    "    y_prob = pipe.predict_proba(X_val)\n",
    "    \n",
    "    # Aplicar el nuevo umbral a las predicciones\n",
    "    y_pred = (y_prob[:, 1] > threshold).astype(int)\n",
    "    \n",
    "    # Calcula el model score\n",
    "    model_score = pipe.score(X_val, y_val)\n",
    "    \n",
    "    # Calcular f-beta score\n",
    "    f_beta = fbeta_score(y_val, y_pred, beta=beta)\n",
    "\n",
    "    \n",
    "    print(f\"{classifier.__class__.__name__}\")\n",
    "    print(f\"Model Score: {model_score:.3f}\")\n",
    "    print(f\"F-{beta} Score: {f_beta:.3f}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13496dff",
   "metadata": {},
   "source": [
    "## Hacemos undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6647737",
   "metadata": {},
   "source": [
    "Una vez confirmado que elegimos el model LGBM, volvemos al train0 para renombrarlos como train2 haciendo un undersampling del total de la muestra. Ahora elegimos cual la mejor estrategia de remuestreo para entrenar el modelo. Lo hacemos mediante validación cruzada de x_train0 e y_train0, los cuales, una vez tengamos el valor elegido, serán balanceados de tal forma que los pasaremos a x_train2 e y_train2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc4f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_train0, y_train0, test_size=0.2, stratify=y_train0, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e539513c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.05 - F2 Score on Validation Set: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.10 - F2 Score on Validation Set: 0.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.15 - F2 Score on Validation Set: 0.2729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.20 - F2 Score on Validation Set: 0.2815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.25 - F2 Score on Validation Set: 0.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.30 - F2 Score on Validation Set: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.35 - F2 Score on Validation Set: 0.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.40 - F2 Score on Validation Set: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.45 - F2 Score on Validation Set: 0.2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.50 - F2 Score on Validation Set: 0.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.55 - F2 Score on Validation Set: 0.2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.60 - F2 Score on Validation Set: 0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.65 - F2 Score on Validation Set: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.70 - F2 Score on Validation Set: 0.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.75 - F2 Score on Validation Set: 0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.80 - F2 Score on Validation Set: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.85 - F2 Score on Validation Set: 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.90 - F2 Score on Validation Set: 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\AppData\\Local\\Temp\\ipykernel_4800\\2113754859.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.95 - F2 Score on Validation Set: 0.1748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Supongamos que X_train3 es tu conjunto de entrenamiento y X_val es tu conjunto de validación\n",
    "\n",
    "# 1. Divide el conjunto de entrenamiento en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define las tasas de undersampling que deseas probar (de 0.05 en 0.05)\n",
    "undersampling_rates = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# 3. Itera sobre las tasas de undersampling\n",
    "for rate in undersampling_rates:\n",
    "    # 4. Aplica RandomUnderSampler con la tasa actual\n",
    "    rus = RandomUnderSampler(sampling_strategy=rate, random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 5. Entrena un clasificador (por ejemplo, RandomForest) con los datos undersampled\n",
    "    clf = RandomForestClassifier(random_state=69)\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 6. Realiza predicciones en el conjunto de validación\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # 7. Calcula y muestra el F2-score\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "    print(f\"Undersampling Rate: {rate:.2f} - F2 Score on Validation Set: {f2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ef158",
   "metadata": {},
   "source": [
    "El F2-Score más alto nos da en 0.2. Para ser más exhaustivos, comprobamos yendo de 0.01 en 0.01 (en vez de de 0.1 en 0.1), para buscar el remuestreo óptimo que maximice esta métrica. Aquí veremos que este es 0.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3896c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 71100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 78210, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.090909 -> initscore=-2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "Undersampling Rate: 0.100 - F2 Score on Validation Set: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 64636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 71746, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099100 -> initscore=-2.207269\n",
      "[LightGBM] [Info] Start training from score -2.207269\n",
      "Undersampling Rate: 0.110 - F2 Score on Validation Set: 0.2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 59250\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 66360, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "Undersampling Rate: 0.120 - F2 Score on Validation Set: 0.2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 54692\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 61802, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115045 -> initscore=-2.040215\n",
      "[LightGBM] [Info] Start training from score -2.040215\n",
      "Undersampling Rate: 0.130 - F2 Score on Validation Set: 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 50785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 57895, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122809 -> initscore=-1.966099\n",
      "[LightGBM] [Info] Start training from score -1.966099\n",
      "Undersampling Rate: 0.140 - F2 Score on Validation Set: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 47400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 54510, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.130435 -> initscore=-1.897120\n",
      "[LightGBM] [Info] Start training from score -1.897120\n",
      "Undersampling Rate: 0.150 - F2 Score on Validation Set: 0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 44437\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 51547, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137932 -> initscore=-1.832570\n",
      "[LightGBM] [Info] Start training from score -1.832570\n",
      "Undersampling Rate: 0.160 - F2 Score on Validation Set: 0.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 41823\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 48933, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.145301 -> initscore=-1.771944\n",
      "[LightGBM] [Info] Start training from score -1.771944\n",
      "Undersampling Rate: 0.170 - F2 Score on Validation Set: 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 39500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 46610, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152542 -> initscore=-1.714798\n",
      "[LightGBM] [Info] Start training from score -1.714798\n",
      "Undersampling Rate: 0.180 - F2 Score on Validation Set: 0.2991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 37421\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 44531, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.159664 -> initscore=-1.660730\n",
      "[LightGBM] [Info] Start training from score -1.660730\n",
      "Undersampling Rate: 0.190 - F2 Score on Validation Set: 0.2935\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Divide el conjunto de entrenamiento en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define las tasas de undersampling que deseas probar (de 0.001 en 0.001 entre 0.1 y 0.2)\n",
    "undersampling_rates = np.arange(0.10, 0.20, 0.01)\n",
    "\n",
    "# Almacena los resultados\n",
    "undersampling_results = []\n",
    "f2_scores = []\n",
    "\n",
    "# 3. Itera sobre las tasas de undersampling\n",
    "for rate in undersampling_rates:\n",
    "    # 4. Aplica RandomUnderSampler con la tasa actual\n",
    "    rus = RandomUnderSampler(sampling_strategy=rate, random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 5. Entrena un clasificador (por ejemplo, LGBMClassifier) con los datos undersampled\n",
    "    clf = LGBMClassifier(random_state=69)\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 6. Realiza predicciones en el conjunto de validación\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # 7. Calcula y almacena el F2-score\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "    undersampling_results.append(rate)\n",
    "    f2_scores.append(f2)\n",
    "    print(f\"Undersampling Rate: {rate:.3f} - F2 Score on Validation Set: {f2:.4f}\")\n",
    "\n",
    "# Grafica los resultados\n",
    "plt.plot(undersampling_results, f2_scores, marker='o')\n",
    "plt.xlabel('Undersampling Rate')\n",
    "plt.ylabel('F2 Score on Validation Set')\n",
    "plt.title('Undersampling Rate vs F2 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb4913",
   "metadata": {},
   "source": [
    "Hacemos undersampling con 0.16 como estrategia de remuestreo. De esta forma, optimizamos el F2-Score, que es la métrica en la que estamos fijando nuestra atención. Como hemos comprobado a la hora de elaborar el modelo, cuanto mayor sea el sampling strategy a partir de 0.16, a pesar de que la F2-Score decrece, la captación de verdaderos positivos aumenta. Pero como la investigación de cada caso también tiene un coste y, utilizando la métrica F2Score ya estamos priorizando el recall sobre la precisión, decidimos quedarnos aquí. De otra forma, la cantidad de falsos positivos sería muy grande en comparación con los verdaderos positivos que recogeríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e899902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes del undersampling - X_train: (40098, 40) y_train: (40098, 1)\n",
      "Después del undersampling - X_train_resampled: (63966, 40) y_train_resampled: (63966, 1)\n"
     ]
    }
   ],
   "source": [
    "# Para reducir tiempos de computación a la hora de ejecutar un problema con un millón de instancias, y para elegir el modelo\n",
    "# a utilizar, realizamos undersampling. Ahora el dataset se nos queda en un 60% de entrenamiento que estará rebalanceado,\n",
    "# y una validación y test que permanecen vírgenes.\n",
    "# Siempre utilizamos el mismo random_state para los splits\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Definir el undersampler con la proporción deseada\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.16, random_state=69)\n",
    "\n",
    "# Aplicar undersampling a X_train e y_train\n",
    "X_train2, y_train2 = undersampler.fit_resample(X_train0, y_train0)\n",
    "\n",
    "# Ver las formas antes y después del undersampling\n",
    "print(\"Antes del undersampling - X_train:\", X_train1.shape, \"y_train:\", y_train1.shape)\n",
    "print(\"Después del undersampling - X_train_resampled:\", X_train2.shape, \"y_train_resampled:\", y_train2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0a804",
   "metadata": {},
   "source": [
    "## Buscamos hiperparámetros con LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef2fd6",
   "metadata": {},
   "source": [
    "A la hora de buscar los hiperparámetros, como scorer objetivo hemos elegido que se maximice el f2score, lo que hará que el modelo optimice esta métrica, que es especialmente sensible con la búsqueda de positivos en detrimento de la búsqueda de negativos y de evitar falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515c02d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3761\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3762\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gaspi\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8823, number of negative: 55143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3763\n",
      "[LightGBM] [Info] Number of data points in the train set: 63966, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "F2-score en datos de prueba: 0.313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197794\n",
      "           1       0.14      0.46      0.21      2206\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.57      0.71      0.60    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo LGBMClassifier\n",
    "lgbm_model = LGBMClassifier(random_state=69)\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Definir la métrica a optimizar (F2-score)\n",
    "scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, scoring=scorer, cv=3)\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Imprimir el F2-score del mejor modelo en los datos de entrenamiento\n",
    "y_pred = best_lgbm_model.predict(X_test)\n",
    "f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"F2-score en datos de prueba: {f2_score:.3f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b871b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = best_lgbm_model.predict_proba(X_test)\n",
    "y_pred_prob = y_pred_prob[:,1] #para transformarlo en un array de 1d y que lo coja el predictor de la curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add24c9",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee390a5",
   "metadata": {},
   "source": [
    "#### Accuracy del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27e0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6d6da",
   "metadata": {},
   "source": [
    "El modelo acierta en 96 de cada 100 casos. Esta métrica no mejora la del modelo base (que al haber un 99,1% de negativos, en el caso de que se den todos los casos como negativos, se tendría un 99,1% de acierto). Sin embargo, no es relevante porque es mucho más importante detectar un verdadero positivo que un verdadero negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443e530",
   "metadata": {},
   "source": [
    "#### Curva ROC y AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a9de0",
   "metadata": {},
   "source": [
    "La curva ROC nos indica el número de verdaderos positivos que vamos a tener y el coste que tiene esto en falsos positivos. El punto deseado se debería encontrar moderadamente más arriba del punto álgido de la curva, ya que así priorizaríamos predecir más verdaderos, que es lo interesante. Además, el area bajo la curva es de 0.895, lo cual, según las fuentes consultadas, es una buena métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc832e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prob = [0 for _ in range(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a37e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.8926420498790691\n"
     ]
    }
   ],
   "source": [
    "r_auc = roc_auc_score(y_test, t_prob)\n",
    "print(r_auc)\n",
    "\n",
    "f_auc_prob = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f_auc_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6d84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_r_auc, tpr_r_auc, _ = roc_curve(y_test, t_prob)\n",
    "fpr_f_auc_prob, tpr_f_auc_prob, _ = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5b0f01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_f_auc_prob, tpr_f_auc_prob, linestyle='-', label='prediction prob (AUROC = %0.2f)' % f_auc_prob)\n",
    "\n",
    "plt.plot(fpr_r_auc, tpr_r_auc, linestyle='--', label='base prob (AUROC = %0.2f)' % r_auc)\n",
    "\n",
    "\n",
    "\n",
    "#Title\n",
    "plt.title('ROC Plot')\n",
    "\n",
    "#Axis labels\n",
    "plt.xlabel('False Positive Rates')\n",
    "plt.ylabel('True Positive Rates')\n",
    "\n",
    "#Show legend\n",
    "plt.legend()\n",
    "\n",
    "#Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509919c9",
   "metadata": {},
   "source": [
    "#### Curva de ganancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72909fe",
   "metadata": {},
   "source": [
    "Al ser un dataset tan desbalanceado es muy probable que la curva de ganancia esté alejada de la diagonal (si solo hubiera un positivo, muy probablemente con examinar el 1% de instancias con más probabilidad de haber cometido fraude ya habríamos conseguido detectar el 100% de los positivos). En este caso, examinando 20% de los casos más probables, detectaríamos más del 80% de los fraudes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0b342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "#Probabilidad de que froud_bool=1\n",
    "y_pred_prob=best_lgbm_model.predict_proba(X_test) #lo vuelvo a ejecutar porque aquí hay que tener el array completo, en 2D, no como para la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38975aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_cumulative_gain(y_test, y_pred_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53f261",
   "metadata": {},
   "source": [
    "#### Curva Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c49bb",
   "metadata": {},
   "source": [
    "Para la detección del fraude, el modelo mejora cuantiosamente lo que obtendríamos intentando encontrar aleatoriamente fraude.\n",
    "En el caso de Fraud Bool positivo, la mayoría se cogen entre 85 y 90 veces mejor con el modelo que de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcbc3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test, y_pred_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5d1a0",
   "metadata": {},
   "source": [
    "### Curvas de precisión-sensitividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711232cf",
   "metadata": {},
   "source": [
    "#### F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6a1d8",
   "metadata": {},
   "source": [
    "Con el F-Score encontramos la precisión y la sensitividad del modelo. En el caso del F1-Score pondera ambas por igual (es decir, es tan grave errar en un falso positivo como en un falso negativo. Sin embargo, como en este problema lo que intentamos es detectar los positivos principalmente, creemos que la sensitividad o recall es mucho más importante que la precisión. Por tanto, hemos hecho un F2-Score, que ha sido la métrica que hemos intentado optimizar en todo momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f668b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21230347156273086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed321afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125194159676918"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_test, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcb908",
   "metadata": {},
   "source": [
    "#### Matriz de confusión absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503dd44",
   "metadata": {},
   "source": [
    "De 200.000 instancias que tiene la parte de Test, hemos predicho 7.113 positivos. Con esa predicción hemos evitado un 46% del total de fraudes (1.016). Hay numerosos puntos del dataset en los que podíamos haber cambiado parámetros para detectar más de un 46% del fraude, pero ello hubiera supuesto un coste enorme de falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6652f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_pred_LGBM = best_lgbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1189344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[191529,   6265],\n",
       "       [  1200,   1006]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = confusion_matrix(y_test, y_pred_LGBM)#, labels=valores_unicos)\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3136c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_display = ConfusionMatrixDisplay(confusion_matrix=mc, display_labels = ['no fraude', 'fraude']) #display_labels debe ir en el orden en el que van valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2369415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2c12983bbd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee17eb",
   "metadata": {},
   "source": [
    "#### Matriz de confusión relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a63c0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = confusion_matrix(y_test, y_pred_LGBM)\n",
    "mc_rel = mc / mc.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ef21aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2c129784a50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc_rel = mc / mc.sum(axis=1)[:, np.newaxis]\n",
    "mc_rel_display = ConfusionMatrixDisplay(confusion_matrix=mc_rel, display_labels = ['no fraude', 'fraude'])\n",
    "mc_rel_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b24a8",
   "metadata": {},
   "source": [
    "## Explicabilidad: SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1703a0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align='center'><img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAdxJREFUeNq0Vt1Rg0AQJjcpgBJiBWIFkgoMFYhPPAIVECogPuYpdJBYgXQQrMCUkA50V7+d2ZwXuXPGm9khHLu3f9+3l1nkWNvtNqfHLgpfQ1EUS3tz5nAQ0+NIsiAZSc6eDlI8M3J00B/mDuUKDk6kfOebAgW3pkdD0pFcODGW4gKKvOrAUm04MA4QDt1OEIXU9hDigfS5rC1eS5T90gltck1Xrizo257kgySZcNRzgCSxCvgiE9nckPJo2b/B2AcEkk2OwL8bD8gmOKR1GPbaCUqxEgTq0tLvgb6zfo7+DgYGkkWL2tqLDV4RSITfbHPPfJKIrWz4nJQTMPAWA7IbD6imcNaDeDfgk+4No+wZr40BL3g9eQJJCFqRQ54KiSt72lsLpE3o3MCBSxDuq4yOckU2hKXRuwBH3OyMR4g1UpyTYw6mlmBqNdUXRM1NfyF5EPI6JkcpIDBIX8jX6DR/6ckAZJ0wEAdLR8DEk6OfC1Pp8BKo6TQIwPJbvJ6toK5lmuvJoRtfK6Ym1iRYIarRo2UyYHvRN5qpakR3yoizWrouoyuXXQqI185LCw07op5ZyCRGL99h24InP0e9xdQukEKVmhzrqZuRIfwISB//cP3Wk3f8f/yR+BRgAHu00HjLcEQBAAAAAElFTkSuQmCC' /></div><script charset='utf-8'>/*! For license information please see bundle.js.LICENSE.txt */\n",
       "(()=>{var e={486:function(e,t,n){var r;e=n.nmd(e),function(){var a,i=\"Expected a function\",o=\"__lodash_hash_undefined__\",u=\"__lodash_placeholder__\",l=32,s=128,c=1/0,f=9007199254740991,p=NaN,d=4294967295,h=[[\"ary\",s],[\"bind\",1],[\"bindKey\",2],[\"curry\",8],[\"curryRight\",16],[\"flip\",512],[\"partial\",l],[\"partialRight\",64],[\"rearg\",256]],v=\"[object Arguments]\",g=\"[object Array]\",y=\"[object Boolean]\",m=\"[object Date]\",b=\"[object Error]\",_=\"[object Function]\",w=\"[object GeneratorFunction]\",x=\"[object Map]\",k=\"[object Number]\",S=\"[object Object]\",E=\"[object Promise]\",C=\"[object RegExp]\",T=\"[object Set]\",M=\"[object String]\",N=\"[object Symbol]\",P=\"[object WeakMap]\",z=\"[object ArrayBuffer]\",L=\"[object DataView]\",O=\"[object Float32Array]\",A=\"[object Float64Array]\",F=\"[object Int8Array]\",D=\"[object Int16Array]\",R=\"[object Int32Array]\",j=\"[object Uint8Array]\",U=\"[object Uint8ClampedArray]\",I=\"[object Uint16Array]\",$=\"[object Uint32Array]\",B=/\\b__p \\+= '';/g,W=/\\b(__p \\+=) '' \\+/g,V=/(__e\\(.*?\\)|\\b__t\\)) \\+\\n'';/g,H=/&(?:amp|lt|gt|quot|#39);/g,q=/[&<>\"']/g,Q=RegExp(H.source),Y=RegExp(q.source),G=/<%-([\\s\\S]+?)%>/g,K=/<%([\\s\\S]+?)%>/g,Z=/<%=([\\s\\S]+?)%>/g,X=/\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,J=/^\\w*$/,ee=/[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g,te=/[\\\\^$.*+?()[\\]{}|]/g,ne=RegExp(te.source),re=/^\\s+/,ae=/\\s/,ie=/\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/,oe=/\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,ue=/,? & /,le=/[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g,se=/[()=,{}\\[\\]\\/\\s]/,ce=/\\\\(\\\\)?/g,fe=/\\$\\{([^\\\\}]*(?:\\\\.[^\\\\}]*)*)\\}/g,pe=/\\w*$/,de=/^[-+]0x[0-9a-f]+$/i,he=/^0b[01]+$/i,ve=/^\\[object .+?Constructor\\]$/,ge=/^0o[0-7]+$/i,ye=/^(?:0|[1-9]\\d*)$/,me=/[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g,be=/($^)/,_e=/['\\n\\r\\u2028\\u2029\\\\]/g,we=\"\\\\ud800-\\\\udfff\",xe=\"\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe2f\\\\u20d0-\\\\u20ff\",ke=\"\\\\u2700-\\\\u27bf\",Se=\"a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff\",Ee=\"A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde\",Ce=\"\\\\ufe0e\\\\ufe0f\",Te=\"\\\\xac\\\\xb1\\\\xd7\\\\xf7\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\\\\u2000-\\\\u206f \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\",Me=\"[\"+we+\"]\",Ne=\"[\"+Te+\"]\",Pe=\"[\"+xe+\"]\",ze=\"\\\\d+\",Le=\"[\"+ke+\"]\",Oe=\"[\"+Se+\"]\",Ae=\"[^\"+we+Te+ze+ke+Se+Ee+\"]\",Fe=\"\\\\ud83c[\\\\udffb-\\\\udfff]\",De=\"[^\"+we+\"]\",Re=\"(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}\",je=\"[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]\",Ue=\"[\"+Ee+\"]\",Ie=\"\\\\u200d\",$e=\"(?:\"+Oe+\"|\"+Ae+\")\",Be=\"(?:\"+Ue+\"|\"+Ae+\")\",We=\"(?:['’](?:d|ll|m|re|s|t|ve))?\",Ve=\"(?:['’](?:D|LL|M|RE|S|T|VE))?\",He=\"(?:\"+Pe+\"|\"+Fe+\")?\",qe=\"[\"+Ce+\"]?\",Qe=qe+He+\"(?:\"+Ie+\"(?:\"+[De,Re,je].join(\"|\")+\")\"+qe+He+\")*\",Ye=\"(?:\"+[Le,Re,je].join(\"|\")+\")\"+Qe,Ge=\"(?:\"+[De+Pe+\"?\",Pe,Re,je,Me].join(\"|\")+\")\",Ke=RegExp(\"['’]\",\"g\"),Ze=RegExp(Pe,\"g\"),Xe=RegExp(Fe+\"(?=\"+Fe+\")|\"+Ge+Qe,\"g\"),Je=RegExp([Ue+\"?\"+Oe+\"+\"+We+\"(?=\"+[Ne,Ue,\"$\"].join(\"|\")+\")\",Be+\"+\"+Ve+\"(?=\"+[Ne,Ue+$e,\"$\"].join(\"|\")+\")\",Ue+\"?\"+$e+\"+\"+We,Ue+\"+\"+Ve,\"\\\\d*(?:1ST|2ND|3RD|(?![123])\\\\dTH)(?=\\\\b|[a-z_])\",\"\\\\d*(?:1st|2nd|3rd|(?![123])\\\\dth)(?=\\\\b|[A-Z_])\",ze,Ye].join(\"|\"),\"g\"),et=RegExp(\"[\"+Ie+we+xe+Ce+\"]\"),tt=/[a-z][A-Z]|[A-Z]{2}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,nt=[\"Array\",\"Buffer\",\"DataView\",\"Date\",\"Error\",\"Float32Array\",\"Float64Array\",\"Function\",\"Int8Array\",\"Int16Array\",\"Int32Array\",\"Map\",\"Math\",\"Object\",\"Promise\",\"RegExp\",\"Set\",\"String\",\"Symbol\",\"TypeError\",\"Uint8Array\",\"Uint8ClampedArray\",\"Uint16Array\",\"Uint32Array\",\"WeakMap\",\"_\",\"clearTimeout\",\"isFinite\",\"parseInt\",\"setTimeout\"],rt=-1,at={};at[O]=at[A]=at[F]=at[D]=at[R]=at[j]=at[U]=at[I]=at[$]=!0,at[v]=at[g]=at[z]=at[y]=at[L]=at[m]=at[b]=at[_]=at[x]=at[k]=at[S]=at[C]=at[T]=at[M]=at[P]=!1;var it={};it[v]=it[g]=it[z]=it[L]=it[y]=it[m]=it[O]=it[A]=it[F]=it[D]=it[R]=it[x]=it[k]=it[S]=it[C]=it[T]=it[M]=it[N]=it[j]=it[U]=it[I]=it[$]=!0,it[b]=it[_]=it[P]=!1;var ot={\"\\\\\":\"\\\\\",\"'\":\"'\",\"\\n\":\"n\",\"\\r\":\"r\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},ut=parseFloat,lt=parseInt,st=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,ct=\"object\"==typeof self&&self&&self.Object===Object&&self,ft=st||ct||Function(\"return this\")(),pt=t&&!t.nodeType&&t,dt=pt&&e&&!e.nodeType&&e,ht=dt&&dt.exports===pt,vt=ht&&st.process,gt=function(){try{return dt&&dt.require&&dt.require(\"util\").types||vt&&vt.binding&&vt.binding(\"util\")}catch(e){}}(),yt=gt&&gt.isArrayBuffer,mt=gt&&gt.isDate,bt=gt&&gt.isMap,_t=gt&&gt.isRegExp,wt=gt&&gt.isSet,xt=gt&&gt.isTypedArray;function kt(e,t,n){switch(n.length){case 0:return e.call(t);case 1:return e.call(t,n[0]);case 2:return e.call(t,n[0],n[1]);case 3:return e.call(t,n[0],n[1],n[2])}return e.apply(t,n)}function St(e,t,n,r){for(var a=-1,i=null==e?0:e.length;++a<i;){var o=e[a];t(r,o,n(o),e)}return r}function Et(e,t){for(var n=-1,r=null==e?0:e.length;++n<r&&!1!==t(e[n],n,e););return e}function Ct(e,t){for(var n=null==e?0:e.length;n--&&!1!==t(e[n],n,e););return e}function Tt(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(!t(e[n],n,e))return!1;return!0}function Mt(e,t){for(var n=-1,r=null==e?0:e.length,a=0,i=[];++n<r;){var o=e[n];t(o,n,e)&&(i[a++]=o)}return i}function Nt(e,t){return!(null==e||!e.length)&&Ut(e,t,0)>-1}function Pt(e,t,n){for(var r=-1,a=null==e?0:e.length;++r<a;)if(n(t,e[r]))return!0;return!1}function zt(e,t){for(var n=-1,r=null==e?0:e.length,a=Array(r);++n<r;)a[n]=t(e[n],n,e);return a}function Lt(e,t){for(var n=-1,r=t.length,a=e.length;++n<r;)e[a+n]=t[n];return e}function Ot(e,t,n,r){var a=-1,i=null==e?0:e.length;for(r&&i&&(n=e[++a]);++a<i;)n=t(n,e[a],a,e);return n}function At(e,t,n,r){var a=null==e?0:e.length;for(r&&a&&(n=e[--a]);a--;)n=t(n,e[a],a,e);return n}function Ft(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(t(e[n],n,e))return!0;return!1}var Dt=Wt(\"length\");function Rt(e,t,n){var r;return n(e,(function(e,n,a){if(t(e,n,a))return r=n,!1})),r}function jt(e,t,n,r){for(var a=e.length,i=n+(r?1:-1);r?i--:++i<a;)if(t(e[i],i,e))return i;return-1}function Ut(e,t,n){return t==t?function(e,t,n){for(var r=n-1,a=e.length;++r<a;)if(e[r]===t)return r;return-1}(e,t,n):jt(e,$t,n)}function It(e,t,n,r){for(var a=n-1,i=e.length;++a<i;)if(r(e[a],t))return a;return-1}function $t(e){return e!=e}function Bt(e,t){var n=null==e?0:e.length;return n?qt(e,t)/n:p}function Wt(e){return function(t){return null==t?a:t[e]}}function Vt(e){return function(t){return null==e?a:e[t]}}function Ht(e,t,n,r,a){return a(e,(function(e,a,i){n=r?(r=!1,e):t(n,e,a,i)})),n}function qt(e,t){for(var n,r=-1,i=e.length;++r<i;){var o=t(e[r]);o!==a&&(n=n===a?o:n+o)}return n}function Qt(e,t){for(var n=-1,r=Array(e);++n<e;)r[n]=t(n);return r}function Yt(e){return e?e.slice(0,pn(e)+1).replace(re,\"\"):e}function Gt(e){return function(t){return e(t)}}function Kt(e,t){return zt(t,(function(t){return e[t]}))}function Zt(e,t){return e.has(t)}function Xt(e,t){for(var n=-1,r=e.length;++n<r&&Ut(t,e[n],0)>-1;);return n}function Jt(e,t){for(var n=e.length;n--&&Ut(t,e[n],0)>-1;);return n}var en=Vt({À:\"A\",Á:\"A\",Â:\"A\",Ã:\"A\",Ä:\"A\",Å:\"A\",à:\"a\",á:\"a\",â:\"a\",ã:\"a\",ä:\"a\",å:\"a\",Ç:\"C\",ç:\"c\",Ð:\"D\",ð:\"d\",È:\"E\",É:\"E\",Ê:\"E\",Ë:\"E\",è:\"e\",é:\"e\",ê:\"e\",ë:\"e\",Ì:\"I\",Í:\"I\",Î:\"I\",Ï:\"I\",ì:\"i\",í:\"i\",î:\"i\",ï:\"i\",Ñ:\"N\",ñ:\"n\",Ò:\"O\",Ó:\"O\",Ô:\"O\",Õ:\"O\",Ö:\"O\",Ø:\"O\",ò:\"o\",ó:\"o\",ô:\"o\",õ:\"o\",ö:\"o\",ø:\"o\",Ù:\"U\",Ú:\"U\",Û:\"U\",Ü:\"U\",ù:\"u\",ú:\"u\",û:\"u\",ü:\"u\",Ý:\"Y\",ý:\"y\",ÿ:\"y\",Æ:\"Ae\",æ:\"ae\",Þ:\"Th\",þ:\"th\",ß:\"ss\",Ā:\"A\",Ă:\"A\",Ą:\"A\",ā:\"a\",ă:\"a\",ą:\"a\",Ć:\"C\",Ĉ:\"C\",Ċ:\"C\",Č:\"C\",ć:\"c\",ĉ:\"c\",ċ:\"c\",č:\"c\",Ď:\"D\",Đ:\"D\",ď:\"d\",đ:\"d\",Ē:\"E\",Ĕ:\"E\",Ė:\"E\",Ę:\"E\",Ě:\"E\",ē:\"e\",ĕ:\"e\",ė:\"e\",ę:\"e\",ě:\"e\",Ĝ:\"G\",Ğ:\"G\",Ġ:\"G\",Ģ:\"G\",ĝ:\"g\",ğ:\"g\",ġ:\"g\",ģ:\"g\",Ĥ:\"H\",Ħ:\"H\",ĥ:\"h\",ħ:\"h\",Ĩ:\"I\",Ī:\"I\",Ĭ:\"I\",Į:\"I\",İ:\"I\",ĩ:\"i\",ī:\"i\",ĭ:\"i\",į:\"i\",ı:\"i\",Ĵ:\"J\",ĵ:\"j\",Ķ:\"K\",ķ:\"k\",ĸ:\"k\",Ĺ:\"L\",Ļ:\"L\",Ľ:\"L\",Ŀ:\"L\",Ł:\"L\",ĺ:\"l\",ļ:\"l\",ľ:\"l\",ŀ:\"l\",ł:\"l\",Ń:\"N\",Ņ:\"N\",Ň:\"N\",Ŋ:\"N\",ń:\"n\",ņ:\"n\",ň:\"n\",ŋ:\"n\",Ō:\"O\",Ŏ:\"O\",Ő:\"O\",ō:\"o\",ŏ:\"o\",ő:\"o\",Ŕ:\"R\",Ŗ:\"R\",Ř:\"R\",ŕ:\"r\",ŗ:\"r\",ř:\"r\",Ś:\"S\",Ŝ:\"S\",Ş:\"S\",Š:\"S\",ś:\"s\",ŝ:\"s\",ş:\"s\",š:\"s\",Ţ:\"T\",Ť:\"T\",Ŧ:\"T\",ţ:\"t\",ť:\"t\",ŧ:\"t\",Ũ:\"U\",Ū:\"U\",Ŭ:\"U\",Ů:\"U\",Ű:\"U\",Ų:\"U\",ũ:\"u\",ū:\"u\",ŭ:\"u\",ů:\"u\",ű:\"u\",ų:\"u\",Ŵ:\"W\",ŵ:\"w\",Ŷ:\"Y\",ŷ:\"y\",Ÿ:\"Y\",Ź:\"Z\",Ż:\"Z\",Ž:\"Z\",ź:\"z\",ż:\"z\",ž:\"z\",Ĳ:\"IJ\",ĳ:\"ij\",Œ:\"Oe\",œ:\"oe\",ŉ:\"'n\",ſ:\"s\"}),tn=Vt({\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"});function nn(e){return\"\\\\\"+ot[e]}function rn(e){return et.test(e)}function an(e){var t=-1,n=Array(e.size);return e.forEach((function(e,r){n[++t]=[r,e]})),n}function on(e,t){return function(n){return e(t(n))}}function un(e,t){for(var n=-1,r=e.length,a=0,i=[];++n<r;){var o=e[n];o!==t&&o!==u||(e[n]=u,i[a++]=n)}return i}function ln(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=e})),n}function sn(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=[e,e]})),n}function cn(e){return rn(e)?function(e){for(var t=Xe.lastIndex=0;Xe.test(e);)++t;return t}(e):Dt(e)}function fn(e){return rn(e)?function(e){return e.match(Xe)||[]}(e):function(e){return e.split(\"\")}(e)}function pn(e){for(var t=e.length;t--&&ae.test(e.charAt(t)););return t}var dn=Vt({\"&amp;\":\"&\",\"&lt;\":\"<\",\"&gt;\":\">\",\"&quot;\":'\"',\"&#39;\":\"'\"}),hn=function e(t){var n,r=(t=null==t?ft:hn.defaults(ft.Object(),t,hn.pick(ft,nt))).Array,ae=t.Date,we=t.Error,xe=t.Function,ke=t.Math,Se=t.Object,Ee=t.RegExp,Ce=t.String,Te=t.TypeError,Me=r.prototype,Ne=xe.prototype,Pe=Se.prototype,ze=t[\"__core-js_shared__\"],Le=Ne.toString,Oe=Pe.hasOwnProperty,Ae=0,Fe=(n=/[^.]+$/.exec(ze&&ze.keys&&ze.keys.IE_PROTO||\"\"))?\"Symbol(src)_1.\"+n:\"\",De=Pe.toString,Re=Le.call(Se),je=ft._,Ue=Ee(\"^\"+Le.call(Oe).replace(te,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\"),Ie=ht?t.Buffer:a,$e=t.Symbol,Be=t.Uint8Array,We=Ie?Ie.allocUnsafe:a,Ve=on(Se.getPrototypeOf,Se),He=Se.create,qe=Pe.propertyIsEnumerable,Qe=Me.splice,Ye=$e?$e.isConcatSpreadable:a,Ge=$e?$e.iterator:a,Xe=$e?$e.toStringTag:a,et=function(){try{var e=li(Se,\"defineProperty\");return e({},\"\",{}),e}catch(e){}}(),ot=t.clearTimeout!==ft.clearTimeout&&t.clearTimeout,st=ae&&ae.now!==ft.Date.now&&ae.now,ct=t.setTimeout!==ft.setTimeout&&t.setTimeout,pt=ke.ceil,dt=ke.floor,vt=Se.getOwnPropertySymbols,gt=Ie?Ie.isBuffer:a,Dt=t.isFinite,Vt=Me.join,vn=on(Se.keys,Se),gn=ke.max,yn=ke.min,mn=ae.now,bn=t.parseInt,_n=ke.random,wn=Me.reverse,xn=li(t,\"DataView\"),kn=li(t,\"Map\"),Sn=li(t,\"Promise\"),En=li(t,\"Set\"),Cn=li(t,\"WeakMap\"),Tn=li(Se,\"create\"),Mn=Cn&&new Cn,Nn={},Pn=Di(xn),zn=Di(kn),Ln=Di(Sn),On=Di(En),An=Di(Cn),Fn=$e?$e.prototype:a,Dn=Fn?Fn.valueOf:a,Rn=Fn?Fn.toString:a;function jn(e){if(eu(e)&&!Wo(e)&&!(e instanceof Bn)){if(e instanceof $n)return e;if(Oe.call(e,\"__wrapped__\"))return Ri(e)}return new $n(e)}var Un=function(){function e(){}return function(t){if(!Jo(t))return{};if(He)return He(t);e.prototype=t;var n=new e;return e.prototype=a,n}}();function In(){}function $n(e,t){this.__wrapped__=e,this.__actions__=[],this.__chain__=!!t,this.__index__=0,this.__values__=a}function Bn(e){this.__wrapped__=e,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=d,this.__views__=[]}function Wn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function Vn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function Hn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function qn(e){var t=-1,n=null==e?0:e.length;for(this.__data__=new Hn;++t<n;)this.add(e[t])}function Qn(e){var t=this.__data__=new Vn(e);this.size=t.size}function Yn(e,t){var n=Wo(e),r=!n&&Bo(e),a=!n&&!r&&Qo(e),i=!n&&!r&&!a&&lu(e),o=n||r||a||i,u=o?Qt(e.length,Ce):[],l=u.length;for(var s in e)!t&&!Oe.call(e,s)||o&&(\"length\"==s||a&&(\"offset\"==s||\"parent\"==s)||i&&(\"buffer\"==s||\"byteLength\"==s||\"byteOffset\"==s)||vi(s,l))||u.push(s);return u}function Gn(e){var t=e.length;return t?e[Hr(0,t-1)]:a}function Kn(e,t){return zi(Ca(e),ir(t,0,e.length))}function Zn(e){return zi(Ca(e))}function Xn(e,t,n){(n!==a&&!Uo(e[t],n)||n===a&&!(t in e))&&rr(e,t,n)}function Jn(e,t,n){var r=e[t];Oe.call(e,t)&&Uo(r,n)&&(n!==a||t in e)||rr(e,t,n)}function er(e,t){for(var n=e.length;n--;)if(Uo(e[n][0],t))return n;return-1}function tr(e,t,n,r){return cr(e,(function(e,a,i){t(r,e,n(e),i)})),r}function nr(e,t){return e&&Ta(t,Pu(t),e)}function rr(e,t,n){\"__proto__\"==t&&et?et(e,t,{configurable:!0,enumerable:!0,value:n,writable:!0}):e[t]=n}function ar(e,t){for(var n=-1,i=t.length,o=r(i),u=null==e;++n<i;)o[n]=u?a:Eu(e,t[n]);return o}function ir(e,t,n){return e==e&&(n!==a&&(e=e<=n?e:n),t!==a&&(e=e>=t?e:t)),e}function or(e,t,n,r,i,o){var u,l=1&t,s=2&t,c=4&t;if(n&&(u=i?n(e,r,i,o):n(e)),u!==a)return u;if(!Jo(e))return e;var f=Wo(e);if(f){if(u=function(e){var t=e.length,n=new e.constructor(t);return t&&\"string\"==typeof e[0]&&Oe.call(e,\"index\")&&(n.index=e.index,n.input=e.input),n}(e),!l)return Ca(e,u)}else{var p=fi(e),d=p==_||p==w;if(Qo(e))return _a(e,l);if(p==S||p==v||d&&!i){if(u=s||d?{}:di(e),!l)return s?function(e,t){return Ta(e,ci(e),t)}(e,function(e,t){return e&&Ta(t,zu(t),e)}(u,e)):function(e,t){return Ta(e,si(e),t)}(e,nr(u,e))}else{if(!it[p])return i?e:{};u=function(e,t,n){var r,a=e.constructor;switch(t){case z:return wa(e);case y:case m:return new a(+e);case L:return function(e,t){var n=t?wa(e.buffer):e.buffer;return new e.constructor(n,e.byteOffset,e.byteLength)}(e,n);case O:case A:case F:case D:case R:case j:case U:case I:case $:return xa(e,n);case x:return new a;case k:case M:return new a(e);case C:return function(e){var t=new e.constructor(e.source,pe.exec(e));return t.lastIndex=e.lastIndex,t}(e);case T:return new a;case N:return r=e,Dn?Se(Dn.call(r)):{}}}(e,p,l)}}o||(o=new Qn);var h=o.get(e);if(h)return h;o.set(e,u),iu(e)?e.forEach((function(r){u.add(or(r,t,n,r,e,o))})):tu(e)&&e.forEach((function(r,a){u.set(a,or(r,t,n,a,e,o))}));var g=f?a:(c?s?ti:ei:s?zu:Pu)(e);return Et(g||e,(function(r,a){g&&(r=e[a=r]),Jn(u,a,or(r,t,n,a,e,o))})),u}function ur(e,t,n){var r=n.length;if(null==e)return!r;for(e=Se(e);r--;){var i=n[r],o=t[i],u=e[i];if(u===a&&!(i in e)||!o(u))return!1}return!0}function lr(e,t,n){if(\"function\"!=typeof e)throw new Te(i);return Ti((function(){e.apply(a,n)}),t)}function sr(e,t,n,r){var a=-1,i=Nt,o=!0,u=e.length,l=[],s=t.length;if(!u)return l;n&&(t=zt(t,Gt(n))),r?(i=Pt,o=!1):t.length>=200&&(i=Zt,o=!1,t=new qn(t));e:for(;++a<u;){var c=e[a],f=null==n?c:n(c);if(c=r||0!==c?c:0,o&&f==f){for(var p=s;p--;)if(t[p]===f)continue e;l.push(c)}else i(t,f,r)||l.push(c)}return l}jn.templateSettings={escape:G,evaluate:K,interpolate:Z,variable:\"\",imports:{_:jn}},jn.prototype=In.prototype,jn.prototype.constructor=jn,$n.prototype=Un(In.prototype),$n.prototype.constructor=$n,Bn.prototype=Un(In.prototype),Bn.prototype.constructor=Bn,Wn.prototype.clear=function(){this.__data__=Tn?Tn(null):{},this.size=0},Wn.prototype.delete=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t},Wn.prototype.get=function(e){var t=this.__data__;if(Tn){var n=t[e];return n===o?a:n}return Oe.call(t,e)?t[e]:a},Wn.prototype.has=function(e){var t=this.__data__;return Tn?t[e]!==a:Oe.call(t,e)},Wn.prototype.set=function(e,t){var n=this.__data__;return this.size+=this.has(e)?0:1,n[e]=Tn&&t===a?o:t,this},Vn.prototype.clear=function(){this.__data__=[],this.size=0},Vn.prototype.delete=function(e){var t=this.__data__,n=er(t,e);return!(n<0||(n==t.length-1?t.pop():Qe.call(t,n,1),--this.size,0))},Vn.prototype.get=function(e){var t=this.__data__,n=er(t,e);return n<0?a:t[n][1]},Vn.prototype.has=function(e){return er(this.__data__,e)>-1},Vn.prototype.set=function(e,t){var n=this.__data__,r=er(n,e);return r<0?(++this.size,n.push([e,t])):n[r][1]=t,this},Hn.prototype.clear=function(){this.size=0,this.__data__={hash:new Wn,map:new(kn||Vn),string:new Wn}},Hn.prototype.delete=function(e){var t=oi(this,e).delete(e);return this.size-=t?1:0,t},Hn.prototype.get=function(e){return oi(this,e).get(e)},Hn.prototype.has=function(e){return oi(this,e).has(e)},Hn.prototype.set=function(e,t){var n=oi(this,e),r=n.size;return n.set(e,t),this.size+=n.size==r?0:1,this},qn.prototype.add=qn.prototype.push=function(e){return this.__data__.set(e,o),this},qn.prototype.has=function(e){return this.__data__.has(e)},Qn.prototype.clear=function(){this.__data__=new Vn,this.size=0},Qn.prototype.delete=function(e){var t=this.__data__,n=t.delete(e);return this.size=t.size,n},Qn.prototype.get=function(e){return this.__data__.get(e)},Qn.prototype.has=function(e){return this.__data__.has(e)},Qn.prototype.set=function(e,t){var n=this.__data__;if(n instanceof Vn){var r=n.__data__;if(!kn||r.length<199)return r.push([e,t]),this.size=++n.size,this;n=this.__data__=new Hn(r)}return n.set(e,t),this.size=n.size,this};var cr=Pa(mr),fr=Pa(br,!0);function pr(e,t){var n=!0;return cr(e,(function(e,r,a){return n=!!t(e,r,a)})),n}function dr(e,t,n){for(var r=-1,i=e.length;++r<i;){var o=e[r],u=t(o);if(null!=u&&(l===a?u==u&&!uu(u):n(u,l)))var l=u,s=o}return s}function hr(e,t){var n=[];return cr(e,(function(e,r,a){t(e,r,a)&&n.push(e)})),n}function vr(e,t,n,r,a){var i=-1,o=e.length;for(n||(n=hi),a||(a=[]);++i<o;){var u=e[i];t>0&&n(u)?t>1?vr(u,t-1,n,r,a):Lt(a,u):r||(a[a.length]=u)}return a}var gr=za(),yr=za(!0);function mr(e,t){return e&&gr(e,t,Pu)}function br(e,t){return e&&yr(e,t,Pu)}function _r(e,t){return Mt(t,(function(t){return Ko(e[t])}))}function wr(e,t){for(var n=0,r=(t=ga(t,e)).length;null!=e&&n<r;)e=e[Fi(t[n++])];return n&&n==r?e:a}function xr(e,t,n){var r=t(e);return Wo(e)?r:Lt(r,n(e))}function kr(e){return null==e?e===a?\"[object Undefined]\":\"[object Null]\":Xe&&Xe in Se(e)?function(e){var t=Oe.call(e,Xe),n=e[Xe];try{e[Xe]=a;var r=!0}catch(e){}var i=De.call(e);return r&&(t?e[Xe]=n:delete e[Xe]),i}(e):function(e){return De.call(e)}(e)}function Sr(e,t){return e>t}function Er(e,t){return null!=e&&Oe.call(e,t)}function Cr(e,t){return null!=e&&t in Se(e)}function Tr(e,t,n){for(var i=n?Pt:Nt,o=e[0].length,u=e.length,l=u,s=r(u),c=1/0,f=[];l--;){var p=e[l];l&&t&&(p=zt(p,Gt(t))),c=yn(p.length,c),s[l]=!n&&(t||o>=120&&p.length>=120)?new qn(l&&p):a}p=e[0];var d=-1,h=s[0];e:for(;++d<o&&f.length<c;){var v=p[d],g=t?t(v):v;if(v=n||0!==v?v:0,!(h?Zt(h,g):i(f,g,n))){for(l=u;--l;){var y=s[l];if(!(y?Zt(y,g):i(e[l],g,n)))continue e}h&&h.push(g),f.push(v)}}return f}function Mr(e,t,n){var r=null==(e=Si(e,t=ga(t,e)))?e:e[Fi(Yi(t))];return null==r?a:kt(r,e,n)}function Nr(e){return eu(e)&&kr(e)==v}function Pr(e,t,n,r,i){return e===t||(null==e||null==t||!eu(e)&&!eu(t)?e!=e&&t!=t:function(e,t,n,r,i,o){var u=Wo(e),l=Wo(t),s=u?g:fi(e),c=l?g:fi(t),f=(s=s==v?S:s)==S,p=(c=c==v?S:c)==S,d=s==c;if(d&&Qo(e)){if(!Qo(t))return!1;u=!0,f=!1}if(d&&!f)return o||(o=new Qn),u||lu(e)?Xa(e,t,n,r,i,o):function(e,t,n,r,a,i,o){switch(n){case L:if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case z:return!(e.byteLength!=t.byteLength||!i(new Be(e),new Be(t)));case y:case m:case k:return Uo(+e,+t);case b:return e.name==t.name&&e.message==t.message;case C:case M:return e==t+\"\";case x:var u=an;case T:var l=1&r;if(u||(u=ln),e.size!=t.size&&!l)return!1;var s=o.get(e);if(s)return s==t;r|=2,o.set(e,t);var c=Xa(u(e),u(t),r,a,i,o);return o.delete(e),c;case N:if(Dn)return Dn.call(e)==Dn.call(t)}return!1}(e,t,s,n,r,i,o);if(!(1&n)){var h=f&&Oe.call(e,\"__wrapped__\"),_=p&&Oe.call(t,\"__wrapped__\");if(h||_){var w=h?e.value():e,E=_?t.value():t;return o||(o=new Qn),i(w,E,n,r,o)}}return!!d&&(o||(o=new Qn),function(e,t,n,r,i,o){var u=1&n,l=ei(e),s=l.length;if(s!=ei(t).length&&!u)return!1;for(var c=s;c--;){var f=l[c];if(!(u?f in t:Oe.call(t,f)))return!1}var p=o.get(e),d=o.get(t);if(p&&d)return p==t&&d==e;var h=!0;o.set(e,t),o.set(t,e);for(var v=u;++c<s;){var g=e[f=l[c]],y=t[f];if(r)var m=u?r(y,g,f,t,e,o):r(g,y,f,e,t,o);if(!(m===a?g===y||i(g,y,n,r,o):m)){h=!1;break}v||(v=\"constructor\"==f)}if(h&&!v){var b=e.constructor,_=t.constructor;b==_||!(\"constructor\"in e)||!(\"constructor\"in t)||\"function\"==typeof b&&b instanceof b&&\"function\"==typeof _&&_ instanceof _||(h=!1)}return o.delete(e),o.delete(t),h}(e,t,n,r,i,o))}(e,t,n,r,Pr,i))}function zr(e,t,n,r){var i=n.length,o=i,u=!r;if(null==e)return!o;for(e=Se(e);i--;){var l=n[i];if(u&&l[2]?l[1]!==e[l[0]]:!(l[0]in e))return!1}for(;++i<o;){var s=(l=n[i])[0],c=e[s],f=l[1];if(u&&l[2]){if(c===a&&!(s in e))return!1}else{var p=new Qn;if(r)var d=r(c,f,s,e,t,p);if(!(d===a?Pr(f,c,3,r,p):d))return!1}}return!0}function Lr(e){return!(!Jo(e)||(t=e,Fe&&Fe in t))&&(Ko(e)?Ue:ve).test(Di(e));var t}function Or(e){return\"function\"==typeof e?e:null==e?nl:\"object\"==typeof e?Wo(e)?jr(e[0],e[1]):Rr(e):fl(e)}function Ar(e){if(!_i(e))return vn(e);var t=[];for(var n in Se(e))Oe.call(e,n)&&\"constructor\"!=n&&t.push(n);return t}function Fr(e,t){return e<t}function Dr(e,t){var n=-1,a=Ho(e)?r(e.length):[];return cr(e,(function(e,r,i){a[++n]=t(e,r,i)})),a}function Rr(e){var t=ui(e);return 1==t.length&&t[0][2]?xi(t[0][0],t[0][1]):function(n){return n===e||zr(n,e,t)}}function jr(e,t){return yi(e)&&wi(t)?xi(Fi(e),t):function(n){var r=Eu(n,e);return r===a&&r===t?Cu(n,e):Pr(t,r,3)}}function Ur(e,t,n,r,i){e!==t&&gr(t,(function(o,u){if(i||(i=new Qn),Jo(o))!function(e,t,n,r,i,o,u){var l=Ei(e,n),s=Ei(t,n),c=u.get(s);if(c)Xn(e,n,c);else{var f=o?o(l,s,n+\"\",e,t,u):a,p=f===a;if(p){var d=Wo(s),h=!d&&Qo(s),v=!d&&!h&&lu(s);f=s,d||h||v?Wo(l)?f=l:qo(l)?f=Ca(l):h?(p=!1,f=_a(s,!0)):v?(p=!1,f=xa(s,!0)):f=[]:ru(s)||Bo(s)?(f=l,Bo(l)?f=gu(l):Jo(l)&&!Ko(l)||(f=di(s))):p=!1}p&&(u.set(s,f),i(f,s,r,o,u),u.delete(s)),Xn(e,n,f)}}(e,t,u,n,Ur,r,i);else{var l=r?r(Ei(e,u),o,u+\"\",e,t,i):a;l===a&&(l=o),Xn(e,u,l)}}),zu)}function Ir(e,t){var n=e.length;if(n)return vi(t+=t<0?n:0,n)?e[t]:a}function $r(e,t,n){t=t.length?zt(t,(function(e){return Wo(e)?function(t){return wr(t,1===e.length?e[0]:e)}:e})):[nl];var r=-1;t=zt(t,Gt(ii()));var a=Dr(e,(function(e,n,a){var i=zt(t,(function(t){return t(e)}));return{criteria:i,index:++r,value:e}}));return function(e,t){var r=e.length;for(e.sort((function(e,t){return function(e,t,n){for(var r=-1,a=e.criteria,i=t.criteria,o=a.length,u=n.length;++r<o;){var l=ka(a[r],i[r]);if(l)return r>=u?l:l*(\"desc\"==n[r]?-1:1)}return e.index-t.index}(e,t,n)}));r--;)e[r]=e[r].value;return e}(a)}function Br(e,t,n){for(var r=-1,a=t.length,i={};++r<a;){var o=t[r],u=wr(e,o);n(u,o)&&Kr(i,ga(o,e),u)}return i}function Wr(e,t,n,r){var a=r?It:Ut,i=-1,o=t.length,u=e;for(e===t&&(t=Ca(t)),n&&(u=zt(e,Gt(n)));++i<o;)for(var l=0,s=t[i],c=n?n(s):s;(l=a(u,c,l,r))>-1;)u!==e&&Qe.call(u,l,1),Qe.call(e,l,1);return e}function Vr(e,t){for(var n=e?t.length:0,r=n-1;n--;){var a=t[n];if(n==r||a!==i){var i=a;vi(a)?Qe.call(e,a,1):la(e,a)}}return e}function Hr(e,t){return e+dt(_n()*(t-e+1))}function qr(e,t){var n=\"\";if(!e||t<1||t>f)return n;do{t%2&&(n+=e),(t=dt(t/2))&&(e+=e)}while(t);return n}function Qr(e,t){return Mi(ki(e,t,nl),e+\"\")}function Yr(e){return Gn(Uu(e))}function Gr(e,t){var n=Uu(e);return zi(n,ir(t,0,n.length))}function Kr(e,t,n,r){if(!Jo(e))return e;for(var i=-1,o=(t=ga(t,e)).length,u=o-1,l=e;null!=l&&++i<o;){var s=Fi(t[i]),c=n;if(\"__proto__\"===s||\"constructor\"===s||\"prototype\"===s)return e;if(i!=u){var f=l[s];(c=r?r(f,s,l):a)===a&&(c=Jo(f)?f:vi(t[i+1])?[]:{})}Jn(l,s,c),l=l[s]}return e}var Zr=Mn?function(e,t){return Mn.set(e,t),e}:nl,Xr=et?function(e,t){return et(e,\"toString\",{configurable:!0,enumerable:!1,value:Ju(t),writable:!0})}:nl;function Jr(e){return zi(Uu(e))}function ea(e,t,n){var a=-1,i=e.length;t<0&&(t=-t>i?0:i+t),(n=n>i?i:n)<0&&(n+=i),i=t>n?0:n-t>>>0,t>>>=0;for(var o=r(i);++a<i;)o[a]=e[a+t];return o}function ta(e,t){var n;return cr(e,(function(e,r,a){return!(n=t(e,r,a))})),!!n}function na(e,t,n){var r=0,a=null==e?r:e.length;if(\"number\"==typeof t&&t==t&&a<=2147483647){for(;r<a;){var i=r+a>>>1,o=e[i];null!==o&&!uu(o)&&(n?o<=t:o<t)?r=i+1:a=i}return a}return ra(e,t,nl,n)}function ra(e,t,n,r){var i=0,o=null==e?0:e.length;if(0===o)return 0;for(var u=(t=n(t))!=t,l=null===t,s=uu(t),c=t===a;i<o;){var f=dt((i+o)/2),p=n(e[f]),d=p!==a,h=null===p,v=p==p,g=uu(p);if(u)var y=r||v;else y=c?v&&(r||d):l?v&&d&&(r||!h):s?v&&d&&!h&&(r||!g):!h&&!g&&(r?p<=t:p<t);y?i=f+1:o=f}return yn(o,4294967294)}function aa(e,t){for(var n=-1,r=e.length,a=0,i=[];++n<r;){var o=e[n],u=t?t(o):o;if(!n||!Uo(u,l)){var l=u;i[a++]=0===o?0:o}}return i}function ia(e){return\"number\"==typeof e?e:uu(e)?p:+e}function oa(e){if(\"string\"==typeof e)return e;if(Wo(e))return zt(e,oa)+\"\";if(uu(e))return Rn?Rn.call(e):\"\";var t=e+\"\";return\"0\"==t&&1/e==-1/0?\"-0\":t}function ua(e,t,n){var r=-1,a=Nt,i=e.length,o=!0,u=[],l=u;if(n)o=!1,a=Pt;else if(i>=200){var s=t?null:qa(e);if(s)return ln(s);o=!1,a=Zt,l=new qn}else l=t?[]:u;e:for(;++r<i;){var c=e[r],f=t?t(c):c;if(c=n||0!==c?c:0,o&&f==f){for(var p=l.length;p--;)if(l[p]===f)continue e;t&&l.push(f),u.push(c)}else a(l,f,n)||(l!==u&&l.push(f),u.push(c))}return u}function la(e,t){return null==(e=Si(e,t=ga(t,e)))||delete e[Fi(Yi(t))]}function sa(e,t,n,r){return Kr(e,t,n(wr(e,t)),r)}function ca(e,t,n,r){for(var a=e.length,i=r?a:-1;(r?i--:++i<a)&&t(e[i],i,e););return n?ea(e,r?0:i,r?i+1:a):ea(e,r?i+1:0,r?a:i)}function fa(e,t){var n=e;return n instanceof Bn&&(n=n.value()),Ot(t,(function(e,t){return t.func.apply(t.thisArg,Lt([e],t.args))}),n)}function pa(e,t,n){var a=e.length;if(a<2)return a?ua(e[0]):[];for(var i=-1,o=r(a);++i<a;)for(var u=e[i],l=-1;++l<a;)l!=i&&(o[i]=sr(o[i]||u,e[l],t,n));return ua(vr(o,1),t,n)}function da(e,t,n){for(var r=-1,i=e.length,o=t.length,u={};++r<i;){var l=r<o?t[r]:a;n(u,e[r],l)}return u}function ha(e){return qo(e)?e:[]}function va(e){return\"function\"==typeof e?e:nl}function ga(e,t){return Wo(e)?e:yi(e,t)?[e]:Ai(yu(e))}var ya=Qr;function ma(e,t,n){var r=e.length;return n=n===a?r:n,!t&&n>=r?e:ea(e,t,n)}var ba=ot||function(e){return ft.clearTimeout(e)};function _a(e,t){if(t)return e.slice();var n=e.length,r=We?We(n):new e.constructor(n);return e.copy(r),r}function wa(e){var t=new e.constructor(e.byteLength);return new Be(t).set(new Be(e)),t}function xa(e,t){var n=t?wa(e.buffer):e.buffer;return new e.constructor(n,e.byteOffset,e.length)}function ka(e,t){if(e!==t){var n=e!==a,r=null===e,i=e==e,o=uu(e),u=t!==a,l=null===t,s=t==t,c=uu(t);if(!l&&!c&&!o&&e>t||o&&u&&s&&!l&&!c||r&&u&&s||!n&&s||!i)return 1;if(!r&&!o&&!c&&e<t||c&&n&&i&&!r&&!o||l&&n&&i||!u&&i||!s)return-1}return 0}function Sa(e,t,n,a){for(var i=-1,o=e.length,u=n.length,l=-1,s=t.length,c=gn(o-u,0),f=r(s+c),p=!a;++l<s;)f[l]=t[l];for(;++i<u;)(p||i<o)&&(f[n[i]]=e[i]);for(;c--;)f[l++]=e[i++];return f}function Ea(e,t,n,a){for(var i=-1,o=e.length,u=-1,l=n.length,s=-1,c=t.length,f=gn(o-l,0),p=r(f+c),d=!a;++i<f;)p[i]=e[i];for(var h=i;++s<c;)p[h+s]=t[s];for(;++u<l;)(d||i<o)&&(p[h+n[u]]=e[i++]);return p}function Ca(e,t){var n=-1,a=e.length;for(t||(t=r(a));++n<a;)t[n]=e[n];return t}function Ta(e,t,n,r){var i=!n;n||(n={});for(var o=-1,u=t.length;++o<u;){var l=t[o],s=r?r(n[l],e[l],l,n,e):a;s===a&&(s=e[l]),i?rr(n,l,s):Jn(n,l,s)}return n}function Ma(e,t){return function(n,r){var a=Wo(n)?St:tr,i=t?t():{};return a(n,e,ii(r,2),i)}}function Na(e){return Qr((function(t,n){var r=-1,i=n.length,o=i>1?n[i-1]:a,u=i>2?n[2]:a;for(o=e.length>3&&\"function\"==typeof o?(i--,o):a,u&&gi(n[0],n[1],u)&&(o=i<3?a:o,i=1),t=Se(t);++r<i;){var l=n[r];l&&e(t,l,r,o)}return t}))}function Pa(e,t){return function(n,r){if(null==n)return n;if(!Ho(n))return e(n,r);for(var a=n.length,i=t?a:-1,o=Se(n);(t?i--:++i<a)&&!1!==r(o[i],i,o););return n}}function za(e){return function(t,n,r){for(var a=-1,i=Se(t),o=r(t),u=o.length;u--;){var l=o[e?u:++a];if(!1===n(i[l],l,i))break}return t}}function La(e){return function(t){var n=rn(t=yu(t))?fn(t):a,r=n?n[0]:t.charAt(0),i=n?ma(n,1).join(\"\"):t.slice(1);return r[e]()+i}}function Oa(e){return function(t){return Ot(Ku(Bu(t).replace(Ke,\"\")),e,\"\")}}function Aa(e){return function(){var t=arguments;switch(t.length){case 0:return new e;case 1:return new e(t[0]);case 2:return new e(t[0],t[1]);case 3:return new e(t[0],t[1],t[2]);case 4:return new e(t[0],t[1],t[2],t[3]);case 5:return new e(t[0],t[1],t[2],t[3],t[4]);case 6:return new e(t[0],t[1],t[2],t[3],t[4],t[5]);case 7:return new e(t[0],t[1],t[2],t[3],t[4],t[5],t[6])}var n=Un(e.prototype),r=e.apply(n,t);return Jo(r)?r:n}}function Fa(e){return function(t,n,r){var i=Se(t);if(!Ho(t)){var o=ii(n,3);t=Pu(t),n=function(e){return o(i[e],e,i)}}var u=e(t,n,r);return u>-1?i[o?t[u]:u]:a}}function Da(e){return Ja((function(t){var n=t.length,r=n,o=$n.prototype.thru;for(e&&t.reverse();r--;){var u=t[r];if(\"function\"!=typeof u)throw new Te(i);if(o&&!l&&\"wrapper\"==ri(u))var l=new $n([],!0)}for(r=l?r:n;++r<n;){var s=ri(u=t[r]),c=\"wrapper\"==s?ni(u):a;l=c&&mi(c[0])&&424==c[1]&&!c[4].length&&1==c[9]?l[ri(c[0])].apply(l,c[3]):1==u.length&&mi(u)?l[s]():l.thru(u)}return function(){var e=arguments,r=e[0];if(l&&1==e.length&&Wo(r))return l.plant(r).value();for(var a=0,i=n?t[a].apply(this,e):r;++a<n;)i=t[a].call(this,i);return i}}))}function Ra(e,t,n,i,o,u,l,c,f,p){var d=t&s,h=1&t,v=2&t,g=24&t,y=512&t,m=v?a:Aa(e);return function s(){for(var b=arguments.length,_=r(b),w=b;w--;)_[w]=arguments[w];if(g)var x=ai(s),k=function(e,t){for(var n=e.length,r=0;n--;)e[n]===t&&++r;return r}(_,x);if(i&&(_=Sa(_,i,o,g)),u&&(_=Ea(_,u,l,g)),b-=k,g&&b<p){var S=un(_,x);return Va(e,t,Ra,s.placeholder,n,_,S,c,f,p-b)}var E=h?n:this,C=v?E[e]:e;return b=_.length,c?_=function(e,t){for(var n=e.length,r=yn(t.length,n),i=Ca(e);r--;){var o=t[r];e[r]=vi(o,n)?i[o]:a}return e}(_,c):y&&b>1&&_.reverse(),d&&f<b&&(_.length=f),this&&this!==ft&&this instanceof s&&(C=m||Aa(C)),C.apply(E,_)}}function ja(e,t){return function(n,r){return function(e,t,n,r){return mr(e,(function(e,a,i){t(r,n(e),a,i)})),r}(n,e,t(r),{})}}function Ua(e,t){return function(n,r){var i;if(n===a&&r===a)return t;if(n!==a&&(i=n),r!==a){if(i===a)return r;\"string\"==typeof n||\"string\"==typeof r?(n=oa(n),r=oa(r)):(n=ia(n),r=ia(r)),i=e(n,r)}return i}}function Ia(e){return Ja((function(t){return t=zt(t,Gt(ii())),Qr((function(n){var r=this;return e(t,(function(e){return kt(e,r,n)}))}))}))}function $a(e,t){var n=(t=t===a?\" \":oa(t)).length;if(n<2)return n?qr(t,e):t;var r=qr(t,pt(e/cn(t)));return rn(t)?ma(fn(r),0,e).join(\"\"):r.slice(0,e)}function Ba(e){return function(t,n,i){return i&&\"number\"!=typeof i&&gi(t,n,i)&&(n=i=a),t=pu(t),n===a?(n=t,t=0):n=pu(n),function(e,t,n,a){for(var i=-1,o=gn(pt((t-e)/(n||1)),0),u=r(o);o--;)u[a?o:++i]=e,e+=n;return u}(t,n,i=i===a?t<n?1:-1:pu(i),e)}}function Wa(e){return function(t,n){return\"string\"==typeof t&&\"string\"==typeof n||(t=vu(t),n=vu(n)),e(t,n)}}function Va(e,t,n,r,i,o,u,s,c,f){var p=8&t;t|=p?l:64,4&(t&=~(p?64:l))||(t&=-4);var d=[e,t,i,p?o:a,p?u:a,p?a:o,p?a:u,s,c,f],h=n.apply(a,d);return mi(e)&&Ci(h,d),h.placeholder=r,Ni(h,e,t)}function Ha(e){var t=ke[e];return function(e,n){if(e=vu(e),(n=null==n?0:yn(du(n),292))&&Dt(e)){var r=(yu(e)+\"e\").split(\"e\");return+((r=(yu(t(r[0]+\"e\"+(+r[1]+n)))+\"e\").split(\"e\"))[0]+\"e\"+(+r[1]-n))}return t(e)}}var qa=En&&1/ln(new En([,-0]))[1]==c?function(e){return new En(e)}:ul;function Qa(e){return function(t){var n=fi(t);return n==x?an(t):n==T?sn(t):function(e,t){return zt(t,(function(t){return[t,e[t]]}))}(t,e(t))}}function Ya(e,t,n,o,c,f,p,d){var h=2&t;if(!h&&\"function\"!=typeof e)throw new Te(i);var v=o?o.length:0;if(v||(t&=-97,o=c=a),p=p===a?p:gn(du(p),0),d=d===a?d:du(d),v-=c?c.length:0,64&t){var g=o,y=c;o=c=a}var m=h?a:ni(e),b=[e,t,n,o,c,g,y,f,p,d];if(m&&function(e,t){var n=e[1],r=t[1],a=n|r,i=a<131,o=r==s&&8==n||r==s&&256==n&&e[7].length<=t[8]||384==r&&t[7].length<=t[8]&&8==n;if(!i&&!o)return e;1&r&&(e[2]=t[2],a|=1&n?0:4);var l=t[3];if(l){var c=e[3];e[3]=c?Sa(c,l,t[4]):l,e[4]=c?un(e[3],u):t[4]}(l=t[5])&&(c=e[5],e[5]=c?Ea(c,l,t[6]):l,e[6]=c?un(e[5],u):t[6]),(l=t[7])&&(e[7]=l),r&s&&(e[8]=null==e[8]?t[8]:yn(e[8],t[8])),null==e[9]&&(e[9]=t[9]),e[0]=t[0],e[1]=a}(b,m),e=b[0],t=b[1],n=b[2],o=b[3],c=b[4],!(d=b[9]=b[9]===a?h?0:e.length:gn(b[9]-v,0))&&24&t&&(t&=-25),t&&1!=t)_=8==t||16==t?function(e,t,n){var i=Aa(e);return function o(){for(var u=arguments.length,l=r(u),s=u,c=ai(o);s--;)l[s]=arguments[s];var f=u<3&&l[0]!==c&&l[u-1]!==c?[]:un(l,c);return(u-=f.length)<n?Va(e,t,Ra,o.placeholder,a,l,f,a,a,n-u):kt(this&&this!==ft&&this instanceof o?i:e,this,l)}}(e,t,d):t!=l&&33!=t||c.length?Ra.apply(a,b):function(e,t,n,a){var i=1&t,o=Aa(e);return function t(){for(var u=-1,l=arguments.length,s=-1,c=a.length,f=r(c+l),p=this&&this!==ft&&this instanceof t?o:e;++s<c;)f[s]=a[s];for(;l--;)f[s++]=arguments[++u];return kt(p,i?n:this,f)}}(e,t,n,o);else var _=function(e,t,n){var r=1&t,a=Aa(e);return function t(){return(this&&this!==ft&&this instanceof t?a:e).apply(r?n:this,arguments)}}(e,t,n);return Ni((m?Zr:Ci)(_,b),e,t)}function Ga(e,t,n,r){return e===a||Uo(e,Pe[n])&&!Oe.call(r,n)?t:e}function Ka(e,t,n,r,i,o){return Jo(e)&&Jo(t)&&(o.set(t,e),Ur(e,t,a,Ka,o),o.delete(t)),e}function Za(e){return ru(e)?a:e}function Xa(e,t,n,r,i,o){var u=1&n,l=e.length,s=t.length;if(l!=s&&!(u&&s>l))return!1;var c=o.get(e),f=o.get(t);if(c&&f)return c==t&&f==e;var p=-1,d=!0,h=2&n?new qn:a;for(o.set(e,t),o.set(t,e);++p<l;){var v=e[p],g=t[p];if(r)var y=u?r(g,v,p,t,e,o):r(v,g,p,e,t,o);if(y!==a){if(y)continue;d=!1;break}if(h){if(!Ft(t,(function(e,t){if(!Zt(h,t)&&(v===e||i(v,e,n,r,o)))return h.push(t)}))){d=!1;break}}else if(v!==g&&!i(v,g,n,r,o)){d=!1;break}}return o.delete(e),o.delete(t),d}function Ja(e){return Mi(ki(e,a,Wi),e+\"\")}function ei(e){return xr(e,Pu,si)}function ti(e){return xr(e,zu,ci)}var ni=Mn?function(e){return Mn.get(e)}:ul;function ri(e){for(var t=e.name+\"\",n=Nn[t],r=Oe.call(Nn,t)?n.length:0;r--;){var a=n[r],i=a.func;if(null==i||i==e)return a.name}return t}function ai(e){return(Oe.call(jn,\"placeholder\")?jn:e).placeholder}function ii(){var e=jn.iteratee||rl;return e=e===rl?Or:e,arguments.length?e(arguments[0],arguments[1]):e}function oi(e,t){var n,r,a=e.__data__;return(\"string\"==(r=typeof(n=t))||\"number\"==r||\"symbol\"==r||\"boolean\"==r?\"__proto__\"!==n:null===n)?a[\"string\"==typeof t?\"string\":\"hash\"]:a.map}function ui(e){for(var t=Pu(e),n=t.length;n--;){var r=t[n],a=e[r];t[n]=[r,a,wi(a)]}return t}function li(e,t){var n=function(e,t){return null==e?a:e[t]}(e,t);return Lr(n)?n:a}var si=vt?function(e){return null==e?[]:(e=Se(e),Mt(vt(e),(function(t){return qe.call(e,t)})))}:hl,ci=vt?function(e){for(var t=[];e;)Lt(t,si(e)),e=Ve(e);return t}:hl,fi=kr;function pi(e,t,n){for(var r=-1,a=(t=ga(t,e)).length,i=!1;++r<a;){var o=Fi(t[r]);if(!(i=null!=e&&n(e,o)))break;e=e[o]}return i||++r!=a?i:!!(a=null==e?0:e.length)&&Xo(a)&&vi(o,a)&&(Wo(e)||Bo(e))}function di(e){return\"function\"!=typeof e.constructor||_i(e)?{}:Un(Ve(e))}function hi(e){return Wo(e)||Bo(e)||!!(Ye&&e&&e[Ye])}function vi(e,t){var n=typeof e;return!!(t=null==t?f:t)&&(\"number\"==n||\"symbol\"!=n&&ye.test(e))&&e>-1&&e%1==0&&e<t}function gi(e,t,n){if(!Jo(n))return!1;var r=typeof t;return!!(\"number\"==r?Ho(n)&&vi(t,n.length):\"string\"==r&&t in n)&&Uo(n[t],e)}function yi(e,t){if(Wo(e))return!1;var n=typeof e;return!(\"number\"!=n&&\"symbol\"!=n&&\"boolean\"!=n&&null!=e&&!uu(e))||J.test(e)||!X.test(e)||null!=t&&e in Se(t)}function mi(e){var t=ri(e),n=jn[t];if(\"function\"!=typeof n||!(t in Bn.prototype))return!1;if(e===n)return!0;var r=ni(n);return!!r&&e===r[0]}(xn&&fi(new xn(new ArrayBuffer(1)))!=L||kn&&fi(new kn)!=x||Sn&&fi(Sn.resolve())!=E||En&&fi(new En)!=T||Cn&&fi(new Cn)!=P)&&(fi=function(e){var t=kr(e),n=t==S?e.constructor:a,r=n?Di(n):\"\";if(r)switch(r){case Pn:return L;case zn:return x;case Ln:return E;case On:return T;case An:return P}return t});var bi=ze?Ko:vl;function _i(e){var t=e&&e.constructor;return e===(\"function\"==typeof t&&t.prototype||Pe)}function wi(e){return e==e&&!Jo(e)}function xi(e,t){return function(n){return null!=n&&n[e]===t&&(t!==a||e in Se(n))}}function ki(e,t,n){return t=gn(t===a?e.length-1:t,0),function(){for(var a=arguments,i=-1,o=gn(a.length-t,0),u=r(o);++i<o;)u[i]=a[t+i];i=-1;for(var l=r(t+1);++i<t;)l[i]=a[i];return l[t]=n(u),kt(e,this,l)}}function Si(e,t){return t.length<2?e:wr(e,ea(t,0,-1))}function Ei(e,t){if((\"constructor\"!==t||\"function\"!=typeof e[t])&&\"__proto__\"!=t)return e[t]}var Ci=Pi(Zr),Ti=ct||function(e,t){return ft.setTimeout(e,t)},Mi=Pi(Xr);function Ni(e,t,n){var r=t+\"\";return Mi(e,function(e,t){var n=t.length;if(!n)return e;var r=n-1;return t[r]=(n>1?\"& \":\"\")+t[r],t=t.join(n>2?\", \":\" \"),e.replace(ie,\"{\\n/* [wrapped with \"+t+\"] */\\n\")}(r,function(e,t){return Et(h,(function(n){var r=\"_.\"+n[0];t&n[1]&&!Nt(e,r)&&e.push(r)})),e.sort()}(function(e){var t=e.match(oe);return t?t[1].split(ue):[]}(r),n)))}function Pi(e){var t=0,n=0;return function(){var r=mn(),i=16-(r-n);if(n=r,i>0){if(++t>=800)return arguments[0]}else t=0;return e.apply(a,arguments)}}function zi(e,t){var n=-1,r=e.length,i=r-1;for(t=t===a?r:t;++n<t;){var o=Hr(n,i),u=e[o];e[o]=e[n],e[n]=u}return e.length=t,e}var Li,Oi,Ai=(Li=Oo((function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(\"\"),e.replace(ee,(function(e,n,r,a){t.push(r?a.replace(ce,\"$1\"):n||e)})),t}),(function(e){return 500===Oi.size&&Oi.clear(),e})),Oi=Li.cache,Li);function Fi(e){if(\"string\"==typeof e||uu(e))return e;var t=e+\"\";return\"0\"==t&&1/e==-1/0?\"-0\":t}function Di(e){if(null!=e){try{return Le.call(e)}catch(e){}try{return e+\"\"}catch(e){}}return\"\"}function Ri(e){if(e instanceof Bn)return e.clone();var t=new $n(e.__wrapped__,e.__chain__);return t.__actions__=Ca(e.__actions__),t.__index__=e.__index__,t.__values__=e.__values__,t}var ji=Qr((function(e,t){return qo(e)?sr(e,vr(t,1,qo,!0)):[]})),Ui=Qr((function(e,t){var n=Yi(t);return qo(n)&&(n=a),qo(e)?sr(e,vr(t,1,qo,!0),ii(n,2)):[]})),Ii=Qr((function(e,t){var n=Yi(t);return qo(n)&&(n=a),qo(e)?sr(e,vr(t,1,qo,!0),a,n):[]}));function $i(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var a=null==n?0:du(n);return a<0&&(a=gn(r+a,0)),jt(e,ii(t,3),a)}function Bi(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var i=r-1;return n!==a&&(i=du(n),i=n<0?gn(r+i,0):yn(i,r-1)),jt(e,ii(t,3),i,!0)}function Wi(e){return null!=e&&e.length?vr(e,1):[]}function Vi(e){return e&&e.length?e[0]:a}var Hi=Qr((function(e){var t=zt(e,ha);return t.length&&t[0]===e[0]?Tr(t):[]})),qi=Qr((function(e){var t=Yi(e),n=zt(e,ha);return t===Yi(n)?t=a:n.pop(),n.length&&n[0]===e[0]?Tr(n,ii(t,2)):[]})),Qi=Qr((function(e){var t=Yi(e),n=zt(e,ha);return(t=\"function\"==typeof t?t:a)&&n.pop(),n.length&&n[0]===e[0]?Tr(n,a,t):[]}));function Yi(e){var t=null==e?0:e.length;return t?e[t-1]:a}var Gi=Qr(Ki);function Ki(e,t){return e&&e.length&&t&&t.length?Wr(e,t):e}var Zi=Ja((function(e,t){var n=null==e?0:e.length,r=ar(e,t);return Vr(e,zt(t,(function(e){return vi(e,n)?+e:e})).sort(ka)),r}));function Xi(e){return null==e?e:wn.call(e)}var Ji=Qr((function(e){return ua(vr(e,1,qo,!0))})),eo=Qr((function(e){var t=Yi(e);return qo(t)&&(t=a),ua(vr(e,1,qo,!0),ii(t,2))})),to=Qr((function(e){var t=Yi(e);return t=\"function\"==typeof t?t:a,ua(vr(e,1,qo,!0),a,t)}));function no(e){if(!e||!e.length)return[];var t=0;return e=Mt(e,(function(e){if(qo(e))return t=gn(e.length,t),!0})),Qt(t,(function(t){return zt(e,Wt(t))}))}function ro(e,t){if(!e||!e.length)return[];var n=no(e);return null==t?n:zt(n,(function(e){return kt(t,a,e)}))}var ao=Qr((function(e,t){return qo(e)?sr(e,t):[]})),io=Qr((function(e){return pa(Mt(e,qo))})),oo=Qr((function(e){var t=Yi(e);return qo(t)&&(t=a),pa(Mt(e,qo),ii(t,2))})),uo=Qr((function(e){var t=Yi(e);return t=\"function\"==typeof t?t:a,pa(Mt(e,qo),a,t)})),lo=Qr(no),so=Qr((function(e){var t=e.length,n=t>1?e[t-1]:a;return n=\"function\"==typeof n?(e.pop(),n):a,ro(e,n)}));function co(e){var t=jn(e);return t.__chain__=!0,t}function fo(e,t){return t(e)}var po=Ja((function(e){var t=e.length,n=t?e[0]:0,r=this.__wrapped__,i=function(t){return ar(t,e)};return!(t>1||this.__actions__.length)&&r instanceof Bn&&vi(n)?((r=r.slice(n,+n+(t?1:0))).__actions__.push({func:fo,args:[i],thisArg:a}),new $n(r,this.__chain__).thru((function(e){return t&&!e.length&&e.push(a),e}))):this.thru(i)})),ho=Ma((function(e,t,n){Oe.call(e,n)?++e[n]:rr(e,n,1)})),vo=Fa($i),go=Fa(Bi);function yo(e,t){return(Wo(e)?Et:cr)(e,ii(t,3))}function mo(e,t){return(Wo(e)?Ct:fr)(e,ii(t,3))}var bo=Ma((function(e,t,n){Oe.call(e,n)?e[n].push(t):rr(e,n,[t])})),_o=Qr((function(e,t,n){var a=-1,i=\"function\"==typeof t,o=Ho(e)?r(e.length):[];return cr(e,(function(e){o[++a]=i?kt(t,e,n):Mr(e,t,n)})),o})),wo=Ma((function(e,t,n){rr(e,n,t)}));function xo(e,t){return(Wo(e)?zt:Dr)(e,ii(t,3))}var ko=Ma((function(e,t,n){e[n?0:1].push(t)}),(function(){return[[],[]]})),So=Qr((function(e,t){if(null==e)return[];var n=t.length;return n>1&&gi(e,t[0],t[1])?t=[]:n>2&&gi(t[0],t[1],t[2])&&(t=[t[0]]),$r(e,vr(t,1),[])})),Eo=st||function(){return ft.Date.now()};function Co(e,t,n){return t=n?a:t,t=e&&null==t?e.length:t,Ya(e,s,a,a,a,a,t)}function To(e,t){var n;if(\"function\"!=typeof t)throw new Te(i);return e=du(e),function(){return--e>0&&(n=t.apply(this,arguments)),e<=1&&(t=a),n}}var Mo=Qr((function(e,t,n){var r=1;if(n.length){var a=un(n,ai(Mo));r|=l}return Ya(e,r,t,n,a)})),No=Qr((function(e,t,n){var r=3;if(n.length){var a=un(n,ai(No));r|=l}return Ya(t,r,e,n,a)}));function Po(e,t,n){var r,o,u,l,s,c,f=0,p=!1,d=!1,h=!0;if(\"function\"!=typeof e)throw new Te(i);function v(t){var n=r,i=o;return r=o=a,f=t,l=e.apply(i,n)}function g(e){var n=e-c;return c===a||n>=t||n<0||d&&e-f>=u}function y(){var e=Eo();if(g(e))return m(e);s=Ti(y,function(e){var n=t-(e-c);return d?yn(n,u-(e-f)):n}(e))}function m(e){return s=a,h&&r?v(e):(r=o=a,l)}function b(){var e=Eo(),n=g(e);if(r=arguments,o=this,c=e,n){if(s===a)return function(e){return f=e,s=Ti(y,t),p?v(e):l}(c);if(d)return ba(s),s=Ti(y,t),v(c)}return s===a&&(s=Ti(y,t)),l}return t=vu(t)||0,Jo(n)&&(p=!!n.leading,u=(d=\"maxWait\"in n)?gn(vu(n.maxWait)||0,t):u,h=\"trailing\"in n?!!n.trailing:h),b.cancel=function(){s!==a&&ba(s),f=0,r=c=o=s=a},b.flush=function(){return s===a?l:m(Eo())},b}var zo=Qr((function(e,t){return lr(e,1,t)})),Lo=Qr((function(e,t,n){return lr(e,vu(t)||0,n)}));function Oo(e,t){if(\"function\"!=typeof e||null!=t&&\"function\"!=typeof t)throw new Te(i);var n=function(){var r=arguments,a=t?t.apply(this,r):r[0],i=n.cache;if(i.has(a))return i.get(a);var o=e.apply(this,r);return n.cache=i.set(a,o)||i,o};return n.cache=new(Oo.Cache||Hn),n}function Ao(e){if(\"function\"!=typeof e)throw new Te(i);return function(){var t=arguments;switch(t.length){case 0:return!e.call(this);case 1:return!e.call(this,t[0]);case 2:return!e.call(this,t[0],t[1]);case 3:return!e.call(this,t[0],t[1],t[2])}return!e.apply(this,t)}}Oo.Cache=Hn;var Fo=ya((function(e,t){var n=(t=1==t.length&&Wo(t[0])?zt(t[0],Gt(ii())):zt(vr(t,1),Gt(ii()))).length;return Qr((function(r){for(var a=-1,i=yn(r.length,n);++a<i;)r[a]=t[a].call(this,r[a]);return kt(e,this,r)}))})),Do=Qr((function(e,t){var n=un(t,ai(Do));return Ya(e,l,a,t,n)})),Ro=Qr((function(e,t){var n=un(t,ai(Ro));return Ya(e,64,a,t,n)})),jo=Ja((function(e,t){return Ya(e,256,a,a,a,t)}));function Uo(e,t){return e===t||e!=e&&t!=t}var Io=Wa(Sr),$o=Wa((function(e,t){return e>=t})),Bo=Nr(function(){return arguments}())?Nr:function(e){return eu(e)&&Oe.call(e,\"callee\")&&!qe.call(e,\"callee\")},Wo=r.isArray,Vo=yt?Gt(yt):function(e){return eu(e)&&kr(e)==z};function Ho(e){return null!=e&&Xo(e.length)&&!Ko(e)}function qo(e){return eu(e)&&Ho(e)}var Qo=gt||vl,Yo=mt?Gt(mt):function(e){return eu(e)&&kr(e)==m};function Go(e){if(!eu(e))return!1;var t=kr(e);return t==b||\"[object DOMException]\"==t||\"string\"==typeof e.message&&\"string\"==typeof e.name&&!ru(e)}function Ko(e){if(!Jo(e))return!1;var t=kr(e);return t==_||t==w||\"[object AsyncFunction]\"==t||\"[object Proxy]\"==t}function Zo(e){return\"number\"==typeof e&&e==du(e)}function Xo(e){return\"number\"==typeof e&&e>-1&&e%1==0&&e<=f}function Jo(e){var t=typeof e;return null!=e&&(\"object\"==t||\"function\"==t)}function eu(e){return null!=e&&\"object\"==typeof e}var tu=bt?Gt(bt):function(e){return eu(e)&&fi(e)==x};function nu(e){return\"number\"==typeof e||eu(e)&&kr(e)==k}function ru(e){if(!eu(e)||kr(e)!=S)return!1;var t=Ve(e);if(null===t)return!0;var n=Oe.call(t,\"constructor\")&&t.constructor;return\"function\"==typeof n&&n instanceof n&&Le.call(n)==Re}var au=_t?Gt(_t):function(e){return eu(e)&&kr(e)==C},iu=wt?Gt(wt):function(e){return eu(e)&&fi(e)==T};function ou(e){return\"string\"==typeof e||!Wo(e)&&eu(e)&&kr(e)==M}function uu(e){return\"symbol\"==typeof e||eu(e)&&kr(e)==N}var lu=xt?Gt(xt):function(e){return eu(e)&&Xo(e.length)&&!!at[kr(e)]},su=Wa(Fr),cu=Wa((function(e,t){return e<=t}));function fu(e){if(!e)return[];if(Ho(e))return ou(e)?fn(e):Ca(e);if(Ge&&e[Ge])return function(e){for(var t,n=[];!(t=e.next()).done;)n.push(t.value);return n}(e[Ge]());var t=fi(e);return(t==x?an:t==T?ln:Uu)(e)}function pu(e){return e?(e=vu(e))===c||e===-1/0?17976931348623157e292*(e<0?-1:1):e==e?e:0:0===e?e:0}function du(e){var t=pu(e),n=t%1;return t==t?n?t-n:t:0}function hu(e){return e?ir(du(e),0,d):0}function vu(e){if(\"number\"==typeof e)return e;if(uu(e))return p;if(Jo(e)){var t=\"function\"==typeof e.valueOf?e.valueOf():e;e=Jo(t)?t+\"\":t}if(\"string\"!=typeof e)return 0===e?e:+e;e=Yt(e);var n=he.test(e);return n||ge.test(e)?lt(e.slice(2),n?2:8):de.test(e)?p:+e}function gu(e){return Ta(e,zu(e))}function yu(e){return null==e?\"\":oa(e)}var mu=Na((function(e,t){if(_i(t)||Ho(t))Ta(t,Pu(t),e);else for(var n in t)Oe.call(t,n)&&Jn(e,n,t[n])})),bu=Na((function(e,t){Ta(t,zu(t),e)})),_u=Na((function(e,t,n,r){Ta(t,zu(t),e,r)})),wu=Na((function(e,t,n,r){Ta(t,Pu(t),e,r)})),xu=Ja(ar),ku=Qr((function(e,t){e=Se(e);var n=-1,r=t.length,i=r>2?t[2]:a;for(i&&gi(t[0],t[1],i)&&(r=1);++n<r;)for(var o=t[n],u=zu(o),l=-1,s=u.length;++l<s;){var c=u[l],f=e[c];(f===a||Uo(f,Pe[c])&&!Oe.call(e,c))&&(e[c]=o[c])}return e})),Su=Qr((function(e){return e.push(a,Ka),kt(Ou,a,e)}));function Eu(e,t,n){var r=null==e?a:wr(e,t);return r===a?n:r}function Cu(e,t){return null!=e&&pi(e,t,Cr)}var Tu=ja((function(e,t,n){null!=t&&\"function\"!=typeof t.toString&&(t=De.call(t)),e[t]=n}),Ju(nl)),Mu=ja((function(e,t,n){null!=t&&\"function\"!=typeof t.toString&&(t=De.call(t)),Oe.call(e,t)?e[t].push(n):e[t]=[n]}),ii),Nu=Qr(Mr);function Pu(e){return Ho(e)?Yn(e):Ar(e)}function zu(e){return Ho(e)?Yn(e,!0):function(e){if(!Jo(e))return function(e){var t=[];if(null!=e)for(var n in Se(e))t.push(n);return t}(e);var t=_i(e),n=[];for(var r in e)(\"constructor\"!=r||!t&&Oe.call(e,r))&&n.push(r);return n}(e)}var Lu=Na((function(e,t,n){Ur(e,t,n)})),Ou=Na((function(e,t,n,r){Ur(e,t,n,r)})),Au=Ja((function(e,t){var n={};if(null==e)return n;var r=!1;t=zt(t,(function(t){return t=ga(t,e),r||(r=t.length>1),t})),Ta(e,ti(e),n),r&&(n=or(n,7,Za));for(var a=t.length;a--;)la(n,t[a]);return n})),Fu=Ja((function(e,t){return null==e?{}:function(e,t){return Br(e,t,(function(t,n){return Cu(e,n)}))}(e,t)}));function Du(e,t){if(null==e)return{};var n=zt(ti(e),(function(e){return[e]}));return t=ii(t),Br(e,n,(function(e,n){return t(e,n[0])}))}var Ru=Qa(Pu),ju=Qa(zu);function Uu(e){return null==e?[]:Kt(e,Pu(e))}var Iu=Oa((function(e,t,n){return t=t.toLowerCase(),e+(n?$u(t):t)}));function $u(e){return Gu(yu(e).toLowerCase())}function Bu(e){return(e=yu(e))&&e.replace(me,en).replace(Ze,\"\")}var Wu=Oa((function(e,t,n){return e+(n?\"-\":\"\")+t.toLowerCase()})),Vu=Oa((function(e,t,n){return e+(n?\" \":\"\")+t.toLowerCase()})),Hu=La(\"toLowerCase\"),qu=Oa((function(e,t,n){return e+(n?\"_\":\"\")+t.toLowerCase()})),Qu=Oa((function(e,t,n){return e+(n?\" \":\"\")+Gu(t)})),Yu=Oa((function(e,t,n){return e+(n?\" \":\"\")+t.toUpperCase()})),Gu=La(\"toUpperCase\");function Ku(e,t,n){return e=yu(e),(t=n?a:t)===a?function(e){return tt.test(e)}(e)?function(e){return e.match(Je)||[]}(e):function(e){return e.match(le)||[]}(e):e.match(t)||[]}var Zu=Qr((function(e,t){try{return kt(e,a,t)}catch(e){return Go(e)?e:new we(e)}})),Xu=Ja((function(e,t){return Et(t,(function(t){t=Fi(t),rr(e,t,Mo(e[t],e))})),e}));function Ju(e){return function(){return e}}var el=Da(),tl=Da(!0);function nl(e){return e}function rl(e){return Or(\"function\"==typeof e?e:or(e,1))}var al=Qr((function(e,t){return function(n){return Mr(n,e,t)}})),il=Qr((function(e,t){return function(n){return Mr(e,n,t)}}));function ol(e,t,n){var r=Pu(t),a=_r(t,r);null!=n||Jo(t)&&(a.length||!r.length)||(n=t,t=e,e=this,a=_r(t,Pu(t)));var i=!(Jo(n)&&\"chain\"in n&&!n.chain),o=Ko(e);return Et(a,(function(n){var r=t[n];e[n]=r,o&&(e.prototype[n]=function(){var t=this.__chain__;if(i||t){var n=e(this.__wrapped__);return(n.__actions__=Ca(this.__actions__)).push({func:r,args:arguments,thisArg:e}),n.__chain__=t,n}return r.apply(e,Lt([this.value()],arguments))})})),e}function ul(){}var ll=Ia(zt),sl=Ia(Tt),cl=Ia(Ft);function fl(e){return yi(e)?Wt(Fi(e)):function(e){return function(t){return wr(t,e)}}(e)}var pl=Ba(),dl=Ba(!0);function hl(){return[]}function vl(){return!1}var gl,yl=Ua((function(e,t){return e+t}),0),ml=Ha(\"ceil\"),bl=Ua((function(e,t){return e/t}),1),_l=Ha(\"floor\"),wl=Ua((function(e,t){return e*t}),1),xl=Ha(\"round\"),kl=Ua((function(e,t){return e-t}),0);return jn.after=function(e,t){if(\"function\"!=typeof t)throw new Te(i);return e=du(e),function(){if(--e<1)return t.apply(this,arguments)}},jn.ary=Co,jn.assign=mu,jn.assignIn=bu,jn.assignInWith=_u,jn.assignWith=wu,jn.at=xu,jn.before=To,jn.bind=Mo,jn.bindAll=Xu,jn.bindKey=No,jn.castArray=function(){if(!arguments.length)return[];var e=arguments[0];return Wo(e)?e:[e]},jn.chain=co,jn.chunk=function(e,t,n){t=(n?gi(e,t,n):t===a)?1:gn(du(t),0);var i=null==e?0:e.length;if(!i||t<1)return[];for(var o=0,u=0,l=r(pt(i/t));o<i;)l[u++]=ea(e,o,o+=t);return l},jn.compact=function(e){for(var t=-1,n=null==e?0:e.length,r=0,a=[];++t<n;){var i=e[t];i&&(a[r++]=i)}return a},jn.concat=function(){var e=arguments.length;if(!e)return[];for(var t=r(e-1),n=arguments[0],a=e;a--;)t[a-1]=arguments[a];return Lt(Wo(n)?Ca(n):[n],vr(t,1))},jn.cond=function(e){var t=null==e?0:e.length,n=ii();return e=t?zt(e,(function(e){if(\"function\"!=typeof e[1])throw new Te(i);return[n(e[0]),e[1]]})):[],Qr((function(n){for(var r=-1;++r<t;){var a=e[r];if(kt(a[0],this,n))return kt(a[1],this,n)}}))},jn.conforms=function(e){return function(e){var t=Pu(e);return function(n){return ur(n,e,t)}}(or(e,1))},jn.constant=Ju,jn.countBy=ho,jn.create=function(e,t){var n=Un(e);return null==t?n:nr(n,t)},jn.curry=function e(t,n,r){var i=Ya(t,8,a,a,a,a,a,n=r?a:n);return i.placeholder=e.placeholder,i},jn.curryRight=function e(t,n,r){var i=Ya(t,16,a,a,a,a,a,n=r?a:n);return i.placeholder=e.placeholder,i},jn.debounce=Po,jn.defaults=ku,jn.defaultsDeep=Su,jn.defer=zo,jn.delay=Lo,jn.difference=ji,jn.differenceBy=Ui,jn.differenceWith=Ii,jn.drop=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,(t=n||t===a?1:du(t))<0?0:t,r):[]},jn.dropRight=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,0,(t=r-(t=n||t===a?1:du(t)))<0?0:t):[]},jn.dropRightWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!0,!0):[]},jn.dropWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!0):[]},jn.fill=function(e,t,n,r){var i=null==e?0:e.length;return i?(n&&\"number\"!=typeof n&&gi(e,t,n)&&(n=0,r=i),function(e,t,n,r){var i=e.length;for((n=du(n))<0&&(n=-n>i?0:i+n),(r=r===a||r>i?i:du(r))<0&&(r+=i),r=n>r?0:hu(r);n<r;)e[n++]=t;return e}(e,t,n,r)):[]},jn.filter=function(e,t){return(Wo(e)?Mt:hr)(e,ii(t,3))},jn.flatMap=function(e,t){return vr(xo(e,t),1)},jn.flatMapDeep=function(e,t){return vr(xo(e,t),c)},jn.flatMapDepth=function(e,t,n){return n=n===a?1:du(n),vr(xo(e,t),n)},jn.flatten=Wi,jn.flattenDeep=function(e){return null!=e&&e.length?vr(e,c):[]},jn.flattenDepth=function(e,t){return null!=e&&e.length?vr(e,t=t===a?1:du(t)):[]},jn.flip=function(e){return Ya(e,512)},jn.flow=el,jn.flowRight=tl,jn.fromPairs=function(e){for(var t=-1,n=null==e?0:e.length,r={};++t<n;){var a=e[t];r[a[0]]=a[1]}return r},jn.functions=function(e){return null==e?[]:_r(e,Pu(e))},jn.functionsIn=function(e){return null==e?[]:_r(e,zu(e))},jn.groupBy=bo,jn.initial=function(e){return null!=e&&e.length?ea(e,0,-1):[]},jn.intersection=Hi,jn.intersectionBy=qi,jn.intersectionWith=Qi,jn.invert=Tu,jn.invertBy=Mu,jn.invokeMap=_o,jn.iteratee=rl,jn.keyBy=wo,jn.keys=Pu,jn.keysIn=zu,jn.map=xo,jn.mapKeys=function(e,t){var n={};return t=ii(t,3),mr(e,(function(e,r,a){rr(n,t(e,r,a),e)})),n},jn.mapValues=function(e,t){var n={};return t=ii(t,3),mr(e,(function(e,r,a){rr(n,r,t(e,r,a))})),n},jn.matches=function(e){return Rr(or(e,1))},jn.matchesProperty=function(e,t){return jr(e,or(t,1))},jn.memoize=Oo,jn.merge=Lu,jn.mergeWith=Ou,jn.method=al,jn.methodOf=il,jn.mixin=ol,jn.negate=Ao,jn.nthArg=function(e){return e=du(e),Qr((function(t){return Ir(t,e)}))},jn.omit=Au,jn.omitBy=function(e,t){return Du(e,Ao(ii(t)))},jn.once=function(e){return To(2,e)},jn.orderBy=function(e,t,n,r){return null==e?[]:(Wo(t)||(t=null==t?[]:[t]),Wo(n=r?a:n)||(n=null==n?[]:[n]),$r(e,t,n))},jn.over=ll,jn.overArgs=Fo,jn.overEvery=sl,jn.overSome=cl,jn.partial=Do,jn.partialRight=Ro,jn.partition=ko,jn.pick=Fu,jn.pickBy=Du,jn.property=fl,jn.propertyOf=function(e){return function(t){return null==e?a:wr(e,t)}},jn.pull=Gi,jn.pullAll=Ki,jn.pullAllBy=function(e,t,n){return e&&e.length&&t&&t.length?Wr(e,t,ii(n,2)):e},jn.pullAllWith=function(e,t,n){return e&&e.length&&t&&t.length?Wr(e,t,a,n):e},jn.pullAt=Zi,jn.range=pl,jn.rangeRight=dl,jn.rearg=jo,jn.reject=function(e,t){return(Wo(e)?Mt:hr)(e,Ao(ii(t,3)))},jn.remove=function(e,t){var n=[];if(!e||!e.length)return n;var r=-1,a=[],i=e.length;for(t=ii(t,3);++r<i;){var o=e[r];t(o,r,e)&&(n.push(o),a.push(r))}return Vr(e,a),n},jn.rest=function(e,t){if(\"function\"!=typeof e)throw new Te(i);return Qr(e,t=t===a?t:du(t))},jn.reverse=Xi,jn.sampleSize=function(e,t,n){return t=(n?gi(e,t,n):t===a)?1:du(t),(Wo(e)?Kn:Gr)(e,t)},jn.set=function(e,t,n){return null==e?e:Kr(e,t,n)},jn.setWith=function(e,t,n,r){return r=\"function\"==typeof r?r:a,null==e?e:Kr(e,t,n,r)},jn.shuffle=function(e){return(Wo(e)?Zn:Jr)(e)},jn.slice=function(e,t,n){var r=null==e?0:e.length;return r?(n&&\"number\"!=typeof n&&gi(e,t,n)?(t=0,n=r):(t=null==t?0:du(t),n=n===a?r:du(n)),ea(e,t,n)):[]},jn.sortBy=So,jn.sortedUniq=function(e){return e&&e.length?aa(e):[]},jn.sortedUniqBy=function(e,t){return e&&e.length?aa(e,ii(t,2)):[]},jn.split=function(e,t,n){return n&&\"number\"!=typeof n&&gi(e,t,n)&&(t=n=a),(n=n===a?d:n>>>0)?(e=yu(e))&&(\"string\"==typeof t||null!=t&&!au(t))&&!(t=oa(t))&&rn(e)?ma(fn(e),0,n):e.split(t,n):[]},jn.spread=function(e,t){if(\"function\"!=typeof e)throw new Te(i);return t=null==t?0:gn(du(t),0),Qr((function(n){var r=n[t],a=ma(n,0,t);return r&&Lt(a,r),kt(e,this,a)}))},jn.tail=function(e){var t=null==e?0:e.length;return t?ea(e,1,t):[]},jn.take=function(e,t,n){return e&&e.length?ea(e,0,(t=n||t===a?1:du(t))<0?0:t):[]},jn.takeRight=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,(t=r-(t=n||t===a?1:du(t)))<0?0:t,r):[]},jn.takeRightWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!1,!0):[]},jn.takeWhile=function(e,t){return e&&e.length?ca(e,ii(t,3)):[]},jn.tap=function(e,t){return t(e),e},jn.throttle=function(e,t,n){var r=!0,a=!0;if(\"function\"!=typeof e)throw new Te(i);return Jo(n)&&(r=\"leading\"in n?!!n.leading:r,a=\"trailing\"in n?!!n.trailing:a),Po(e,t,{leading:r,maxWait:t,trailing:a})},jn.thru=fo,jn.toArray=fu,jn.toPairs=Ru,jn.toPairsIn=ju,jn.toPath=function(e){return Wo(e)?zt(e,Fi):uu(e)?[e]:Ca(Ai(yu(e)))},jn.toPlainObject=gu,jn.transform=function(e,t,n){var r=Wo(e),a=r||Qo(e)||lu(e);if(t=ii(t,4),null==n){var i=e&&e.constructor;n=a?r?new i:[]:Jo(e)&&Ko(i)?Un(Ve(e)):{}}return(a?Et:mr)(e,(function(e,r,a){return t(n,e,r,a)})),n},jn.unary=function(e){return Co(e,1)},jn.union=Ji,jn.unionBy=eo,jn.unionWith=to,jn.uniq=function(e){return e&&e.length?ua(e):[]},jn.uniqBy=function(e,t){return e&&e.length?ua(e,ii(t,2)):[]},jn.uniqWith=function(e,t){return t=\"function\"==typeof t?t:a,e&&e.length?ua(e,a,t):[]},jn.unset=function(e,t){return null==e||la(e,t)},jn.unzip=no,jn.unzipWith=ro,jn.update=function(e,t,n){return null==e?e:sa(e,t,va(n))},jn.updateWith=function(e,t,n,r){return r=\"function\"==typeof r?r:a,null==e?e:sa(e,t,va(n),r)},jn.values=Uu,jn.valuesIn=function(e){return null==e?[]:Kt(e,zu(e))},jn.without=ao,jn.words=Ku,jn.wrap=function(e,t){return Do(va(t),e)},jn.xor=io,jn.xorBy=oo,jn.xorWith=uo,jn.zip=lo,jn.zipObject=function(e,t){return da(e||[],t||[],Jn)},jn.zipObjectDeep=function(e,t){return da(e||[],t||[],Kr)},jn.zipWith=so,jn.entries=Ru,jn.entriesIn=ju,jn.extend=bu,jn.extendWith=_u,ol(jn,jn),jn.add=yl,jn.attempt=Zu,jn.camelCase=Iu,jn.capitalize=$u,jn.ceil=ml,jn.clamp=function(e,t,n){return n===a&&(n=t,t=a),n!==a&&(n=(n=vu(n))==n?n:0),t!==a&&(t=(t=vu(t))==t?t:0),ir(vu(e),t,n)},jn.clone=function(e){return or(e,4)},jn.cloneDeep=function(e){return or(e,5)},jn.cloneDeepWith=function(e,t){return or(e,5,t=\"function\"==typeof t?t:a)},jn.cloneWith=function(e,t){return or(e,4,t=\"function\"==typeof t?t:a)},jn.conformsTo=function(e,t){return null==t||ur(e,t,Pu(t))},jn.deburr=Bu,jn.defaultTo=function(e,t){return null==e||e!=e?t:e},jn.divide=bl,jn.endsWith=function(e,t,n){e=yu(e),t=oa(t);var r=e.length,i=n=n===a?r:ir(du(n),0,r);return(n-=t.length)>=0&&e.slice(n,i)==t},jn.eq=Uo,jn.escape=function(e){return(e=yu(e))&&Y.test(e)?e.replace(q,tn):e},jn.escapeRegExp=function(e){return(e=yu(e))&&ne.test(e)?e.replace(te,\"\\\\$&\"):e},jn.every=function(e,t,n){var r=Wo(e)?Tt:pr;return n&&gi(e,t,n)&&(t=a),r(e,ii(t,3))},jn.find=vo,jn.findIndex=$i,jn.findKey=function(e,t){return Rt(e,ii(t,3),mr)},jn.findLast=go,jn.findLastIndex=Bi,jn.findLastKey=function(e,t){return Rt(e,ii(t,3),br)},jn.floor=_l,jn.forEach=yo,jn.forEachRight=mo,jn.forIn=function(e,t){return null==e?e:gr(e,ii(t,3),zu)},jn.forInRight=function(e,t){return null==e?e:yr(e,ii(t,3),zu)},jn.forOwn=function(e,t){return e&&mr(e,ii(t,3))},jn.forOwnRight=function(e,t){return e&&br(e,ii(t,3))},jn.get=Eu,jn.gt=Io,jn.gte=$o,jn.has=function(e,t){return null!=e&&pi(e,t,Er)},jn.hasIn=Cu,jn.head=Vi,jn.identity=nl,jn.includes=function(e,t,n,r){e=Ho(e)?e:Uu(e),n=n&&!r?du(n):0;var a=e.length;return n<0&&(n=gn(a+n,0)),ou(e)?n<=a&&e.indexOf(t,n)>-1:!!a&&Ut(e,t,n)>-1},jn.indexOf=function(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var a=null==n?0:du(n);return a<0&&(a=gn(r+a,0)),Ut(e,t,a)},jn.inRange=function(e,t,n){return t=pu(t),n===a?(n=t,t=0):n=pu(n),function(e,t,n){return e>=yn(t,n)&&e<gn(t,n)}(e=vu(e),t,n)},jn.invoke=Nu,jn.isArguments=Bo,jn.isArray=Wo,jn.isArrayBuffer=Vo,jn.isArrayLike=Ho,jn.isArrayLikeObject=qo,jn.isBoolean=function(e){return!0===e||!1===e||eu(e)&&kr(e)==y},jn.isBuffer=Qo,jn.isDate=Yo,jn.isElement=function(e){return eu(e)&&1===e.nodeType&&!ru(e)},jn.isEmpty=function(e){if(null==e)return!0;if(Ho(e)&&(Wo(e)||\"string\"==typeof e||\"function\"==typeof e.splice||Qo(e)||lu(e)||Bo(e)))return!e.length;var t=fi(e);if(t==x||t==T)return!e.size;if(_i(e))return!Ar(e).length;for(var n in e)if(Oe.call(e,n))return!1;return!0},jn.isEqual=function(e,t){return Pr(e,t)},jn.isEqualWith=function(e,t,n){var r=(n=\"function\"==typeof n?n:a)?n(e,t):a;return r===a?Pr(e,t,a,n):!!r},jn.isError=Go,jn.isFinite=function(e){return\"number\"==typeof e&&Dt(e)},jn.isFunction=Ko,jn.isInteger=Zo,jn.isLength=Xo,jn.isMap=tu,jn.isMatch=function(e,t){return e===t||zr(e,t,ui(t))},jn.isMatchWith=function(e,t,n){return n=\"function\"==typeof n?n:a,zr(e,t,ui(t),n)},jn.isNaN=function(e){return nu(e)&&e!=+e},jn.isNative=function(e){if(bi(e))throw new we(\"Unsupported core-js use. Try https://npms.io/search?q=ponyfill.\");return Lr(e)},jn.isNil=function(e){return null==e},jn.isNull=function(e){return null===e},jn.isNumber=nu,jn.isObject=Jo,jn.isObjectLike=eu,jn.isPlainObject=ru,jn.isRegExp=au,jn.isSafeInteger=function(e){return Zo(e)&&e>=-9007199254740991&&e<=f},jn.isSet=iu,jn.isString=ou,jn.isSymbol=uu,jn.isTypedArray=lu,jn.isUndefined=function(e){return e===a},jn.isWeakMap=function(e){return eu(e)&&fi(e)==P},jn.isWeakSet=function(e){return eu(e)&&\"[object WeakSet]\"==kr(e)},jn.join=function(e,t){return null==e?\"\":Vt.call(e,t)},jn.kebabCase=Wu,jn.last=Yi,jn.lastIndexOf=function(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var i=r;return n!==a&&(i=(i=du(n))<0?gn(r+i,0):yn(i,r-1)),t==t?function(e,t,n){for(var r=n+1;r--;)if(e[r]===t)return r;return r}(e,t,i):jt(e,$t,i,!0)},jn.lowerCase=Vu,jn.lowerFirst=Hu,jn.lt=su,jn.lte=cu,jn.max=function(e){return e&&e.length?dr(e,nl,Sr):a},jn.maxBy=function(e,t){return e&&e.length?dr(e,ii(t,2),Sr):a},jn.mean=function(e){return Bt(e,nl)},jn.meanBy=function(e,t){return Bt(e,ii(t,2))},jn.min=function(e){return e&&e.length?dr(e,nl,Fr):a},jn.minBy=function(e,t){return e&&e.length?dr(e,ii(t,2),Fr):a},jn.stubArray=hl,jn.stubFalse=vl,jn.stubObject=function(){return{}},jn.stubString=function(){return\"\"},jn.stubTrue=function(){return!0},jn.multiply=wl,jn.nth=function(e,t){return e&&e.length?Ir(e,du(t)):a},jn.noConflict=function(){return ft._===this&&(ft._=je),this},jn.noop=ul,jn.now=Eo,jn.pad=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;if(!t||r>=t)return e;var a=(t-r)/2;return $a(dt(a),n)+e+$a(pt(a),n)},jn.padEnd=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;return t&&r<t?e+$a(t-r,n):e},jn.padStart=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;return t&&r<t?$a(t-r,n)+e:e},jn.parseInt=function(e,t,n){return n||null==t?t=0:t&&(t=+t),bn(yu(e).replace(re,\"\"),t||0)},jn.random=function(e,t,n){if(n&&\"boolean\"!=typeof n&&gi(e,t,n)&&(t=n=a),n===a&&(\"boolean\"==typeof t?(n=t,t=a):\"boolean\"==typeof e&&(n=e,e=a)),e===a&&t===a?(e=0,t=1):(e=pu(e),t===a?(t=e,e=0):t=pu(t)),e>t){var r=e;e=t,t=r}if(n||e%1||t%1){var i=_n();return yn(e+i*(t-e+ut(\"1e-\"+((i+\"\").length-1))),t)}return Hr(e,t)},jn.reduce=function(e,t,n){var r=Wo(e)?Ot:Ht,a=arguments.length<3;return r(e,ii(t,4),n,a,cr)},jn.reduceRight=function(e,t,n){var r=Wo(e)?At:Ht,a=arguments.length<3;return r(e,ii(t,4),n,a,fr)},jn.repeat=function(e,t,n){return t=(n?gi(e,t,n):t===a)?1:du(t),qr(yu(e),t)},jn.replace=function(){var e=arguments,t=yu(e[0]);return e.length<3?t:t.replace(e[1],e[2])},jn.result=function(e,t,n){var r=-1,i=(t=ga(t,e)).length;for(i||(i=1,e=a);++r<i;){var o=null==e?a:e[Fi(t[r])];o===a&&(r=i,o=n),e=Ko(o)?o.call(e):o}return e},jn.round=xl,jn.runInContext=e,jn.sample=function(e){return(Wo(e)?Gn:Yr)(e)},jn.size=function(e){if(null==e)return 0;if(Ho(e))return ou(e)?cn(e):e.length;var t=fi(e);return t==x||t==T?e.size:Ar(e).length},jn.snakeCase=qu,jn.some=function(e,t,n){var r=Wo(e)?Ft:ta;return n&&gi(e,t,n)&&(t=a),r(e,ii(t,3))},jn.sortedIndex=function(e,t){return na(e,t)},jn.sortedIndexBy=function(e,t,n){return ra(e,t,ii(n,2))},jn.sortedIndexOf=function(e,t){var n=null==e?0:e.length;if(n){var r=na(e,t);if(r<n&&Uo(e[r],t))return r}return-1},jn.sortedLastIndex=function(e,t){return na(e,t,!0)},jn.sortedLastIndexBy=function(e,t,n){return ra(e,t,ii(n,2),!0)},jn.sortedLastIndexOf=function(e,t){if(null!=e&&e.length){var n=na(e,t,!0)-1;if(Uo(e[n],t))return n}return-1},jn.startCase=Qu,jn.startsWith=function(e,t,n){return e=yu(e),n=null==n?0:ir(du(n),0,e.length),t=oa(t),e.slice(n,n+t.length)==t},jn.subtract=kl,jn.sum=function(e){return e&&e.length?qt(e,nl):0},jn.sumBy=function(e,t){return e&&e.length?qt(e,ii(t,2)):0},jn.template=function(e,t,n){var r=jn.templateSettings;n&&gi(e,t,n)&&(t=a),e=yu(e),t=_u({},t,r,Ga);var i,o,u=_u({},t.imports,r.imports,Ga),l=Pu(u),s=Kt(u,l),c=0,f=t.interpolate||be,p=\"__p += '\",d=Ee((t.escape||be).source+\"|\"+f.source+\"|\"+(f===Z?fe:be).source+\"|\"+(t.evaluate||be).source+\"|$\",\"g\"),h=\"//# sourceURL=\"+(Oe.call(t,\"sourceURL\")?(t.sourceURL+\"\").replace(/\\s/g,\" \"):\"lodash.templateSources[\"+ ++rt+\"]\")+\"\\n\";e.replace(d,(function(t,n,r,a,u,l){return r||(r=a),p+=e.slice(c,l).replace(_e,nn),n&&(i=!0,p+=\"' +\\n__e(\"+n+\") +\\n'\"),u&&(o=!0,p+=\"';\\n\"+u+\";\\n__p += '\"),r&&(p+=\"' +\\n((__t = (\"+r+\")) == null ? '' : __t) +\\n'\"),c=l+t.length,t})),p+=\"';\\n\";var v=Oe.call(t,\"variable\")&&t.variable;if(v){if(se.test(v))throw new we(\"Invalid `variable` option passed into `_.template`\")}else p=\"with (obj) {\\n\"+p+\"\\n}\\n\";p=(o?p.replace(B,\"\"):p).replace(W,\"$1\").replace(V,\"$1;\"),p=\"function(\"+(v||\"obj\")+\") {\\n\"+(v?\"\":\"obj || (obj = {});\\n\")+\"var __t, __p = ''\"+(i?\", __e = _.escape\":\"\")+(o?\", __j = Array.prototype.join;\\nfunction print() { __p += __j.call(arguments, '') }\\n\":\";\\n\")+p+\"return __p\\n}\";var g=Zu((function(){return xe(l,h+\"return \"+p).apply(a,s)}));if(g.source=p,Go(g))throw g;return g},jn.times=function(e,t){if((e=du(e))<1||e>f)return[];var n=d,r=yn(e,d);t=ii(t),e-=d;for(var a=Qt(r,t);++n<e;)t(n);return a},jn.toFinite=pu,jn.toInteger=du,jn.toLength=hu,jn.toLower=function(e){return yu(e).toLowerCase()},jn.toNumber=vu,jn.toSafeInteger=function(e){return e?ir(du(e),-9007199254740991,f):0===e?e:0},jn.toString=yu,jn.toUpper=function(e){return yu(e).toUpperCase()},jn.trim=function(e,t,n){if((e=yu(e))&&(n||t===a))return Yt(e);if(!e||!(t=oa(t)))return e;var r=fn(e),i=fn(t);return ma(r,Xt(r,i),Jt(r,i)+1).join(\"\")},jn.trimEnd=function(e,t,n){if((e=yu(e))&&(n||t===a))return e.slice(0,pn(e)+1);if(!e||!(t=oa(t)))return e;var r=fn(e);return ma(r,0,Jt(r,fn(t))+1).join(\"\")},jn.trimStart=function(e,t,n){if((e=yu(e))&&(n||t===a))return e.replace(re,\"\");if(!e||!(t=oa(t)))return e;var r=fn(e);return ma(r,Xt(r,fn(t))).join(\"\")},jn.truncate=function(e,t){var n=30,r=\"...\";if(Jo(t)){var i=\"separator\"in t?t.separator:i;n=\"length\"in t?du(t.length):n,r=\"omission\"in t?oa(t.omission):r}var o=(e=yu(e)).length;if(rn(e)){var u=fn(e);o=u.length}if(n>=o)return e;var l=n-cn(r);if(l<1)return r;var s=u?ma(u,0,l).join(\"\"):e.slice(0,l);if(i===a)return s+r;if(u&&(l+=s.length-l),au(i)){if(e.slice(l).search(i)){var c,f=s;for(i.global||(i=Ee(i.source,yu(pe.exec(i))+\"g\")),i.lastIndex=0;c=i.exec(f);)var p=c.index;s=s.slice(0,p===a?l:p)}}else if(e.indexOf(oa(i),l)!=l){var d=s.lastIndexOf(i);d>-1&&(s=s.slice(0,d))}return s+r},jn.unescape=function(e){return(e=yu(e))&&Q.test(e)?e.replace(H,dn):e},jn.uniqueId=function(e){var t=++Ae;return yu(e)+t},jn.upperCase=Yu,jn.upperFirst=Gu,jn.each=yo,jn.eachRight=mo,jn.first=Vi,ol(jn,(gl={},mr(jn,(function(e,t){Oe.call(jn.prototype,t)||(gl[t]=e)})),gl),{chain:!1}),jn.VERSION=\"4.17.21\",Et([\"bind\",\"bindKey\",\"curry\",\"curryRight\",\"partial\",\"partialRight\"],(function(e){jn[e].placeholder=jn})),Et([\"drop\",\"take\"],(function(e,t){Bn.prototype[e]=function(n){n=n===a?1:gn(du(n),0);var r=this.__filtered__&&!t?new Bn(this):this.clone();return r.__filtered__?r.__takeCount__=yn(n,r.__takeCount__):r.__views__.push({size:yn(n,d),type:e+(r.__dir__<0?\"Right\":\"\")}),r},Bn.prototype[e+\"Right\"]=function(t){return this.reverse()[e](t).reverse()}})),Et([\"filter\",\"map\",\"takeWhile\"],(function(e,t){var n=t+1,r=1==n||3==n;Bn.prototype[e]=function(e){var t=this.clone();return t.__iteratees__.push({iteratee:ii(e,3),type:n}),t.__filtered__=t.__filtered__||r,t}})),Et([\"head\",\"last\"],(function(e,t){var n=\"take\"+(t?\"Right\":\"\");Bn.prototype[e]=function(){return this[n](1).value()[0]}})),Et([\"initial\",\"tail\"],(function(e,t){var n=\"drop\"+(t?\"\":\"Right\");Bn.prototype[e]=function(){return this.__filtered__?new Bn(this):this[n](1)}})),Bn.prototype.compact=function(){return this.filter(nl)},Bn.prototype.find=function(e){return this.filter(e).head()},Bn.prototype.findLast=function(e){return this.reverse().find(e)},Bn.prototype.invokeMap=Qr((function(e,t){return\"function\"==typeof e?new Bn(this):this.map((function(n){return Mr(n,e,t)}))})),Bn.prototype.reject=function(e){return this.filter(Ao(ii(e)))},Bn.prototype.slice=function(e,t){e=du(e);var n=this;return n.__filtered__&&(e>0||t<0)?new Bn(n):(e<0?n=n.takeRight(-e):e&&(n=n.drop(e)),t!==a&&(n=(t=du(t))<0?n.dropRight(-t):n.take(t-e)),n)},Bn.prototype.takeRightWhile=function(e){return this.reverse().takeWhile(e).reverse()},Bn.prototype.toArray=function(){return this.take(d)},mr(Bn.prototype,(function(e,t){var n=/^(?:filter|find|map|reject)|While$/.test(t),r=/^(?:head|last)$/.test(t),i=jn[r?\"take\"+(\"last\"==t?\"Right\":\"\"):t],o=r||/^find/.test(t);i&&(jn.prototype[t]=function(){var t=this.__wrapped__,u=r?[1]:arguments,l=t instanceof Bn,s=u[0],c=l||Wo(t),f=function(e){var t=i.apply(jn,Lt([e],u));return r&&p?t[0]:t};c&&n&&\"function\"==typeof s&&1!=s.length&&(l=c=!1);var p=this.__chain__,d=!!this.__actions__.length,h=o&&!p,v=l&&!d;if(!o&&c){t=v?t:new Bn(this);var g=e.apply(t,u);return g.__actions__.push({func:fo,args:[f],thisArg:a}),new $n(g,p)}return h&&v?e.apply(this,u):(g=this.thru(f),h?r?g.value()[0]:g.value():g)})})),Et([\"pop\",\"push\",\"shift\",\"sort\",\"splice\",\"unshift\"],(function(e){var t=Me[e],n=/^(?:push|sort|unshift)$/.test(e)?\"tap\":\"thru\",r=/^(?:pop|shift)$/.test(e);jn.prototype[e]=function(){var e=arguments;if(r&&!this.__chain__){var a=this.value();return t.apply(Wo(a)?a:[],e)}return this[n]((function(n){return t.apply(Wo(n)?n:[],e)}))}})),mr(Bn.prototype,(function(e,t){var n=jn[t];if(n){var r=n.name+\"\";Oe.call(Nn,r)||(Nn[r]=[]),Nn[r].push({name:t,func:n})}})),Nn[Ra(a,2).name]=[{name:\"wrapper\",func:a}],Bn.prototype.clone=function(){var e=new Bn(this.__wrapped__);return e.__actions__=Ca(this.__actions__),e.__dir__=this.__dir__,e.__filtered__=this.__filtered__,e.__iteratees__=Ca(this.__iteratees__),e.__takeCount__=this.__takeCount__,e.__views__=Ca(this.__views__),e},Bn.prototype.reverse=function(){if(this.__filtered__){var e=new Bn(this);e.__dir__=-1,e.__filtered__=!0}else(e=this.clone()).__dir__*=-1;return e},Bn.prototype.value=function(){var e=this.__wrapped__.value(),t=this.__dir__,n=Wo(e),r=t<0,a=n?e.length:0,i=function(e,t,n){for(var r=-1,a=n.length;++r<a;){var i=n[r],o=i.size;switch(i.type){case\"drop\":e+=o;break;case\"dropRight\":t-=o;break;case\"take\":t=yn(t,e+o);break;case\"takeRight\":e=gn(e,t-o)}}return{start:e,end:t}}(0,a,this.__views__),o=i.start,u=i.end,l=u-o,s=r?u:o-1,c=this.__iteratees__,f=c.length,p=0,d=yn(l,this.__takeCount__);if(!n||!r&&a==l&&d==l)return fa(e,this.__actions__);var h=[];e:for(;l--&&p<d;){for(var v=-1,g=e[s+=t];++v<f;){var y=c[v],m=y.iteratee,b=y.type,_=m(g);if(2==b)g=_;else if(!_){if(1==b)continue e;break e}}h[p++]=g}return h},jn.prototype.at=po,jn.prototype.chain=function(){return co(this)},jn.prototype.commit=function(){return new $n(this.value(),this.__chain__)},jn.prototype.next=function(){this.__values__===a&&(this.__values__=fu(this.value()));var e=this.__index__>=this.__values__.length;return{done:e,value:e?a:this.__values__[this.__index__++]}},jn.prototype.plant=function(e){for(var t,n=this;n instanceof In;){var r=Ri(n);r.__index__=0,r.__values__=a,t?i.__wrapped__=r:t=r;var i=r;n=n.__wrapped__}return i.__wrapped__=e,t},jn.prototype.reverse=function(){var e=this.__wrapped__;if(e instanceof Bn){var t=e;return this.__actions__.length&&(t=new Bn(this)),(t=t.reverse()).__actions__.push({func:fo,args:[Xi],thisArg:a}),new $n(t,this.__chain__)}return this.thru(Xi)},jn.prototype.toJSON=jn.prototype.valueOf=jn.prototype.value=function(){return fa(this.__wrapped__,this.__actions__)},jn.prototype.first=jn.prototype.head,Ge&&(jn.prototype[Ge]=function(){return this}),jn}();ft._=hn,(r=function(){return hn}.call(t,n,t,e))===a||(e.exports=r)}.call(this)},448:(e,t,n)=>{\"use strict\";var r=n(294),a=n(840);function i(e){for(var t=\"https://reactjs.org/docs/error-decoder.html?invariant=\"+e,n=1;n<arguments.length;n++)t+=\"&args[]=\"+encodeURIComponent(arguments[n]);return\"Minified React error #\"+e+\"; visit \"+t+\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\"}var o=new Set,u={};function l(e,t){s(e,t),s(e+\"Capture\",t)}function s(e,t){for(u[e]=t,e=0;e<t.length;e++)o.add(t[e])}var c=!(\"undefined\"==typeof window||void 0===window.document||void 0===window.document.createElement),f=Object.prototype.hasOwnProperty,p=/^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$/,d={},h={};function v(e,t,n,r,a,i,o){this.acceptsBooleans=2===t||3===t||4===t,this.attributeName=r,this.attributeNamespace=a,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=i,this.removeEmptyString=o}var g={};\"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style\".split(\" \").forEach((function(e){g[e]=new v(e,0,!1,e,null,!1,!1)})),[[\"acceptCharset\",\"accept-charset\"],[\"className\",\"class\"],[\"htmlFor\",\"for\"],[\"httpEquiv\",\"http-equiv\"]].forEach((function(e){var t=e[0];g[t]=new v(t,1,!1,e[1],null,!1,!1)})),[\"contentEditable\",\"draggable\",\"spellCheck\",\"value\"].forEach((function(e){g[e]=new v(e,2,!1,e.toLowerCase(),null,!1,!1)})),[\"autoReverse\",\"externalResourcesRequired\",\"focusable\",\"preserveAlpha\"].forEach((function(e){g[e]=new v(e,2,!1,e,null,!1,!1)})),\"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope\".split(\" \").forEach((function(e){g[e]=new v(e,3,!1,e.toLowerCase(),null,!1,!1)})),[\"checked\",\"multiple\",\"muted\",\"selected\"].forEach((function(e){g[e]=new v(e,3,!0,e,null,!1,!1)})),[\"capture\",\"download\"].forEach((function(e){g[e]=new v(e,4,!1,e,null,!1,!1)})),[\"cols\",\"rows\",\"size\",\"span\"].forEach((function(e){g[e]=new v(e,6,!1,e,null,!1,!1)})),[\"rowSpan\",\"start\"].forEach((function(e){g[e]=new v(e,5,!1,e.toLowerCase(),null,!1,!1)}));var y=/[\\-:]([a-z])/g;function m(e){return e[1].toUpperCase()}function b(e,t,n,r){var a=g.hasOwnProperty(t)?g[t]:null;(null!==a?0!==a.type:r||!(2<t.length)||\"o\"!==t[0]&&\"O\"!==t[0]||\"n\"!==t[1]&&\"N\"!==t[1])&&(function(e,t,n,r){if(null==t||function(e,t,n,r){if(null!==n&&0===n.type)return!1;switch(typeof t){case\"function\":case\"symbol\":return!0;case\"boolean\":return!r&&(null!==n?!n.acceptsBooleans:\"data-\"!==(e=e.toLowerCase().slice(0,5))&&\"aria-\"!==e);default:return!1}}(e,t,n,r))return!0;if(r)return!1;if(null!==n)switch(n.type){case 3:return!t;case 4:return!1===t;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}(t,n,a,r)&&(n=null),r||null===a?function(e){return!!f.call(h,e)||!f.call(d,e)&&(p.test(e)?h[e]=!0:(d[e]=!0,!1))}(t)&&(null===n?e.removeAttribute(t):e.setAttribute(t,\"\"+n)):a.mustUseProperty?e[a.propertyName]=null===n?3!==a.type&&\"\":n:(t=a.attributeName,r=a.attributeNamespace,null===n?e.removeAttribute(t):(n=3===(a=a.type)||4===a&&!0===n?\"\":\"\"+n,r?e.setAttributeNS(r,t,n):e.setAttribute(t,n))))}\"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height\".split(\" \").forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,null,!1,!1)})),\"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type\".split(\" \").forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,\"http://www.w3.org/1999/xlink\",!1,!1)})),[\"xml:base\",\"xml:lang\",\"xml:space\"].forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,\"http://www.w3.org/XML/1998/namespace\",!1,!1)})),[\"tabIndex\",\"crossOrigin\"].forEach((function(e){g[e]=new v(e,1,!1,e.toLowerCase(),null,!1,!1)})),g.xlinkHref=new v(\"xlinkHref\",1,!1,\"xlink:href\",\"http://www.w3.org/1999/xlink\",!0,!1),[\"src\",\"href\",\"action\",\"formAction\"].forEach((function(e){g[e]=new v(e,1,!1,e.toLowerCase(),null,!0,!0)}));var _=r.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,w=Symbol.for(\"react.element\"),x=Symbol.for(\"react.portal\"),k=Symbol.for(\"react.fragment\"),S=Symbol.for(\"react.strict_mode\"),E=Symbol.for(\"react.profiler\"),C=Symbol.for(\"react.provider\"),T=Symbol.for(\"react.context\"),M=Symbol.for(\"react.forward_ref\"),N=Symbol.for(\"react.suspense\"),P=Symbol.for(\"react.suspense_list\"),z=Symbol.for(\"react.memo\"),L=Symbol.for(\"react.lazy\");Symbol.for(\"react.scope\"),Symbol.for(\"react.debug_trace_mode\");var O=Symbol.for(\"react.offscreen\");Symbol.for(\"react.legacy_hidden\"),Symbol.for(\"react.cache\"),Symbol.for(\"react.tracing_marker\");var A=Symbol.iterator;function F(e){return null===e||\"object\"!=typeof e?null:\"function\"==typeof(e=A&&e[A]||e[\"@@iterator\"])?e:null}var D,R=Object.assign;function j(e){if(void 0===D)try{throw Error()}catch(e){var t=e.stack.trim().match(/\\n( *(at )?)/);D=t&&t[1]||\"\"}return\"\\n\"+D+e}var U=!1;function I(e,t){if(!e||U)return\"\";U=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,\"props\",{set:function(){throw Error()}}),\"object\"==typeof Reflect&&Reflect.construct){try{Reflect.construct(t,[])}catch(e){var r=e}Reflect.construct(e,[],t)}else{try{t.call()}catch(e){r=e}e.call(t.prototype)}else{try{throw Error()}catch(e){r=e}e()}}catch(t){if(t&&r&&\"string\"==typeof t.stack){for(var a=t.stack.split(\"\\n\"),i=r.stack.split(\"\\n\"),o=a.length-1,u=i.length-1;1<=o&&0<=u&&a[o]!==i[u];)u--;for(;1<=o&&0<=u;o--,u--)if(a[o]!==i[u]){if(1!==o||1!==u)do{if(o--,0>--u||a[o]!==i[u]){var l=\"\\n\"+a[o].replace(\" at new \",\" at \");return e.displayName&&l.includes(\"<anonymous>\")&&(l=l.replace(\"<anonymous>\",e.displayName)),l}}while(1<=o&&0<=u);break}}}finally{U=!1,Error.prepareStackTrace=n}return(e=e?e.displayName||e.name:\"\")?j(e):\"\"}function $(e){switch(e.tag){case 5:return j(e.type);case 16:return j(\"Lazy\");case 13:return j(\"Suspense\");case 19:return j(\"SuspenseList\");case 0:case 2:case 15:return I(e.type,!1);case 11:return I(e.type.render,!1);case 1:return I(e.type,!0);default:return\"\"}}function B(e){if(null==e)return null;if(\"function\"==typeof e)return e.displayName||e.name||null;if(\"string\"==typeof e)return e;switch(e){case k:return\"Fragment\";case x:return\"Portal\";case E:return\"Profiler\";case S:return\"StrictMode\";case N:return\"Suspense\";case P:return\"SuspenseList\"}if(\"object\"==typeof e)switch(e.$$typeof){case T:return(e.displayName||\"Context\")+\".Consumer\";case C:return(e._context.displayName||\"Context\")+\".Provider\";case M:var t=e.render;return(e=e.displayName)||(e=\"\"!==(e=t.displayName||t.name||\"\")?\"ForwardRef(\"+e+\")\":\"ForwardRef\"),e;case z:return null!==(t=e.displayName||null)?t:B(e.type)||\"Memo\";case L:t=e._payload,e=e._init;try{return B(e(t))}catch(e){}}return null}function W(e){var t=e.type;switch(e.tag){case 24:return\"Cache\";case 9:return(t.displayName||\"Context\")+\".Consumer\";case 10:return(t._context.displayName||\"Context\")+\".Provider\";case 18:return\"DehydratedFragment\";case 11:return e=(e=t.render).displayName||e.name||\"\",t.displayName||(\"\"!==e?\"ForwardRef(\"+e+\")\":\"ForwardRef\");case 7:return\"Fragment\";case 5:return t;case 4:return\"Portal\";case 3:return\"Root\";case 6:return\"Text\";case 16:return B(t);case 8:return t===S?\"StrictMode\":\"Mode\";case 22:return\"Offscreen\";case 12:return\"Profiler\";case 21:return\"Scope\";case 13:return\"Suspense\";case 19:return\"SuspenseList\";case 25:return\"TracingMarker\";case 1:case 0:case 17:case 2:case 14:case 15:if(\"function\"==typeof t)return t.displayName||t.name||null;if(\"string\"==typeof t)return t}return null}function V(e){switch(typeof e){case\"boolean\":case\"number\":case\"string\":case\"undefined\":case\"object\":return e;default:return\"\"}}function H(e){var t=e.type;return(e=e.nodeName)&&\"input\"===e.toLowerCase()&&(\"checkbox\"===t||\"radio\"===t)}function q(e){e._valueTracker||(e._valueTracker=function(e){var t=H(e)?\"checked\":\"value\",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),r=\"\"+e[t];if(!e.hasOwnProperty(t)&&void 0!==n&&\"function\"==typeof n.get&&\"function\"==typeof n.set){var a=n.get,i=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return a.call(this)},set:function(e){r=\"\"+e,i.call(this,e)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return r},setValue:function(e){r=\"\"+e},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}(e))}function Q(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),r=\"\";return e&&(r=H(e)?e.checked?\"true\":\"false\":e.value),(e=r)!==n&&(t.setValue(e),!0)}function Y(e){if(void 0===(e=e||(\"undefined\"!=typeof document?document:void 0)))return null;try{return e.activeElement||e.body}catch(t){return e.body}}function G(e,t){var n=t.checked;return R({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=n?n:e._wrapperState.initialChecked})}function K(e,t){var n=null==t.defaultValue?\"\":t.defaultValue,r=null!=t.checked?t.checked:t.defaultChecked;n=V(null!=t.value?t.value:n),e._wrapperState={initialChecked:r,initialValue:n,controlled:\"checkbox\"===t.type||\"radio\"===t.type?null!=t.checked:null!=t.value}}function Z(e,t){null!=(t=t.checked)&&b(e,\"checked\",t,!1)}function X(e,t){Z(e,t);var n=V(t.value),r=t.type;if(null!=n)\"number\"===r?(0===n&&\"\"===e.value||e.value!=n)&&(e.value=\"\"+n):e.value!==\"\"+n&&(e.value=\"\"+n);else if(\"submit\"===r||\"reset\"===r)return void e.removeAttribute(\"value\");t.hasOwnProperty(\"value\")?ee(e,t.type,n):t.hasOwnProperty(\"defaultValue\")&&ee(e,t.type,V(t.defaultValue)),null==t.checked&&null!=t.defaultChecked&&(e.defaultChecked=!!t.defaultChecked)}function J(e,t,n){if(t.hasOwnProperty(\"value\")||t.hasOwnProperty(\"defaultValue\")){var r=t.type;if(!(\"submit\"!==r&&\"reset\"!==r||void 0!==t.value&&null!==t.value))return;t=\"\"+e._wrapperState.initialValue,n||t===e.value||(e.value=t),e.defaultValue=t}\"\"!==(n=e.name)&&(e.name=\"\"),e.defaultChecked=!!e._wrapperState.initialChecked,\"\"!==n&&(e.name=n)}function ee(e,t,n){\"number\"===t&&Y(e.ownerDocument)===e||(null==n?e.defaultValue=\"\"+e._wrapperState.initialValue:e.defaultValue!==\"\"+n&&(e.defaultValue=\"\"+n))}var te=Array.isArray;function ne(e,t,n,r){if(e=e.options,t){t={};for(var a=0;a<n.length;a++)t[\"$\"+n[a]]=!0;for(n=0;n<e.length;n++)a=t.hasOwnProperty(\"$\"+e[n].value),e[n].selected!==a&&(e[n].selected=a),a&&r&&(e[n].defaultSelected=!0)}else{for(n=\"\"+V(n),t=null,a=0;a<e.length;a++){if(e[a].value===n)return e[a].selected=!0,void(r&&(e[a].defaultSelected=!0));null!==t||e[a].disabled||(t=e[a])}null!==t&&(t.selected=!0)}}function re(e,t){if(null!=t.dangerouslySetInnerHTML)throw Error(i(91));return R({},t,{value:void 0,defaultValue:void 0,children:\"\"+e._wrapperState.initialValue})}function ae(e,t){var n=t.value;if(null==n){if(n=t.children,t=t.defaultValue,null!=n){if(null!=t)throw Error(i(92));if(te(n)){if(1<n.length)throw Error(i(93));n=n[0]}t=n}null==t&&(t=\"\"),n=t}e._wrapperState={initialValue:V(n)}}function ie(e,t){var n=V(t.value),r=V(t.defaultValue);null!=n&&((n=\"\"+n)!==e.value&&(e.value=n),null==t.defaultValue&&e.defaultValue!==n&&(e.defaultValue=n)),null!=r&&(e.defaultValue=\"\"+r)}function oe(e){var t=e.textContent;t===e._wrapperState.initialValue&&\"\"!==t&&null!==t&&(e.value=t)}function ue(e){switch(e){case\"svg\":return\"http://www.w3.org/2000/svg\";case\"math\":return\"http://www.w3.org/1998/Math/MathML\";default:return\"http://www.w3.org/1999/xhtml\"}}function le(e,t){return null==e||\"http://www.w3.org/1999/xhtml\"===e?ue(t):\"http://www.w3.org/2000/svg\"===e&&\"foreignObject\"===t?\"http://www.w3.org/1999/xhtml\":e}var se,ce,fe=(ce=function(e,t){if(\"http://www.w3.org/2000/svg\"!==e.namespaceURI||\"innerHTML\"in e)e.innerHTML=t;else{for((se=se||document.createElement(\"div\")).innerHTML=\"<svg>\"+t.valueOf().toString()+\"</svg>\",t=se.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}},\"undefined\"!=typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,t,n,r){MSApp.execUnsafeLocalFunction((function(){return ce(e,t)}))}:ce);function pe(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&3===n.nodeType)return void(n.nodeValue=t)}e.textContent=t}var de={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},he=[\"Webkit\",\"ms\",\"Moz\",\"O\"];function ve(e,t,n){return null==t||\"boolean\"==typeof t||\"\"===t?\"\":n||\"number\"!=typeof t||0===t||de.hasOwnProperty(e)&&de[e]?(\"\"+t).trim():t+\"px\"}function ge(e,t){for(var n in e=e.style,t)if(t.hasOwnProperty(n)){var r=0===n.indexOf(\"--\"),a=ve(n,t[n],r);\"float\"===n&&(n=\"cssFloat\"),r?e.setProperty(n,a):e[n]=a}}Object.keys(de).forEach((function(e){he.forEach((function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),de[t]=de[e]}))}));var ye=R({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function me(e,t){if(t){if(ye[e]&&(null!=t.children||null!=t.dangerouslySetInnerHTML))throw Error(i(137,e));if(null!=t.dangerouslySetInnerHTML){if(null!=t.children)throw Error(i(60));if(\"object\"!=typeof t.dangerouslySetInnerHTML||!(\"__html\"in t.dangerouslySetInnerHTML))throw Error(i(61))}if(null!=t.style&&\"object\"!=typeof t.style)throw Error(i(62))}}function be(e,t){if(-1===e.indexOf(\"-\"))return\"string\"==typeof t.is;switch(e){case\"annotation-xml\":case\"color-profile\":case\"font-face\":case\"font-face-src\":case\"font-face-uri\":case\"font-face-format\":case\"font-face-name\":case\"missing-glyph\":return!1;default:return!0}}var _e=null;function we(e){return(e=e.target||e.srcElement||window).correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}var xe=null,ke=null,Se=null;function Ee(e){if(e=ba(e)){if(\"function\"!=typeof xe)throw Error(i(280));var t=e.stateNode;t&&(t=wa(t),xe(e.stateNode,e.type,t))}}function Ce(e){ke?Se?Se.push(e):Se=[e]:ke=e}function Te(){if(ke){var e=ke,t=Se;if(Se=ke=null,Ee(e),t)for(e=0;e<t.length;e++)Ee(t[e])}}function Me(e,t){return e(t)}function Ne(){}var Pe=!1;function ze(e,t,n){if(Pe)return e(t,n);Pe=!0;try{return Me(e,t,n)}finally{Pe=!1,(null!==ke||null!==Se)&&(Ne(),Te())}}function Le(e,t){var n=e.stateNode;if(null===n)return null;var r=wa(n);if(null===r)return null;n=r[t];e:switch(t){case\"onClick\":case\"onClickCapture\":case\"onDoubleClick\":case\"onDoubleClickCapture\":case\"onMouseDown\":case\"onMouseDownCapture\":case\"onMouseMove\":case\"onMouseMoveCapture\":case\"onMouseUp\":case\"onMouseUpCapture\":case\"onMouseEnter\":(r=!r.disabled)||(r=!(\"button\"===(e=e.type)||\"input\"===e||\"select\"===e||\"textarea\"===e)),e=!r;break e;default:e=!1}if(e)return null;if(n&&\"function\"!=typeof n)throw Error(i(231,t,typeof n));return n}var Oe=!1;if(c)try{var Ae={};Object.defineProperty(Ae,\"passive\",{get:function(){Oe=!0}}),window.addEventListener(\"test\",Ae,Ae),window.removeEventListener(\"test\",Ae,Ae)}catch(ce){Oe=!1}function Fe(e,t,n,r,a,i,o,u,l){var s=Array.prototype.slice.call(arguments,3);try{t.apply(n,s)}catch(e){this.onError(e)}}var De=!1,Re=null,je=!1,Ue=null,Ie={onError:function(e){De=!0,Re=e}};function $e(e,t,n,r,a,i,o,u,l){De=!1,Re=null,Fe.apply(Ie,arguments)}function Be(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do{0!=(4098&(t=e).flags)&&(n=t.return),e=t.return}while(e)}return 3===t.tag?n:null}function We(e){if(13===e.tag){var t=e.memoizedState;if(null===t&&null!==(e=e.alternate)&&(t=e.memoizedState),null!==t)return t.dehydrated}return null}function Ve(e){if(Be(e)!==e)throw Error(i(188))}function He(e){return null!==(e=function(e){var t=e.alternate;if(!t){if(null===(t=Be(e)))throw Error(i(188));return t!==e?null:e}for(var n=e,r=t;;){var a=n.return;if(null===a)break;var o=a.alternate;if(null===o){if(null!==(r=a.return)){n=r;continue}break}if(a.child===o.child){for(o=a.child;o;){if(o===n)return Ve(a),e;if(o===r)return Ve(a),t;o=o.sibling}throw Error(i(188))}if(n.return!==r.return)n=a,r=o;else{for(var u=!1,l=a.child;l;){if(l===n){u=!0,n=a,r=o;break}if(l===r){u=!0,r=a,n=o;break}l=l.sibling}if(!u){for(l=o.child;l;){if(l===n){u=!0,n=o,r=a;break}if(l===r){u=!0,r=o,n=a;break}l=l.sibling}if(!u)throw Error(i(189))}}if(n.alternate!==r)throw Error(i(190))}if(3!==n.tag)throw Error(i(188));return n.stateNode.current===n?e:t}(e))?qe(e):null}function qe(e){if(5===e.tag||6===e.tag)return e;for(e=e.child;null!==e;){var t=qe(e);if(null!==t)return t;e=e.sibling}return null}var Qe=a.unstable_scheduleCallback,Ye=a.unstable_cancelCallback,Ge=a.unstable_shouldYield,Ke=a.unstable_requestPaint,Ze=a.unstable_now,Xe=a.unstable_getCurrentPriorityLevel,Je=a.unstable_ImmediatePriority,et=a.unstable_UserBlockingPriority,tt=a.unstable_NormalPriority,nt=a.unstable_LowPriority,rt=a.unstable_IdlePriority,at=null,it=null,ot=Math.clz32?Math.clz32:function(e){return 0===(e>>>=0)?32:31-(ut(e)/lt|0)|0},ut=Math.log,lt=Math.LN2,st=64,ct=4194304;function ft(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return 4194240&e;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return 130023424&e;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function pt(e,t){var n=e.pendingLanes;if(0===n)return 0;var r=0,a=e.suspendedLanes,i=e.pingedLanes,o=268435455&n;if(0!==o){var u=o&~a;0!==u?r=ft(u):0!=(i&=o)&&(r=ft(i))}else 0!=(o=n&~a)?r=ft(o):0!==i&&(r=ft(i));if(0===r)return 0;if(0!==t&&t!==r&&0==(t&a)&&((a=r&-r)>=(i=t&-t)||16===a&&0!=(4194240&i)))return t;if(0!=(4&r)&&(r|=16&n),0!==(t=e.entangledLanes))for(e=e.entanglements,t&=r;0<t;)a=1<<(n=31-ot(t)),r|=e[n],t&=~a;return r}function dt(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;default:return-1}}function ht(e){return 0!=(e=-1073741825&e.pendingLanes)?e:1073741824&e?1073741824:0}function vt(){var e=st;return 0==(4194240&(st<<=1))&&(st=64),e}function gt(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function yt(e,t,n){e.pendingLanes|=t,536870912!==t&&(e.suspendedLanes=0,e.pingedLanes=0),(e=e.eventTimes)[t=31-ot(t)]=n}function mt(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var r=31-ot(n),a=1<<r;a&t|e[r]&t&&(e[r]|=t),n&=~a}}var bt=0;function _t(e){return 1<(e&=-e)?4<e?0!=(268435455&e)?16:536870912:4:1}var wt,xt,kt,St,Et,Ct=!1,Tt=[],Mt=null,Nt=null,Pt=null,zt=new Map,Lt=new Map,Ot=[],At=\"mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit\".split(\" \");function Ft(e,t){switch(e){case\"focusin\":case\"focusout\":Mt=null;break;case\"dragenter\":case\"dragleave\":Nt=null;break;case\"mouseover\":case\"mouseout\":Pt=null;break;case\"pointerover\":case\"pointerout\":zt.delete(t.pointerId);break;case\"gotpointercapture\":case\"lostpointercapture\":Lt.delete(t.pointerId)}}function Dt(e,t,n,r,a,i){return null===e||e.nativeEvent!==i?(e={blockedOn:t,domEventName:n,eventSystemFlags:r,nativeEvent:i,targetContainers:[a]},null!==t&&null!==(t=ba(t))&&xt(t),e):(e.eventSystemFlags|=r,t=e.targetContainers,null!==a&&-1===t.indexOf(a)&&t.push(a),e)}function Rt(e){var t=ma(e.target);if(null!==t){var n=Be(t);if(null!==n)if(13===(t=n.tag)){if(null!==(t=We(n)))return e.blockedOn=t,void Et(e.priority,(function(){kt(n)}))}else if(3===t&&n.stateNode.current.memoizedState.isDehydrated)return void(e.blockedOn=3===n.tag?n.stateNode.containerInfo:null)}e.blockedOn=null}function jt(e){if(null!==e.blockedOn)return!1;for(var t=e.targetContainers;0<t.length;){var n=Gt(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(null!==n)return null!==(t=ba(n))&&xt(t),e.blockedOn=n,!1;var r=new(n=e.nativeEvent).constructor(n.type,n);_e=r,n.target.dispatchEvent(r),_e=null,t.shift()}return!0}function Ut(e,t,n){jt(e)&&n.delete(t)}function It(){Ct=!1,null!==Mt&&jt(Mt)&&(Mt=null),null!==Nt&&jt(Nt)&&(Nt=null),null!==Pt&&jt(Pt)&&(Pt=null),zt.forEach(Ut),Lt.forEach(Ut)}function $t(e,t){e.blockedOn===t&&(e.blockedOn=null,Ct||(Ct=!0,a.unstable_scheduleCallback(a.unstable_NormalPriority,It)))}function Bt(e){function t(t){return $t(t,e)}if(0<Tt.length){$t(Tt[0],e);for(var n=1;n<Tt.length;n++){var r=Tt[n];r.blockedOn===e&&(r.blockedOn=null)}}for(null!==Mt&&$t(Mt,e),null!==Nt&&$t(Nt,e),null!==Pt&&$t(Pt,e),zt.forEach(t),Lt.forEach(t),n=0;n<Ot.length;n++)(r=Ot[n]).blockedOn===e&&(r.blockedOn=null);for(;0<Ot.length&&null===(n=Ot[0]).blockedOn;)Rt(n),null===n.blockedOn&&Ot.shift()}var Wt=_.ReactCurrentBatchConfig,Vt=!0;function Ht(e,t,n,r){var a=bt,i=Wt.transition;Wt.transition=null;try{bt=1,Qt(e,t,n,r)}finally{bt=a,Wt.transition=i}}function qt(e,t,n,r){var a=bt,i=Wt.transition;Wt.transition=null;try{bt=4,Qt(e,t,n,r)}finally{bt=a,Wt.transition=i}}function Qt(e,t,n,r){if(Vt){var a=Gt(e,t,n,r);if(null===a)Vr(e,t,r,Yt,n),Ft(e,r);else if(function(e,t,n,r,a){switch(t){case\"focusin\":return Mt=Dt(Mt,e,t,n,r,a),!0;case\"dragenter\":return Nt=Dt(Nt,e,t,n,r,a),!0;case\"mouseover\":return Pt=Dt(Pt,e,t,n,r,a),!0;case\"pointerover\":var i=a.pointerId;return zt.set(i,Dt(zt.get(i)||null,e,t,n,r,a)),!0;case\"gotpointercapture\":return i=a.pointerId,Lt.set(i,Dt(Lt.get(i)||null,e,t,n,r,a)),!0}return!1}(a,e,t,n,r))r.stopPropagation();else if(Ft(e,r),4&t&&-1<At.indexOf(e)){for(;null!==a;){var i=ba(a);if(null!==i&&wt(i),null===(i=Gt(e,t,n,r))&&Vr(e,t,r,Yt,n),i===a)break;a=i}null!==a&&r.stopPropagation()}else Vr(e,t,r,null,n)}}var Yt=null;function Gt(e,t,n,r){if(Yt=null,null!==(e=ma(e=we(r))))if(null===(t=Be(e)))e=null;else if(13===(n=t.tag)){if(null!==(e=We(t)))return e;e=null}else if(3===n){if(t.stateNode.current.memoizedState.isDehydrated)return 3===t.tag?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Yt=e,null}function Kt(e){switch(e){case\"cancel\":case\"click\":case\"close\":case\"contextmenu\":case\"copy\":case\"cut\":case\"auxclick\":case\"dblclick\":case\"dragend\":case\"dragstart\":case\"drop\":case\"focusin\":case\"focusout\":case\"input\":case\"invalid\":case\"keydown\":case\"keypress\":case\"keyup\":case\"mousedown\":case\"mouseup\":case\"paste\":case\"pause\":case\"play\":case\"pointercancel\":case\"pointerdown\":case\"pointerup\":case\"ratechange\":case\"reset\":case\"resize\":case\"seeked\":case\"submit\":case\"touchcancel\":case\"touchend\":case\"touchstart\":case\"volumechange\":case\"change\":case\"selectionchange\":case\"textInput\":case\"compositionstart\":case\"compositionend\":case\"compositionupdate\":case\"beforeblur\":case\"afterblur\":case\"beforeinput\":case\"blur\":case\"fullscreenchange\":case\"focus\":case\"hashchange\":case\"popstate\":case\"select\":case\"selectstart\":return 1;case\"drag\":case\"dragenter\":case\"dragexit\":case\"dragleave\":case\"dragover\":case\"mousemove\":case\"mouseout\":case\"mouseover\":case\"pointermove\":case\"pointerout\":case\"pointerover\":case\"scroll\":case\"toggle\":case\"touchmove\":case\"wheel\":case\"mouseenter\":case\"mouseleave\":case\"pointerenter\":case\"pointerleave\":return 4;case\"message\":switch(Xe()){case Je:return 1;case et:return 4;case tt:case nt:return 16;case rt:return 536870912;default:return 16}default:return 16}}var Zt=null,Xt=null,Jt=null;function en(){if(Jt)return Jt;var e,t,n=Xt,r=n.length,a=\"value\"in Zt?Zt.value:Zt.textContent,i=a.length;for(e=0;e<r&&n[e]===a[e];e++);var o=r-e;for(t=1;t<=o&&n[r-t]===a[i-t];t++);return Jt=a.slice(e,1<t?1-t:void 0)}function tn(e){var t=e.keyCode;return\"charCode\"in e?0===(e=e.charCode)&&13===t&&(e=13):e=t,10===e&&(e=13),32<=e||13===e?e:0}function nn(){return!0}function rn(){return!1}function an(e){function t(t,n,r,a,i){for(var o in this._reactName=t,this._targetInst=r,this.type=n,this.nativeEvent=a,this.target=i,this.currentTarget=null,e)e.hasOwnProperty(o)&&(t=e[o],this[o]=t?t(a):a[o]);return this.isDefaultPrevented=(null!=a.defaultPrevented?a.defaultPrevented:!1===a.returnValue)?nn:rn,this.isPropagationStopped=rn,this}return R(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var e=this.nativeEvent;e&&(e.preventDefault?e.preventDefault():\"unknown\"!=typeof e.returnValue&&(e.returnValue=!1),this.isDefaultPrevented=nn)},stopPropagation:function(){var e=this.nativeEvent;e&&(e.stopPropagation?e.stopPropagation():\"unknown\"!=typeof e.cancelBubble&&(e.cancelBubble=!0),this.isPropagationStopped=nn)},persist:function(){},isPersistent:nn}),t}var on,un,ln,sn={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},cn=an(sn),fn=R({},sn,{view:0,detail:0}),pn=an(fn),dn=R({},fn,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:En,button:0,buttons:0,relatedTarget:function(e){return void 0===e.relatedTarget?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return\"movementX\"in e?e.movementX:(e!==ln&&(ln&&\"mousemove\"===e.type?(on=e.screenX-ln.screenX,un=e.screenY-ln.screenY):un=on=0,ln=e),on)},movementY:function(e){return\"movementY\"in e?e.movementY:un}}),hn=an(dn),vn=an(R({},dn,{dataTransfer:0})),gn=an(R({},fn,{relatedTarget:0})),yn=an(R({},sn,{animationName:0,elapsedTime:0,pseudoElement:0})),mn=R({},sn,{clipboardData:function(e){return\"clipboardData\"in e?e.clipboardData:window.clipboardData}}),bn=an(mn),_n=an(R({},sn,{data:0})),wn={Esc:\"Escape\",Spacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},xn={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"},kn={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};function Sn(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):!!(e=kn[e])&&!!t[e]}function En(){return Sn}var Cn=R({},fn,{key:function(e){if(e.key){var t=wn[e.key]||e.key;if(\"Unidentified\"!==t)return t}return\"keypress\"===e.type?13===(e=tn(e))?\"Enter\":String.fromCharCode(e):\"keydown\"===e.type||\"keyup\"===e.type?xn[e.keyCode]||\"Unidentified\":\"\"},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:En,charCode:function(e){return\"keypress\"===e.type?tn(e):0},keyCode:function(e){return\"keydown\"===e.type||\"keyup\"===e.type?e.keyCode:0},which:function(e){return\"keypress\"===e.type?tn(e):\"keydown\"===e.type||\"keyup\"===e.type?e.keyCode:0}}),Tn=an(Cn),Mn=an(R({},dn,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0})),Nn=an(R({},fn,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:En})),Pn=an(R({},sn,{propertyName:0,elapsedTime:0,pseudoElement:0})),zn=R({},dn,{deltaX:function(e){return\"deltaX\"in e?e.deltaX:\"wheelDeltaX\"in e?-e.wheelDeltaX:0},deltaY:function(e){return\"deltaY\"in e?e.deltaY:\"wheelDeltaY\"in e?-e.wheelDeltaY:\"wheelDelta\"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),Ln=an(zn),On=[9,13,27,32],An=c&&\"CompositionEvent\"in window,Fn=null;c&&\"documentMode\"in document&&(Fn=document.documentMode);var Dn=c&&\"TextEvent\"in window&&!Fn,Rn=c&&(!An||Fn&&8<Fn&&11>=Fn),jn=String.fromCharCode(32),Un=!1;function In(e,t){switch(e){case\"keyup\":return-1!==On.indexOf(t.keyCode);case\"keydown\":return 229!==t.keyCode;case\"keypress\":case\"mousedown\":case\"focusout\":return!0;default:return!1}}function $n(e){return\"object\"==typeof(e=e.detail)&&\"data\"in e?e.data:null}var Bn=!1,Wn={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function Vn(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return\"input\"===t?!!Wn[e.type]:\"textarea\"===t}function Hn(e,t,n,r){Ce(r),0<(t=qr(t,\"onChange\")).length&&(n=new cn(\"onChange\",\"change\",null,n,r),e.push({event:n,listeners:t}))}var qn=null,Qn=null;function Yn(e){jr(e,0)}function Gn(e){if(Q(_a(e)))return e}function Kn(e,t){if(\"change\"===e)return t}var Zn=!1;if(c){var Xn;if(c){var Jn=\"oninput\"in document;if(!Jn){var er=document.createElement(\"div\");er.setAttribute(\"oninput\",\"return;\"),Jn=\"function\"==typeof er.oninput}Xn=Jn}else Xn=!1;Zn=Xn&&(!document.documentMode||9<document.documentMode)}function tr(){qn&&(qn.detachEvent(\"onpropertychange\",nr),Qn=qn=null)}function nr(e){if(\"value\"===e.propertyName&&Gn(Qn)){var t=[];Hn(t,Qn,e,we(e)),ze(Yn,t)}}function rr(e,t,n){\"focusin\"===e?(tr(),Qn=n,(qn=t).attachEvent(\"onpropertychange\",nr)):\"focusout\"===e&&tr()}function ar(e){if(\"selectionchange\"===e||\"keyup\"===e||\"keydown\"===e)return Gn(Qn)}function ir(e,t){if(\"click\"===e)return Gn(t)}function or(e,t){if(\"input\"===e||\"change\"===e)return Gn(t)}var ur=\"function\"==typeof Object.is?Object.is:function(e,t){return e===t&&(0!==e||1/e==1/t)||e!=e&&t!=t};function lr(e,t){if(ur(e,t))return!0;if(\"object\"!=typeof e||null===e||\"object\"!=typeof t||null===t)return!1;var n=Object.keys(e),r=Object.keys(t);if(n.length!==r.length)return!1;for(r=0;r<n.length;r++){var a=n[r];if(!f.call(t,a)||!ur(e[a],t[a]))return!1}return!0}function sr(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function cr(e,t){var n,r=sr(e);for(e=0;r;){if(3===r.nodeType){if(n=e+r.textContent.length,e<=t&&n>=t)return{node:r,offset:t-e};e=n}e:{for(;r;){if(r.nextSibling){r=r.nextSibling;break e}r=r.parentNode}r=void 0}r=sr(r)}}function fr(e,t){return!(!e||!t)&&(e===t||(!e||3!==e.nodeType)&&(t&&3===t.nodeType?fr(e,t.parentNode):\"contains\"in e?e.contains(t):!!e.compareDocumentPosition&&!!(16&e.compareDocumentPosition(t))))}function pr(){for(var e=window,t=Y();t instanceof e.HTMLIFrameElement;){try{var n=\"string\"==typeof t.contentWindow.location.href}catch(e){n=!1}if(!n)break;t=Y((e=t.contentWindow).document)}return t}function dr(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(\"input\"===t&&(\"text\"===e.type||\"search\"===e.type||\"tel\"===e.type||\"url\"===e.type||\"password\"===e.type)||\"textarea\"===t||\"true\"===e.contentEditable)}function hr(e){var t=pr(),n=e.focusedElem,r=e.selectionRange;if(t!==n&&n&&n.ownerDocument&&fr(n.ownerDocument.documentElement,n)){if(null!==r&&dr(n))if(t=r.start,void 0===(e=r.end)&&(e=t),\"selectionStart\"in n)n.selectionStart=t,n.selectionEnd=Math.min(e,n.value.length);else if((e=(t=n.ownerDocument||document)&&t.defaultView||window).getSelection){e=e.getSelection();var a=n.textContent.length,i=Math.min(r.start,a);r=void 0===r.end?i:Math.min(r.end,a),!e.extend&&i>r&&(a=r,r=i,i=a),a=cr(n,i);var o=cr(n,r);a&&o&&(1!==e.rangeCount||e.anchorNode!==a.node||e.anchorOffset!==a.offset||e.focusNode!==o.node||e.focusOffset!==o.offset)&&((t=t.createRange()).setStart(a.node,a.offset),e.removeAllRanges(),i>r?(e.addRange(t),e.extend(o.node,o.offset)):(t.setEnd(o.node,o.offset),e.addRange(t)))}for(t=[],e=n;e=e.parentNode;)1===e.nodeType&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(\"function\"==typeof n.focus&&n.focus(),n=0;n<t.length;n++)(e=t[n]).element.scrollLeft=e.left,e.element.scrollTop=e.top}}var vr=c&&\"documentMode\"in document&&11>=document.documentMode,gr=null,yr=null,mr=null,br=!1;function _r(e,t,n){var r=n.window===n?n.document:9===n.nodeType?n:n.ownerDocument;br||null==gr||gr!==Y(r)||(r=\"selectionStart\"in(r=gr)&&dr(r)?{start:r.selectionStart,end:r.selectionEnd}:{anchorNode:(r=(r.ownerDocument&&r.ownerDocument.defaultView||window).getSelection()).anchorNode,anchorOffset:r.anchorOffset,focusNode:r.focusNode,focusOffset:r.focusOffset},mr&&lr(mr,r)||(mr=r,0<(r=qr(yr,\"onSelect\")).length&&(t=new cn(\"onSelect\",\"select\",null,t,n),e.push({event:t,listeners:r}),t.target=gr)))}function wr(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n[\"Webkit\"+e]=\"webkit\"+t,n[\"Moz\"+e]=\"moz\"+t,n}var xr={animationend:wr(\"Animation\",\"AnimationEnd\"),animationiteration:wr(\"Animation\",\"AnimationIteration\"),animationstart:wr(\"Animation\",\"AnimationStart\"),transitionend:wr(\"Transition\",\"TransitionEnd\")},kr={},Sr={};function Er(e){if(kr[e])return kr[e];if(!xr[e])return e;var t,n=xr[e];for(t in n)if(n.hasOwnProperty(t)&&t in Sr)return kr[e]=n[t];return e}c&&(Sr=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete xr.animationend.animation,delete xr.animationiteration.animation,delete xr.animationstart.animation),\"TransitionEvent\"in window||delete xr.transitionend.transition);var Cr=Er(\"animationend\"),Tr=Er(\"animationiteration\"),Mr=Er(\"animationstart\"),Nr=Er(\"transitionend\"),Pr=new Map,zr=\"abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel\".split(\" \");function Lr(e,t){Pr.set(e,t),l(t,[e])}for(var Or=0;Or<zr.length;Or++){var Ar=zr[Or];Lr(Ar.toLowerCase(),\"on\"+(Ar[0].toUpperCase()+Ar.slice(1)))}Lr(Cr,\"onAnimationEnd\"),Lr(Tr,\"onAnimationIteration\"),Lr(Mr,\"onAnimationStart\"),Lr(\"dblclick\",\"onDoubleClick\"),Lr(\"focusin\",\"onFocus\"),Lr(\"focusout\",\"onBlur\"),Lr(Nr,\"onTransitionEnd\"),s(\"onMouseEnter\",[\"mouseout\",\"mouseover\"]),s(\"onMouseLeave\",[\"mouseout\",\"mouseover\"]),s(\"onPointerEnter\",[\"pointerout\",\"pointerover\"]),s(\"onPointerLeave\",[\"pointerout\",\"pointerover\"]),l(\"onChange\",\"change click focusin focusout input keydown keyup selectionchange\".split(\" \")),l(\"onSelect\",\"focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange\".split(\" \")),l(\"onBeforeInput\",[\"compositionend\",\"keypress\",\"textInput\",\"paste\"]),l(\"onCompositionEnd\",\"compositionend focusout keydown keypress keyup mousedown\".split(\" \")),l(\"onCompositionStart\",\"compositionstart focusout keydown keypress keyup mousedown\".split(\" \")),l(\"onCompositionUpdate\",\"compositionupdate focusout keydown keypress keyup mousedown\".split(\" \"));var Fr=\"abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting\".split(\" \"),Dr=new Set(\"cancel close invalid load scroll toggle\".split(\" \").concat(Fr));function Rr(e,t,n){var r=e.type||\"unknown-event\";e.currentTarget=n,function(e,t,n,r,a,o,u,l,s){if($e.apply(this,arguments),De){if(!De)throw Error(i(198));var c=Re;De=!1,Re=null,je||(je=!0,Ue=c)}}(r,t,void 0,e),e.currentTarget=null}function jr(e,t){t=0!=(4&t);for(var n=0;n<e.length;n++){var r=e[n],a=r.event;r=r.listeners;e:{var i=void 0;if(t)for(var o=r.length-1;0<=o;o--){var u=r[o],l=u.instance,s=u.currentTarget;if(u=u.listener,l!==i&&a.isPropagationStopped())break e;Rr(a,u,s),i=l}else for(o=0;o<r.length;o++){if(l=(u=r[o]).instance,s=u.currentTarget,u=u.listener,l!==i&&a.isPropagationStopped())break e;Rr(a,u,s),i=l}}}if(je)throw e=Ue,je=!1,Ue=null,e}function Ur(e,t){var n=t[va];void 0===n&&(n=t[va]=new Set);var r=e+\"__bubble\";n.has(r)||(Wr(t,e,2,!1),n.add(r))}function Ir(e,t,n){var r=0;t&&(r|=4),Wr(n,e,r,t)}var $r=\"_reactListening\"+Math.random().toString(36).slice(2);function Br(e){if(!e[$r]){e[$r]=!0,o.forEach((function(t){\"selectionchange\"!==t&&(Dr.has(t)||Ir(t,!1,e),Ir(t,!0,e))}));var t=9===e.nodeType?e:e.ownerDocument;null===t||t[$r]||(t[$r]=!0,Ir(\"selectionchange\",!1,t))}}function Wr(e,t,n,r){switch(Kt(t)){case 1:var a=Ht;break;case 4:a=qt;break;default:a=Qt}n=a.bind(null,t,n,e),a=void 0,!Oe||\"touchstart\"!==t&&\"touchmove\"!==t&&\"wheel\"!==t||(a=!0),r?void 0!==a?e.addEventListener(t,n,{capture:!0,passive:a}):e.addEventListener(t,n,!0):void 0!==a?e.addEventListener(t,n,{passive:a}):e.addEventListener(t,n,!1)}function Vr(e,t,n,r,a){var i=r;if(0==(1&t)&&0==(2&t)&&null!==r)e:for(;;){if(null===r)return;var o=r.tag;if(3===o||4===o){var u=r.stateNode.containerInfo;if(u===a||8===u.nodeType&&u.parentNode===a)break;if(4===o)for(o=r.return;null!==o;){var l=o.tag;if((3===l||4===l)&&((l=o.stateNode.containerInfo)===a||8===l.nodeType&&l.parentNode===a))return;o=o.return}for(;null!==u;){if(null===(o=ma(u)))return;if(5===(l=o.tag)||6===l){r=i=o;continue e}u=u.parentNode}}r=r.return}ze((function(){var r=i,a=we(n),o=[];e:{var u=Pr.get(e);if(void 0!==u){var l=cn,s=e;switch(e){case\"keypress\":if(0===tn(n))break e;case\"keydown\":case\"keyup\":l=Tn;break;case\"focusin\":s=\"focus\",l=gn;break;case\"focusout\":s=\"blur\",l=gn;break;case\"beforeblur\":case\"afterblur\":l=gn;break;case\"click\":if(2===n.button)break e;case\"auxclick\":case\"dblclick\":case\"mousedown\":case\"mousemove\":case\"mouseup\":case\"mouseout\":case\"mouseover\":case\"contextmenu\":l=hn;break;case\"drag\":case\"dragend\":case\"dragenter\":case\"dragexit\":case\"dragleave\":case\"dragover\":case\"dragstart\":case\"drop\":l=vn;break;case\"touchcancel\":case\"touchend\":case\"touchmove\":case\"touchstart\":l=Nn;break;case Cr:case Tr:case Mr:l=yn;break;case Nr:l=Pn;break;case\"scroll\":l=pn;break;case\"wheel\":l=Ln;break;case\"copy\":case\"cut\":case\"paste\":l=bn;break;case\"gotpointercapture\":case\"lostpointercapture\":case\"pointercancel\":case\"pointerdown\":case\"pointermove\":case\"pointerout\":case\"pointerover\":case\"pointerup\":l=Mn}var c=0!=(4&t),f=!c&&\"scroll\"===e,p=c?null!==u?u+\"Capture\":null:u;c=[];for(var d,h=r;null!==h;){var v=(d=h).stateNode;if(5===d.tag&&null!==v&&(d=v,null!==p&&null!=(v=Le(h,p))&&c.push(Hr(h,v,d))),f)break;h=h.return}0<c.length&&(u=new l(u,s,null,n,a),o.push({event:u,listeners:c}))}}if(0==(7&t)){if(l=\"mouseout\"===e||\"pointerout\"===e,(!(u=\"mouseover\"===e||\"pointerover\"===e)||n===_e||!(s=n.relatedTarget||n.fromElement)||!ma(s)&&!s[ha])&&(l||u)&&(u=a.window===a?a:(u=a.ownerDocument)?u.defaultView||u.parentWindow:window,l?(l=r,null!==(s=(s=n.relatedTarget||n.toElement)?ma(s):null)&&(s!==(f=Be(s))||5!==s.tag&&6!==s.tag)&&(s=null)):(l=null,s=r),l!==s)){if(c=hn,v=\"onMouseLeave\",p=\"onMouseEnter\",h=\"mouse\",\"pointerout\"!==e&&\"pointerover\"!==e||(c=Mn,v=\"onPointerLeave\",p=\"onPointerEnter\",h=\"pointer\"),f=null==l?u:_a(l),d=null==s?u:_a(s),(u=new c(v,h+\"leave\",l,n,a)).target=f,u.relatedTarget=d,v=null,ma(a)===r&&((c=new c(p,h+\"enter\",s,n,a)).target=d,c.relatedTarget=f,v=c),f=v,l&&s)e:{for(p=s,h=0,d=c=l;d;d=Qr(d))h++;for(d=0,v=p;v;v=Qr(v))d++;for(;0<h-d;)c=Qr(c),h--;for(;0<d-h;)p=Qr(p),d--;for(;h--;){if(c===p||null!==p&&c===p.alternate)break e;c=Qr(c),p=Qr(p)}c=null}else c=null;null!==l&&Yr(o,u,l,c,!1),null!==s&&null!==f&&Yr(o,f,s,c,!0)}if(\"select\"===(l=(u=r?_a(r):window).nodeName&&u.nodeName.toLowerCase())||\"input\"===l&&\"file\"===u.type)var g=Kn;else if(Vn(u))if(Zn)g=or;else{g=ar;var y=rr}else(l=u.nodeName)&&\"input\"===l.toLowerCase()&&(\"checkbox\"===u.type||\"radio\"===u.type)&&(g=ir);switch(g&&(g=g(e,r))?Hn(o,g,n,a):(y&&y(e,u,r),\"focusout\"===e&&(y=u._wrapperState)&&y.controlled&&\"number\"===u.type&&ee(u,\"number\",u.value)),y=r?_a(r):window,e){case\"focusin\":(Vn(y)||\"true\"===y.contentEditable)&&(gr=y,yr=r,mr=null);break;case\"focusout\":mr=yr=gr=null;break;case\"mousedown\":br=!0;break;case\"contextmenu\":case\"mouseup\":case\"dragend\":br=!1,_r(o,n,a);break;case\"selectionchange\":if(vr)break;case\"keydown\":case\"keyup\":_r(o,n,a)}var m;if(An)e:{switch(e){case\"compositionstart\":var b=\"onCompositionStart\";break e;case\"compositionend\":b=\"onCompositionEnd\";break e;case\"compositionupdate\":b=\"onCompositionUpdate\";break e}b=void 0}else Bn?In(e,n)&&(b=\"onCompositionEnd\"):\"keydown\"===e&&229===n.keyCode&&(b=\"onCompositionStart\");b&&(Rn&&\"ko\"!==n.locale&&(Bn||\"onCompositionStart\"!==b?\"onCompositionEnd\"===b&&Bn&&(m=en()):(Xt=\"value\"in(Zt=a)?Zt.value:Zt.textContent,Bn=!0)),0<(y=qr(r,b)).length&&(b=new _n(b,e,null,n,a),o.push({event:b,listeners:y}),(m||null!==(m=$n(n)))&&(b.data=m))),(m=Dn?function(e,t){switch(e){case\"compositionend\":return $n(t);case\"keypress\":return 32!==t.which?null:(Un=!0,jn);case\"textInput\":return(e=t.data)===jn&&Un?null:e;default:return null}}(e,n):function(e,t){if(Bn)return\"compositionend\"===e||!An&&In(e,t)?(e=en(),Jt=Xt=Zt=null,Bn=!1,e):null;switch(e){case\"paste\":default:return null;case\"keypress\":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case\"compositionend\":return Rn&&\"ko\"!==t.locale?null:t.data}}(e,n))&&0<(r=qr(r,\"onBeforeInput\")).length&&(a=new _n(\"onBeforeInput\",\"beforeinput\",null,n,a),o.push({event:a,listeners:r}),a.data=m)}jr(o,t)}))}function Hr(e,t,n){return{instance:e,listener:t,currentTarget:n}}function qr(e,t){for(var n=t+\"Capture\",r=[];null!==e;){var a=e,i=a.stateNode;5===a.tag&&null!==i&&(a=i,null!=(i=Le(e,n))&&r.unshift(Hr(e,i,a)),null!=(i=Le(e,t))&&r.push(Hr(e,i,a))),e=e.return}return r}function Qr(e){if(null===e)return null;do{e=e.return}while(e&&5!==e.tag);return e||null}function Yr(e,t,n,r,a){for(var i=t._reactName,o=[];null!==n&&n!==r;){var u=n,l=u.alternate,s=u.stateNode;if(null!==l&&l===r)break;5===u.tag&&null!==s&&(u=s,a?null!=(l=Le(n,i))&&o.unshift(Hr(n,l,u)):a||null!=(l=Le(n,i))&&o.push(Hr(n,l,u))),n=n.return}0!==o.length&&e.push({event:t,listeners:o})}var Gr=/\\r\\n?/g,Kr=/\\u0000|\\uFFFD/g;function Zr(e){return(\"string\"==typeof e?e:\"\"+e).replace(Gr,\"\\n\").replace(Kr,\"\")}function Xr(e,t,n){if(t=Zr(t),Zr(e)!==t&&n)throw Error(i(425))}function Jr(){}var ea=null,ta=null;function na(e,t){return\"textarea\"===e||\"noscript\"===e||\"string\"==typeof t.children||\"number\"==typeof t.children||\"object\"==typeof t.dangerouslySetInnerHTML&&null!==t.dangerouslySetInnerHTML&&null!=t.dangerouslySetInnerHTML.__html}var ra=\"function\"==typeof setTimeout?setTimeout:void 0,aa=\"function\"==typeof clearTimeout?clearTimeout:void 0,ia=\"function\"==typeof Promise?Promise:void 0,oa=\"function\"==typeof queueMicrotask?queueMicrotask:void 0!==ia?function(e){return ia.resolve(null).then(e).catch(ua)}:ra;function ua(e){setTimeout((function(){throw e}))}function la(e,t){var n=t,r=0;do{var a=n.nextSibling;if(e.removeChild(n),a&&8===a.nodeType)if(\"/$\"===(n=a.data)){if(0===r)return e.removeChild(a),void Bt(t);r--}else\"$\"!==n&&\"$?\"!==n&&\"$!\"!==n||r++;n=a}while(n);Bt(t)}function sa(e){for(;null!=e;e=e.nextSibling){var t=e.nodeType;if(1===t||3===t)break;if(8===t){if(\"$\"===(t=e.data)||\"$!\"===t||\"$?\"===t)break;if(\"/$\"===t)return null}}return e}function ca(e){e=e.previousSibling;for(var t=0;e;){if(8===e.nodeType){var n=e.data;if(\"$\"===n||\"$!\"===n||\"$?\"===n){if(0===t)return e;t--}else\"/$\"===n&&t++}e=e.previousSibling}return null}var fa=Math.random().toString(36).slice(2),pa=\"__reactFiber$\"+fa,da=\"__reactProps$\"+fa,ha=\"__reactContainer$\"+fa,va=\"__reactEvents$\"+fa,ga=\"__reactListeners$\"+fa,ya=\"__reactHandles$\"+fa;function ma(e){var t=e[pa];if(t)return t;for(var n=e.parentNode;n;){if(t=n[ha]||n[pa]){if(n=t.alternate,null!==t.child||null!==n&&null!==n.child)for(e=ca(e);null!==e;){if(n=e[pa])return n;e=ca(e)}return t}n=(e=n).parentNode}return null}function ba(e){return!(e=e[pa]||e[ha])||5!==e.tag&&6!==e.tag&&13!==e.tag&&3!==e.tag?null:e}function _a(e){if(5===e.tag||6===e.tag)return e.stateNode;throw Error(i(33))}function wa(e){return e[da]||null}var xa=[],ka=-1;function Sa(e){return{current:e}}function Ea(e){0>ka||(e.current=xa[ka],xa[ka]=null,ka--)}function Ca(e,t){ka++,xa[ka]=e.current,e.current=t}var Ta={},Ma=Sa(Ta),Na=Sa(!1),Pa=Ta;function za(e,t){var n=e.type.contextTypes;if(!n)return Ta;var r=e.stateNode;if(r&&r.__reactInternalMemoizedUnmaskedChildContext===t)return r.__reactInternalMemoizedMaskedChildContext;var a,i={};for(a in n)i[a]=t[a];return r&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=i),i}function La(e){return null!=e.childContextTypes}function Oa(){Ea(Na),Ea(Ma)}function Aa(e,t,n){if(Ma.current!==Ta)throw Error(i(168));Ca(Ma,t),Ca(Na,n)}function Fa(e,t,n){var r=e.stateNode;if(t=t.childContextTypes,\"function\"!=typeof r.getChildContext)return n;for(var a in r=r.getChildContext())if(!(a in t))throw Error(i(108,W(e)||\"Unknown\",a));return R({},n,r)}function Da(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Ta,Pa=Ma.current,Ca(Ma,e),Ca(Na,Na.current),!0}function Ra(e,t,n){var r=e.stateNode;if(!r)throw Error(i(169));n?(e=Fa(e,t,Pa),r.__reactInternalMemoizedMergedChildContext=e,Ea(Na),Ea(Ma),Ca(Ma,e)):Ea(Na),Ca(Na,n)}var ja=null,Ua=!1,Ia=!1;function $a(e){null===ja?ja=[e]:ja.push(e)}function Ba(){if(!Ia&&null!==ja){Ia=!0;var e=0,t=bt;try{var n=ja;for(bt=1;e<n.length;e++){var r=n[e];do{r=r(!0)}while(null!==r)}ja=null,Ua=!1}catch(t){throw null!==ja&&(ja=ja.slice(e+1)),Qe(Je,Ba),t}finally{bt=t,Ia=!1}}return null}var Wa=[],Va=0,Ha=null,qa=0,Qa=[],Ya=0,Ga=null,Ka=1,Za=\"\";function Xa(e,t){Wa[Va++]=qa,Wa[Va++]=Ha,Ha=e,qa=t}function Ja(e,t,n){Qa[Ya++]=Ka,Qa[Ya++]=Za,Qa[Ya++]=Ga,Ga=e;var r=Ka;e=Za;var a=32-ot(r)-1;r&=~(1<<a),n+=1;var i=32-ot(t)+a;if(30<i){var o=a-a%5;i=(r&(1<<o)-1).toString(32),r>>=o,a-=o,Ka=1<<32-ot(t)+a|n<<a|r,Za=i+e}else Ka=1<<i|n<<a|r,Za=e}function ei(e){null!==e.return&&(Xa(e,1),Ja(e,1,0))}function ti(e){for(;e===Ha;)Ha=Wa[--Va],Wa[Va]=null,qa=Wa[--Va],Wa[Va]=null;for(;e===Ga;)Ga=Qa[--Ya],Qa[Ya]=null,Za=Qa[--Ya],Qa[Ya]=null,Ka=Qa[--Ya],Qa[Ya]=null}var ni=null,ri=null,ai=!1,ii=null;function oi(e,t){var n=Ls(5,null,null,0);n.elementType=\"DELETED\",n.stateNode=t,n.return=e,null===(t=e.deletions)?(e.deletions=[n],e.flags|=16):t.push(n)}function ui(e,t){switch(e.tag){case 5:var n=e.type;return null!==(t=1!==t.nodeType||n.toLowerCase()!==t.nodeName.toLowerCase()?null:t)&&(e.stateNode=t,ni=e,ri=sa(t.firstChild),!0);case 6:return null!==(t=\"\"===e.pendingProps||3!==t.nodeType?null:t)&&(e.stateNode=t,ni=e,ri=null,!0);case 13:return null!==(t=8!==t.nodeType?null:t)&&(n=null!==Ga?{id:Ka,overflow:Za}:null,e.memoizedState={dehydrated:t,treeContext:n,retryLane:1073741824},(n=Ls(18,null,null,0)).stateNode=t,n.return=e,e.child=n,ni=e,ri=null,!0);default:return!1}}function li(e){return 0!=(1&e.mode)&&0==(128&e.flags)}function si(e){if(ai){var t=ri;if(t){var n=t;if(!ui(e,t)){if(li(e))throw Error(i(418));t=sa(n.nextSibling);var r=ni;t&&ui(e,t)?oi(r,n):(e.flags=-4097&e.flags|2,ai=!1,ni=e)}}else{if(li(e))throw Error(i(418));e.flags=-4097&e.flags|2,ai=!1,ni=e}}}function ci(e){for(e=e.return;null!==e&&5!==e.tag&&3!==e.tag&&13!==e.tag;)e=e.return;ni=e}function fi(e){if(e!==ni)return!1;if(!ai)return ci(e),ai=!0,!1;var t;if((t=3!==e.tag)&&!(t=5!==e.tag)&&(t=\"head\"!==(t=e.type)&&\"body\"!==t&&!na(e.type,e.memoizedProps)),t&&(t=ri)){if(li(e))throw pi(),Error(i(418));for(;t;)oi(e,t),t=sa(t.nextSibling)}if(ci(e),13===e.tag){if(!(e=null!==(e=e.memoizedState)?e.dehydrated:null))throw Error(i(317));e:{for(e=e.nextSibling,t=0;e;){if(8===e.nodeType){var n=e.data;if(\"/$\"===n){if(0===t){ri=sa(e.nextSibling);break e}t--}else\"$\"!==n&&\"$!\"!==n&&\"$?\"!==n||t++}e=e.nextSibling}ri=null}}else ri=ni?sa(e.stateNode.nextSibling):null;return!0}function pi(){for(var e=ri;e;)e=sa(e.nextSibling)}function di(){ri=ni=null,ai=!1}function hi(e){null===ii?ii=[e]:ii.push(e)}var vi=_.ReactCurrentBatchConfig;function gi(e,t){if(e&&e.defaultProps){for(var n in t=R({},t),e=e.defaultProps)void 0===t[n]&&(t[n]=e[n]);return t}return t}var yi=Sa(null),mi=null,bi=null,_i=null;function wi(){_i=bi=mi=null}function xi(e){var t=yi.current;Ea(yi),e._currentValue=t}function ki(e,t,n){for(;null!==e;){var r=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,null!==r&&(r.childLanes|=t)):null!==r&&(r.childLanes&t)!==t&&(r.childLanes|=t),e===n)break;e=e.return}}function Si(e,t){mi=e,_i=bi=null,null!==(e=e.dependencies)&&null!==e.firstContext&&(0!=(e.lanes&t)&&(_u=!0),e.firstContext=null)}function Ei(e){var t=e._currentValue;if(_i!==e)if(e={context:e,memoizedValue:t,next:null},null===bi){if(null===mi)throw Error(i(308));bi=e,mi.dependencies={lanes:0,firstContext:e}}else bi=bi.next=e;return t}var Ci=null;function Ti(e){null===Ci?Ci=[e]:Ci.push(e)}function Mi(e,t,n,r){var a=t.interleaved;return null===a?(n.next=n,Ti(t)):(n.next=a.next,a.next=n),t.interleaved=n,Ni(e,r)}function Ni(e,t){e.lanes|=t;var n=e.alternate;for(null!==n&&(n.lanes|=t),n=e,e=e.return;null!==e;)e.childLanes|=t,null!==(n=e.alternate)&&(n.childLanes|=t),n=e,e=e.return;return 3===n.tag?n.stateNode:null}var Pi=!1;function zi(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Li(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function Oi(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Ai(e,t,n){var r=e.updateQueue;if(null===r)return null;if(r=r.shared,0!=(2&Nl)){var a=r.pending;return null===a?t.next=t:(t.next=a.next,a.next=t),r.pending=t,Ni(e,n)}return null===(a=r.interleaved)?(t.next=t,Ti(r)):(t.next=a.next,a.next=t),r.interleaved=t,Ni(e,n)}function Fi(e,t,n){if(null!==(t=t.updateQueue)&&(t=t.shared,0!=(4194240&n))){var r=t.lanes;n|=r&=e.pendingLanes,t.lanes=n,mt(e,n)}}function Di(e,t){var n=e.updateQueue,r=e.alternate;if(null!==r&&n===(r=r.updateQueue)){var a=null,i=null;if(null!==(n=n.firstBaseUpdate)){do{var o={eventTime:n.eventTime,lane:n.lane,tag:n.tag,payload:n.payload,callback:n.callback,next:null};null===i?a=i=o:i=i.next=o,n=n.next}while(null!==n);null===i?a=i=t:i=i.next=t}else a=i=t;return n={baseState:r.baseState,firstBaseUpdate:a,lastBaseUpdate:i,shared:r.shared,effects:r.effects},void(e.updateQueue=n)}null===(e=n.lastBaseUpdate)?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}function Ri(e,t,n,r){var a=e.updateQueue;Pi=!1;var i=a.firstBaseUpdate,o=a.lastBaseUpdate,u=a.shared.pending;if(null!==u){a.shared.pending=null;var l=u,s=l.next;l.next=null,null===o?i=s:o.next=s,o=l;var c=e.alternate;null!==c&&(u=(c=c.updateQueue).lastBaseUpdate)!==o&&(null===u?c.firstBaseUpdate=s:u.next=s,c.lastBaseUpdate=l)}if(null!==i){var f=a.baseState;for(o=0,c=s=l=null,u=i;;){var p=u.lane,d=u.eventTime;if((r&p)===p){null!==c&&(c=c.next={eventTime:d,lane:0,tag:u.tag,payload:u.payload,callback:u.callback,next:null});e:{var h=e,v=u;switch(p=t,d=n,v.tag){case 1:if(\"function\"==typeof(h=v.payload)){f=h.call(d,f,p);break e}f=h;break e;case 3:h.flags=-65537&h.flags|128;case 0:if(null==(p=\"function\"==typeof(h=v.payload)?h.call(d,f,p):h))break e;f=R({},f,p);break e;case 2:Pi=!0}}null!==u.callback&&0!==u.lane&&(e.flags|=64,null===(p=a.effects)?a.effects=[u]:p.push(u))}else d={eventTime:d,lane:p,tag:u.tag,payload:u.payload,callback:u.callback,next:null},null===c?(s=c=d,l=f):c=c.next=d,o|=p;if(null===(u=u.next)){if(null===(u=a.shared.pending))break;u=(p=u).next,p.next=null,a.lastBaseUpdate=p,a.shared.pending=null}}if(null===c&&(l=f),a.baseState=l,a.firstBaseUpdate=s,a.lastBaseUpdate=c,null!==(t=a.shared.interleaved)){a=t;do{o|=a.lane,a=a.next}while(a!==t)}else null===i&&(a.shared.lanes=0);Rl|=o,e.lanes=o,e.memoizedState=f}}function ji(e,t,n){if(e=t.effects,t.effects=null,null!==e)for(t=0;t<e.length;t++){var r=e[t],a=r.callback;if(null!==a){if(r.callback=null,r=n,\"function\"!=typeof a)throw Error(i(191,a));a.call(r)}}}var Ui=(new r.Component).refs;function Ii(e,t,n,r){n=null==(n=n(r,t=e.memoizedState))?t:R({},t,n),e.memoizedState=n,0===e.lanes&&(e.updateQueue.baseState=n)}var $i={isMounted:function(e){return!!(e=e._reactInternals)&&Be(e)===e},enqueueSetState:function(e,t,n){e=e._reactInternals;var r=ts(),a=ns(e),i=Oi(r,a);i.payload=t,null!=n&&(i.callback=n),null!==(t=Ai(e,i,a))&&(rs(t,e,a,r),Fi(t,e,a))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var r=ts(),a=ns(e),i=Oi(r,a);i.tag=1,i.payload=t,null!=n&&(i.callback=n),null!==(t=Ai(e,i,a))&&(rs(t,e,a,r),Fi(t,e,a))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=ts(),r=ns(e),a=Oi(n,r);a.tag=2,null!=t&&(a.callback=t),null!==(t=Ai(e,a,r))&&(rs(t,e,r,n),Fi(t,e,r))}};function Bi(e,t,n,r,a,i,o){return\"function\"==typeof(e=e.stateNode).shouldComponentUpdate?e.shouldComponentUpdate(r,i,o):!(t.prototype&&t.prototype.isPureReactComponent&&lr(n,r)&&lr(a,i))}function Wi(e,t,n){var r=!1,a=Ta,i=t.contextType;return\"object\"==typeof i&&null!==i?i=Ei(i):(a=La(t)?Pa:Ma.current,i=(r=null!=(r=t.contextTypes))?za(e,a):Ta),t=new t(n,i),e.memoizedState=null!==t.state&&void 0!==t.state?t.state:null,t.updater=$i,e.stateNode=t,t._reactInternals=e,r&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=a,e.__reactInternalMemoizedMaskedChildContext=i),t}function Vi(e,t,n,r){e=t.state,\"function\"==typeof t.componentWillReceiveProps&&t.componentWillReceiveProps(n,r),\"function\"==typeof t.UNSAFE_componentWillReceiveProps&&t.UNSAFE_componentWillReceiveProps(n,r),t.state!==e&&$i.enqueueReplaceState(t,t.state,null)}function Hi(e,t,n,r){var a=e.stateNode;a.props=n,a.state=e.memoizedState,a.refs=Ui,zi(e);var i=t.contextType;\"object\"==typeof i&&null!==i?a.context=Ei(i):(i=La(t)?Pa:Ma.current,a.context=za(e,i)),a.state=e.memoizedState,\"function\"==typeof(i=t.getDerivedStateFromProps)&&(Ii(e,t,i,n),a.state=e.memoizedState),\"function\"==typeof t.getDerivedStateFromProps||\"function\"==typeof a.getSnapshotBeforeUpdate||\"function\"!=typeof a.UNSAFE_componentWillMount&&\"function\"!=typeof a.componentWillMount||(t=a.state,\"function\"==typeof a.componentWillMount&&a.componentWillMount(),\"function\"==typeof a.UNSAFE_componentWillMount&&a.UNSAFE_componentWillMount(),t!==a.state&&$i.enqueueReplaceState(a,a.state,null),Ri(e,n,a,r),a.state=e.memoizedState),\"function\"==typeof a.componentDidMount&&(e.flags|=4194308)}function qi(e,t,n){if(null!==(e=n.ref)&&\"function\"!=typeof e&&\"object\"!=typeof e){if(n._owner){if(n=n._owner){if(1!==n.tag)throw Error(i(309));var r=n.stateNode}if(!r)throw Error(i(147,e));var a=r,o=\"\"+e;return null!==t&&null!==t.ref&&\"function\"==typeof t.ref&&t.ref._stringRef===o?t.ref:(t=function(e){var t=a.refs;t===Ui&&(t=a.refs={}),null===e?delete t[o]:t[o]=e},t._stringRef=o,t)}if(\"string\"!=typeof e)throw Error(i(284));if(!n._owner)throw Error(i(290,e))}return e}function Qi(e,t){throw e=Object.prototype.toString.call(t),Error(i(31,\"[object Object]\"===e?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":e))}function Yi(e){return(0,e._init)(e._payload)}function Gi(e){function t(t,n){if(e){var r=t.deletions;null===r?(t.deletions=[n],t.flags|=16):r.push(n)}}function n(n,r){if(!e)return null;for(;null!==r;)t(n,r),r=r.sibling;return null}function r(e,t){for(e=new Map;null!==t;)null!==t.key?e.set(t.key,t):e.set(t.index,t),t=t.sibling;return e}function a(e,t){return(e=As(e,t)).index=0,e.sibling=null,e}function o(t,n,r){return t.index=r,e?null!==(r=t.alternate)?(r=r.index)<n?(t.flags|=2,n):r:(t.flags|=2,n):(t.flags|=1048576,n)}function u(t){return e&&null===t.alternate&&(t.flags|=2),t}function l(e,t,n,r){return null===t||6!==t.tag?((t=js(n,e.mode,r)).return=e,t):((t=a(t,n)).return=e,t)}function s(e,t,n,r){var i=n.type;return i===k?f(e,t,n.props.children,r,n.key):null!==t&&(t.elementType===i||\"object\"==typeof i&&null!==i&&i.$$typeof===L&&Yi(i)===t.type)?((r=a(t,n.props)).ref=qi(e,t,n),r.return=e,r):((r=Fs(n.type,n.key,n.props,null,e.mode,r)).ref=qi(e,t,n),r.return=e,r)}function c(e,t,n,r){return null===t||4!==t.tag||t.stateNode.containerInfo!==n.containerInfo||t.stateNode.implementation!==n.implementation?((t=Us(n,e.mode,r)).return=e,t):((t=a(t,n.children||[])).return=e,t)}function f(e,t,n,r,i){return null===t||7!==t.tag?((t=Ds(n,e.mode,r,i)).return=e,t):((t=a(t,n)).return=e,t)}function p(e,t,n){if(\"string\"==typeof t&&\"\"!==t||\"number\"==typeof t)return(t=js(\"\"+t,e.mode,n)).return=e,t;if(\"object\"==typeof t&&null!==t){switch(t.$$typeof){case w:return(n=Fs(t.type,t.key,t.props,null,e.mode,n)).ref=qi(e,null,t),n.return=e,n;case x:return(t=Us(t,e.mode,n)).return=e,t;case L:return p(e,(0,t._init)(t._payload),n)}if(te(t)||F(t))return(t=Ds(t,e.mode,n,null)).return=e,t;Qi(e,t)}return null}function d(e,t,n,r){var a=null!==t?t.key:null;if(\"string\"==typeof n&&\"\"!==n||\"number\"==typeof n)return null!==a?null:l(e,t,\"\"+n,r);if(\"object\"==typeof n&&null!==n){switch(n.$$typeof){case w:return n.key===a?s(e,t,n,r):null;case x:return n.key===a?c(e,t,n,r):null;case L:return d(e,t,(a=n._init)(n._payload),r)}if(te(n)||F(n))return null!==a?null:f(e,t,n,r,null);Qi(e,n)}return null}function h(e,t,n,r,a){if(\"string\"==typeof r&&\"\"!==r||\"number\"==typeof r)return l(t,e=e.get(n)||null,\"\"+r,a);if(\"object\"==typeof r&&null!==r){switch(r.$$typeof){case w:return s(t,e=e.get(null===r.key?n:r.key)||null,r,a);case x:return c(t,e=e.get(null===r.key?n:r.key)||null,r,a);case L:return h(e,t,n,(0,r._init)(r._payload),a)}if(te(r)||F(r))return f(t,e=e.get(n)||null,r,a,null);Qi(t,r)}return null}function v(a,i,u,l){for(var s=null,c=null,f=i,v=i=0,g=null;null!==f&&v<u.length;v++){f.index>v?(g=f,f=null):g=f.sibling;var y=d(a,f,u[v],l);if(null===y){null===f&&(f=g);break}e&&f&&null===y.alternate&&t(a,f),i=o(y,i,v),null===c?s=y:c.sibling=y,c=y,f=g}if(v===u.length)return n(a,f),ai&&Xa(a,v),s;if(null===f){for(;v<u.length;v++)null!==(f=p(a,u[v],l))&&(i=o(f,i,v),null===c?s=f:c.sibling=f,c=f);return ai&&Xa(a,v),s}for(f=r(a,f);v<u.length;v++)null!==(g=h(f,a,v,u[v],l))&&(e&&null!==g.alternate&&f.delete(null===g.key?v:g.key),i=o(g,i,v),null===c?s=g:c.sibling=g,c=g);return e&&f.forEach((function(e){return t(a,e)})),ai&&Xa(a,v),s}function g(a,u,l,s){var c=F(l);if(\"function\"!=typeof c)throw Error(i(150));if(null==(l=c.call(l)))throw Error(i(151));for(var f=c=null,v=u,g=u=0,y=null,m=l.next();null!==v&&!m.done;g++,m=l.next()){v.index>g?(y=v,v=null):y=v.sibling;var b=d(a,v,m.value,s);if(null===b){null===v&&(v=y);break}e&&v&&null===b.alternate&&t(a,v),u=o(b,u,g),null===f?c=b:f.sibling=b,f=b,v=y}if(m.done)return n(a,v),ai&&Xa(a,g),c;if(null===v){for(;!m.done;g++,m=l.next())null!==(m=p(a,m.value,s))&&(u=o(m,u,g),null===f?c=m:f.sibling=m,f=m);return ai&&Xa(a,g),c}for(v=r(a,v);!m.done;g++,m=l.next())null!==(m=h(v,a,g,m.value,s))&&(e&&null!==m.alternate&&v.delete(null===m.key?g:m.key),u=o(m,u,g),null===f?c=m:f.sibling=m,f=m);return e&&v.forEach((function(e){return t(a,e)})),ai&&Xa(a,g),c}return function e(r,i,o,l){if(\"object\"==typeof o&&null!==o&&o.type===k&&null===o.key&&(o=o.props.children),\"object\"==typeof o&&null!==o){switch(o.$$typeof){case w:e:{for(var s=o.key,c=i;null!==c;){if(c.key===s){if((s=o.type)===k){if(7===c.tag){n(r,c.sibling),(i=a(c,o.props.children)).return=r,r=i;break e}}else if(c.elementType===s||\"object\"==typeof s&&null!==s&&s.$$typeof===L&&Yi(s)===c.type){n(r,c.sibling),(i=a(c,o.props)).ref=qi(r,c,o),i.return=r,r=i;break e}n(r,c);break}t(r,c),c=c.sibling}o.type===k?((i=Ds(o.props.children,r.mode,l,o.key)).return=r,r=i):((l=Fs(o.type,o.key,o.props,null,r.mode,l)).ref=qi(r,i,o),l.return=r,r=l)}return u(r);case x:e:{for(c=o.key;null!==i;){if(i.key===c){if(4===i.tag&&i.stateNode.containerInfo===o.containerInfo&&i.stateNode.implementation===o.implementation){n(r,i.sibling),(i=a(i,o.children||[])).return=r,r=i;break e}n(r,i);break}t(r,i),i=i.sibling}(i=Us(o,r.mode,l)).return=r,r=i}return u(r);case L:return e(r,i,(c=o._init)(o._payload),l)}if(te(o))return v(r,i,o,l);if(F(o))return g(r,i,o,l);Qi(r,o)}return\"string\"==typeof o&&\"\"!==o||\"number\"==typeof o?(o=\"\"+o,null!==i&&6===i.tag?(n(r,i.sibling),(i=a(i,o)).return=r,r=i):(n(r,i),(i=js(o,r.mode,l)).return=r,r=i),u(r)):n(r,i)}}var Ki=Gi(!0),Zi=Gi(!1),Xi={},Ji=Sa(Xi),eo=Sa(Xi),to=Sa(Xi);function no(e){if(e===Xi)throw Error(i(174));return e}function ro(e,t){switch(Ca(to,t),Ca(eo,e),Ca(Ji,Xi),e=t.nodeType){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:le(null,\"\");break;default:t=le(t=(e=8===e?t.parentNode:t).namespaceURI||null,e=e.tagName)}Ea(Ji),Ca(Ji,t)}function ao(){Ea(Ji),Ea(eo),Ea(to)}function io(e){no(to.current);var t=no(Ji.current),n=le(t,e.type);t!==n&&(Ca(eo,e),Ca(Ji,n))}function oo(e){eo.current===e&&(Ea(Ji),Ea(eo))}var uo=Sa(0);function lo(e){for(var t=e;null!==t;){if(13===t.tag){var n=t.memoizedState;if(null!==n&&(null===(n=n.dehydrated)||\"$?\"===n.data||\"$!\"===n.data))return t}else if(19===t.tag&&void 0!==t.memoizedProps.revealOrder){if(0!=(128&t.flags))return t}else if(null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var so=[];function co(){for(var e=0;e<so.length;e++)so[e]._workInProgressVersionPrimary=null;so.length=0}var fo=_.ReactCurrentDispatcher,po=_.ReactCurrentBatchConfig,ho=0,vo=null,go=null,yo=null,mo=!1,bo=!1,_o=0,wo=0;function xo(){throw Error(i(321))}function ko(e,t){if(null===t)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!ur(e[n],t[n]))return!1;return!0}function So(e,t,n,r,a,o){if(ho=o,vo=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,fo.current=null===e||null===e.memoizedState?uu:lu,e=n(r,a),bo){o=0;do{if(bo=!1,_o=0,25<=o)throw Error(i(301));o+=1,yo=go=null,t.updateQueue=null,fo.current=su,e=n(r,a)}while(bo)}if(fo.current=ou,t=null!==go&&null!==go.next,ho=0,yo=go=vo=null,mo=!1,t)throw Error(i(300));return e}function Eo(){var e=0!==_o;return _o=0,e}function Co(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return null===yo?vo.memoizedState=yo=e:yo=yo.next=e,yo}function To(){if(null===go){var e=vo.alternate;e=null!==e?e.memoizedState:null}else e=go.next;var t=null===yo?vo.memoizedState:yo.next;if(null!==t)yo=t,go=e;else{if(null===e)throw Error(i(310));e={memoizedState:(go=e).memoizedState,baseState:go.baseState,baseQueue:go.baseQueue,queue:go.queue,next:null},null===yo?vo.memoizedState=yo=e:yo=yo.next=e}return yo}function Mo(e,t){return\"function\"==typeof t?t(e):t}function No(e){var t=To(),n=t.queue;if(null===n)throw Error(i(311));n.lastRenderedReducer=e;var r=go,a=r.baseQueue,o=n.pending;if(null!==o){if(null!==a){var u=a.next;a.next=o.next,o.next=u}r.baseQueue=a=o,n.pending=null}if(null!==a){o=a.next,r=r.baseState;var l=u=null,s=null,c=o;do{var f=c.lane;if((ho&f)===f)null!==s&&(s=s.next={lane:0,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null}),r=c.hasEagerState?c.eagerState:e(r,c.action);else{var p={lane:f,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null};null===s?(l=s=p,u=r):s=s.next=p,vo.lanes|=f,Rl|=f}c=c.next}while(null!==c&&c!==o);null===s?u=r:s.next=l,ur(r,t.memoizedState)||(_u=!0),t.memoizedState=r,t.baseState=u,t.baseQueue=s,n.lastRenderedState=r}if(null!==(e=n.interleaved)){a=e;do{o=a.lane,vo.lanes|=o,Rl|=o,a=a.next}while(a!==e)}else null===a&&(n.lanes=0);return[t.memoizedState,n.dispatch]}function Po(e){var t=To(),n=t.queue;if(null===n)throw Error(i(311));n.lastRenderedReducer=e;var r=n.dispatch,a=n.pending,o=t.memoizedState;if(null!==a){n.pending=null;var u=a=a.next;do{o=e(o,u.action),u=u.next}while(u!==a);ur(o,t.memoizedState)||(_u=!0),t.memoizedState=o,null===t.baseQueue&&(t.baseState=o),n.lastRenderedState=o}return[o,r]}function zo(){}function Lo(e,t){var n=vo,r=To(),a=t(),o=!ur(r.memoizedState,a);if(o&&(r.memoizedState=a,_u=!0),r=r.queue,Vo(Fo.bind(null,n,r,e),[e]),r.getSnapshot!==t||o||null!==yo&&1&yo.memoizedState.tag){if(n.flags|=2048,Uo(9,Ao.bind(null,n,r,a,t),void 0,null),null===Pl)throw Error(i(349));0!=(30&ho)||Oo(n,t,a)}return a}function Oo(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},null===(t=vo.updateQueue)?(t={lastEffect:null,stores:null},vo.updateQueue=t,t.stores=[e]):null===(n=t.stores)?t.stores=[e]:n.push(e)}function Ao(e,t,n,r){t.value=n,t.getSnapshot=r,Do(t)&&Ro(e)}function Fo(e,t,n){return n((function(){Do(t)&&Ro(e)}))}function Do(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!ur(e,n)}catch(e){return!0}}function Ro(e){var t=Ni(e,1);null!==t&&rs(t,e,1,-1)}function jo(e){var t=Co();return\"function\"==typeof e&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:Mo,lastRenderedState:e},t.queue=e,e=e.dispatch=nu.bind(null,vo,e),[t.memoizedState,e]}function Uo(e,t,n,r){return e={tag:e,create:t,destroy:n,deps:r,next:null},null===(t=vo.updateQueue)?(t={lastEffect:null,stores:null},vo.updateQueue=t,t.lastEffect=e.next=e):null===(n=t.lastEffect)?t.lastEffect=e.next=e:(r=n.next,n.next=e,e.next=r,t.lastEffect=e),e}function Io(){return To().memoizedState}function $o(e,t,n,r){var a=Co();vo.flags|=e,a.memoizedState=Uo(1|t,n,void 0,void 0===r?null:r)}function Bo(e,t,n,r){var a=To();r=void 0===r?null:r;var i=void 0;if(null!==go){var o=go.memoizedState;if(i=o.destroy,null!==r&&ko(r,o.deps))return void(a.memoizedState=Uo(t,n,i,r))}vo.flags|=e,a.memoizedState=Uo(1|t,n,i,r)}function Wo(e,t){return $o(8390656,8,e,t)}function Vo(e,t){return Bo(2048,8,e,t)}function Ho(e,t){return Bo(4,2,e,t)}function qo(e,t){return Bo(4,4,e,t)}function Qo(e,t){return\"function\"==typeof t?(e=e(),t(e),function(){t(null)}):null!=t?(e=e(),t.current=e,function(){t.current=null}):void 0}function Yo(e,t,n){return n=null!=n?n.concat([e]):null,Bo(4,4,Qo.bind(null,t,e),n)}function Go(){}function Ko(e,t){var n=To();t=void 0===t?null:t;var r=n.memoizedState;return null!==r&&null!==t&&ko(t,r[1])?r[0]:(n.memoizedState=[e,t],e)}function Zo(e,t){var n=To();t=void 0===t?null:t;var r=n.memoizedState;return null!==r&&null!==t&&ko(t,r[1])?r[0]:(e=e(),n.memoizedState=[e,t],e)}function Xo(e,t,n){return 0==(21&ho)?(e.baseState&&(e.baseState=!1,_u=!0),e.memoizedState=n):(ur(n,t)||(n=vt(),vo.lanes|=n,Rl|=n,e.baseState=!0),t)}function Jo(e,t){var n=bt;bt=0!==n&&4>n?n:4,e(!0);var r=po.transition;po.transition={};try{e(!1),t()}finally{bt=n,po.transition=r}}function eu(){return To().memoizedState}function tu(e,t,n){var r=ns(e);n={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null},ru(e)?au(t,n):null!==(n=Mi(e,t,n,r))&&(rs(n,e,r,ts()),iu(n,t,r))}function nu(e,t,n){var r=ns(e),a={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null};if(ru(e))au(t,a);else{var i=e.alternate;if(0===e.lanes&&(null===i||0===i.lanes)&&null!==(i=t.lastRenderedReducer))try{var o=t.lastRenderedState,u=i(o,n);if(a.hasEagerState=!0,a.eagerState=u,ur(u,o)){var l=t.interleaved;return null===l?(a.next=a,Ti(t)):(a.next=l.next,l.next=a),void(t.interleaved=a)}}catch(e){}null!==(n=Mi(e,t,a,r))&&(rs(n,e,r,a=ts()),iu(n,t,r))}}function ru(e){var t=e.alternate;return e===vo||null!==t&&t===vo}function au(e,t){bo=mo=!0;var n=e.pending;null===n?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function iu(e,t,n){if(0!=(4194240&n)){var r=t.lanes;n|=r&=e.pendingLanes,t.lanes=n,mt(e,n)}}var ou={readContext:Ei,useCallback:xo,useContext:xo,useEffect:xo,useImperativeHandle:xo,useInsertionEffect:xo,useLayoutEffect:xo,useMemo:xo,useReducer:xo,useRef:xo,useState:xo,useDebugValue:xo,useDeferredValue:xo,useTransition:xo,useMutableSource:xo,useSyncExternalStore:xo,useId:xo,unstable_isNewReconciler:!1},uu={readContext:Ei,useCallback:function(e,t){return Co().memoizedState=[e,void 0===t?null:t],e},useContext:Ei,useEffect:Wo,useImperativeHandle:function(e,t,n){return n=null!=n?n.concat([e]):null,$o(4194308,4,Qo.bind(null,t,e),n)},useLayoutEffect:function(e,t){return $o(4194308,4,e,t)},useInsertionEffect:function(e,t){return $o(4,2,e,t)},useMemo:function(e,t){var n=Co();return t=void 0===t?null:t,e=e(),n.memoizedState=[e,t],e},useReducer:function(e,t,n){var r=Co();return t=void 0!==n?n(t):t,r.memoizedState=r.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},r.queue=e,e=e.dispatch=tu.bind(null,vo,e),[r.memoizedState,e]},useRef:function(e){return e={current:e},Co().memoizedState=e},useState:jo,useDebugValue:Go,useDeferredValue:function(e){return Co().memoizedState=e},useTransition:function(){var e=jo(!1),t=e[0];return e=Jo.bind(null,e[1]),Co().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,n){var r=vo,a=Co();if(ai){if(void 0===n)throw Error(i(407));n=n()}else{if(n=t(),null===Pl)throw Error(i(349));0!=(30&ho)||Oo(r,t,n)}a.memoizedState=n;var o={value:n,getSnapshot:t};return a.queue=o,Wo(Fo.bind(null,r,o,e),[e]),r.flags|=2048,Uo(9,Ao.bind(null,r,o,n,t),void 0,null),n},useId:function(){var e=Co(),t=Pl.identifierPrefix;if(ai){var n=Za;t=\":\"+t+\"R\"+(n=(Ka&~(1<<32-ot(Ka)-1)).toString(32)+n),0<(n=_o++)&&(t+=\"H\"+n.toString(32)),t+=\":\"}else t=\":\"+t+\"r\"+(n=wo++).toString(32)+\":\";return e.memoizedState=t},unstable_isNewReconciler:!1},lu={readContext:Ei,useCallback:Ko,useContext:Ei,useEffect:Vo,useImperativeHandle:Yo,useInsertionEffect:Ho,useLayoutEffect:qo,useMemo:Zo,useReducer:No,useRef:Io,useState:function(){return No(Mo)},useDebugValue:Go,useDeferredValue:function(e){return Xo(To(),go.memoizedState,e)},useTransition:function(){return[No(Mo)[0],To().memoizedState]},useMutableSource:zo,useSyncExternalStore:Lo,useId:eu,unstable_isNewReconciler:!1},su={readContext:Ei,useCallback:Ko,useContext:Ei,useEffect:Vo,useImperativeHandle:Yo,useInsertionEffect:Ho,useLayoutEffect:qo,useMemo:Zo,useReducer:Po,useRef:Io,useState:function(){return Po(Mo)},useDebugValue:Go,useDeferredValue:function(e){var t=To();return null===go?t.memoizedState=e:Xo(t,go.memoizedState,e)},useTransition:function(){return[Po(Mo)[0],To().memoizedState]},useMutableSource:zo,useSyncExternalStore:Lo,useId:eu,unstable_isNewReconciler:!1};function cu(e,t){try{var n=\"\",r=t;do{n+=$(r),r=r.return}while(r);var a=n}catch(e){a=\"\\nError generating stack: \"+e.message+\"\\n\"+e.stack}return{value:e,source:t,stack:a,digest:null}}function fu(e,t,n){return{value:e,source:null,stack:null!=n?n:null,digest:null!=t?t:null}}function pu(e,t){try{console.error(t.value)}catch(e){setTimeout((function(){throw e}))}}var du=\"function\"==typeof WeakMap?WeakMap:Map;function hu(e,t,n){(n=Oi(-1,n)).tag=3,n.payload={element:null};var r=t.value;return n.callback=function(){Hl||(Hl=!0,ql=r),pu(0,t)},n}function vu(e,t,n){(n=Oi(-1,n)).tag=3;var r=e.type.getDerivedStateFromError;if(\"function\"==typeof r){var a=t.value;n.payload=function(){return r(a)},n.callback=function(){pu(0,t)}}var i=e.stateNode;return null!==i&&\"function\"==typeof i.componentDidCatch&&(n.callback=function(){pu(0,t),\"function\"!=typeof r&&(null===Ql?Ql=new Set([this]):Ql.add(this));var e=t.stack;this.componentDidCatch(t.value,{componentStack:null!==e?e:\"\"})}),n}function gu(e,t,n){var r=e.pingCache;if(null===r){r=e.pingCache=new du;var a=new Set;r.set(t,a)}else void 0===(a=r.get(t))&&(a=new Set,r.set(t,a));a.has(n)||(a.add(n),e=Cs.bind(null,e,t,n),t.then(e,e))}function yu(e){do{var t;if((t=13===e.tag)&&(t=null===(t=e.memoizedState)||null!==t.dehydrated),t)return e;e=e.return}while(null!==e);return null}function mu(e,t,n,r,a){return 0==(1&e.mode)?(e===t?e.flags|=65536:(e.flags|=128,n.flags|=131072,n.flags&=-52805,1===n.tag&&(null===n.alternate?n.tag=17:((t=Oi(-1,1)).tag=2,Ai(n,t,1))),n.lanes|=1),e):(e.flags|=65536,e.lanes=a,e)}var bu=_.ReactCurrentOwner,_u=!1;function wu(e,t,n,r){t.child=null===e?Zi(t,null,n,r):Ki(t,e.child,n,r)}function xu(e,t,n,r,a){n=n.render;var i=t.ref;return Si(t,a),r=So(e,t,n,r,i,a),n=Eo(),null===e||_u?(ai&&n&&ei(t),t.flags|=1,wu(e,t,r,a),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Hu(e,t,a))}function ku(e,t,n,r,a){if(null===e){var i=n.type;return\"function\"!=typeof i||Os(i)||void 0!==i.defaultProps||null!==n.compare||void 0!==n.defaultProps?((e=Fs(n.type,null,r,t,t.mode,a)).ref=t.ref,e.return=t,t.child=e):(t.tag=15,t.type=i,Su(e,t,i,r,a))}if(i=e.child,0==(e.lanes&a)){var o=i.memoizedProps;if((n=null!==(n=n.compare)?n:lr)(o,r)&&e.ref===t.ref)return Hu(e,t,a)}return t.flags|=1,(e=As(i,r)).ref=t.ref,e.return=t,t.child=e}function Su(e,t,n,r,a){if(null!==e){var i=e.memoizedProps;if(lr(i,r)&&e.ref===t.ref){if(_u=!1,t.pendingProps=r=i,0==(e.lanes&a))return t.lanes=e.lanes,Hu(e,t,a);0!=(131072&e.flags)&&(_u=!0)}}return Tu(e,t,n,r,a)}function Eu(e,t,n){var r=t.pendingProps,a=r.children,i=null!==e?e.memoizedState:null;if(\"hidden\"===r.mode)if(0==(1&t.mode))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},Ca(Al,Ol),Ol|=n;else{if(0==(1073741824&n))return e=null!==i?i.baseLanes|n:n,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,Ca(Al,Ol),Ol|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},r=null!==i?i.baseLanes:n,Ca(Al,Ol),Ol|=r}else null!==i?(r=i.baseLanes|n,t.memoizedState=null):r=n,Ca(Al,Ol),Ol|=r;return wu(e,t,a,n),t.child}function Cu(e,t){var n=t.ref;(null===e&&null!==n||null!==e&&e.ref!==n)&&(t.flags|=512,t.flags|=2097152)}function Tu(e,t,n,r,a){var i=La(n)?Pa:Ma.current;return i=za(t,i),Si(t,a),n=So(e,t,n,r,i,a),r=Eo(),null===e||_u?(ai&&r&&ei(t),t.flags|=1,wu(e,t,n,a),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Hu(e,t,a))}function Mu(e,t,n,r,a){if(La(n)){var i=!0;Da(t)}else i=!1;if(Si(t,a),null===t.stateNode)Vu(e,t),Wi(t,n,r),Hi(t,n,r,a),r=!0;else if(null===e){var o=t.stateNode,u=t.memoizedProps;o.props=u;var l=o.context,s=n.contextType;s=\"object\"==typeof s&&null!==s?Ei(s):za(t,s=La(n)?Pa:Ma.current);var c=n.getDerivedStateFromProps,f=\"function\"==typeof c||\"function\"==typeof o.getSnapshotBeforeUpdate;f||\"function\"!=typeof o.UNSAFE_componentWillReceiveProps&&\"function\"!=typeof o.componentWillReceiveProps||(u!==r||l!==s)&&Vi(t,o,r,s),Pi=!1;var p=t.memoizedState;o.state=p,Ri(t,r,o,a),l=t.memoizedState,u!==r||p!==l||Na.current||Pi?(\"function\"==typeof c&&(Ii(t,n,c,r),l=t.memoizedState),(u=Pi||Bi(t,n,u,r,p,l,s))?(f||\"function\"!=typeof o.UNSAFE_componentWillMount&&\"function\"!=typeof o.componentWillMount||(\"function\"==typeof o.componentWillMount&&o.componentWillMount(),\"function\"==typeof o.UNSAFE_componentWillMount&&o.UNSAFE_componentWillMount()),\"function\"==typeof o.componentDidMount&&(t.flags|=4194308)):(\"function\"==typeof o.componentDidMount&&(t.flags|=4194308),t.memoizedProps=r,t.memoizedState=l),o.props=r,o.state=l,o.context=s,r=u):(\"function\"==typeof o.componentDidMount&&(t.flags|=4194308),r=!1)}else{o=t.stateNode,Li(e,t),u=t.memoizedProps,s=t.type===t.elementType?u:gi(t.type,u),o.props=s,f=t.pendingProps,p=o.context,l=\"object\"==typeof(l=n.contextType)&&null!==l?Ei(l):za(t,l=La(n)?Pa:Ma.current);var d=n.getDerivedStateFromProps;(c=\"function\"==typeof d||\"function\"==typeof o.getSnapshotBeforeUpdate)||\"function\"!=typeof o.UNSAFE_componentWillReceiveProps&&\"function\"!=typeof o.componentWillReceiveProps||(u!==f||p!==l)&&Vi(t,o,r,l),Pi=!1,p=t.memoizedState,o.state=p,Ri(t,r,o,a);var h=t.memoizedState;u!==f||p!==h||Na.current||Pi?(\"function\"==typeof d&&(Ii(t,n,d,r),h=t.memoizedState),(s=Pi||Bi(t,n,s,r,p,h,l)||!1)?(c||\"function\"!=typeof o.UNSAFE_componentWillUpdate&&\"function\"!=typeof o.componentWillUpdate||(\"function\"==typeof o.componentWillUpdate&&o.componentWillUpdate(r,h,l),\"function\"==typeof o.UNSAFE_componentWillUpdate&&o.UNSAFE_componentWillUpdate(r,h,l)),\"function\"==typeof o.componentDidUpdate&&(t.flags|=4),\"function\"==typeof o.getSnapshotBeforeUpdate&&(t.flags|=1024)):(\"function\"!=typeof o.componentDidUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),\"function\"!=typeof o.getSnapshotBeforeUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),t.memoizedProps=r,t.memoizedState=h),o.props=r,o.state=h,o.context=l,r=s):(\"function\"!=typeof o.componentDidUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),\"function\"!=typeof o.getSnapshotBeforeUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),r=!1)}return Nu(e,t,n,r,i,a)}function Nu(e,t,n,r,a,i){Cu(e,t);var o=0!=(128&t.flags);if(!r&&!o)return a&&Ra(t,n,!1),Hu(e,t,i);r=t.stateNode,bu.current=t;var u=o&&\"function\"!=typeof n.getDerivedStateFromError?null:r.render();return t.flags|=1,null!==e&&o?(t.child=Ki(t,e.child,null,i),t.child=Ki(t,null,u,i)):wu(e,t,u,i),t.memoizedState=r.state,a&&Ra(t,n,!0),t.child}function Pu(e){var t=e.stateNode;t.pendingContext?Aa(0,t.pendingContext,t.pendingContext!==t.context):t.context&&Aa(0,t.context,!1),ro(e,t.containerInfo)}function zu(e,t,n,r,a){return di(),hi(a),t.flags|=256,wu(e,t,n,r),t.child}var Lu,Ou,Au,Fu,Du={dehydrated:null,treeContext:null,retryLane:0};function Ru(e){return{baseLanes:e,cachePool:null,transitions:null}}function ju(e,t,n){var r,a=t.pendingProps,o=uo.current,u=!1,l=0!=(128&t.flags);if((r=l)||(r=(null===e||null!==e.memoizedState)&&0!=(2&o)),r?(u=!0,t.flags&=-129):null!==e&&null===e.memoizedState||(o|=1),Ca(uo,1&o),null===e)return si(t),null!==(e=t.memoizedState)&&null!==(e=e.dehydrated)?(0==(1&t.mode)?t.lanes=1:\"$!\"===e.data?t.lanes=8:t.lanes=1073741824,null):(l=a.children,e=a.fallback,u?(a=t.mode,u=t.child,l={mode:\"hidden\",children:l},0==(1&a)&&null!==u?(u.childLanes=0,u.pendingProps=l):u=Rs(l,a,0,null),e=Ds(e,a,n,null),u.return=t,e.return=t,u.sibling=e,t.child=u,t.child.memoizedState=Ru(n),t.memoizedState=Du,e):Uu(t,l));if(null!==(o=e.memoizedState)&&null!==(r=o.dehydrated))return function(e,t,n,r,a,o,u){if(n)return 256&t.flags?(t.flags&=-257,Iu(e,t,u,r=fu(Error(i(422))))):null!==t.memoizedState?(t.child=e.child,t.flags|=128,null):(o=r.fallback,a=t.mode,r=Rs({mode:\"visible\",children:r.children},a,0,null),(o=Ds(o,a,u,null)).flags|=2,r.return=t,o.return=t,r.sibling=o,t.child=r,0!=(1&t.mode)&&Ki(t,e.child,null,u),t.child.memoizedState=Ru(u),t.memoizedState=Du,o);if(0==(1&t.mode))return Iu(e,t,u,null);if(\"$!\"===a.data){if(r=a.nextSibling&&a.nextSibling.dataset)var l=r.dgst;return r=l,Iu(e,t,u,r=fu(o=Error(i(419)),r,void 0))}if(l=0!=(u&e.childLanes),_u||l){if(null!==(r=Pl)){switch(u&-u){case 4:a=2;break;case 16:a=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:a=32;break;case 536870912:a=268435456;break;default:a=0}0!==(a=0!=(a&(r.suspendedLanes|u))?0:a)&&a!==o.retryLane&&(o.retryLane=a,Ni(e,a),rs(r,e,a,-1))}return gs(),Iu(e,t,u,r=fu(Error(i(421))))}return\"$?\"===a.data?(t.flags|=128,t.child=e.child,t=Ms.bind(null,e),a._reactRetry=t,null):(e=o.treeContext,ri=sa(a.nextSibling),ni=t,ai=!0,ii=null,null!==e&&(Qa[Ya++]=Ka,Qa[Ya++]=Za,Qa[Ya++]=Ga,Ka=e.id,Za=e.overflow,Ga=t),(t=Uu(t,r.children)).flags|=4096,t)}(e,t,l,a,r,o,n);if(u){u=a.fallback,l=t.mode,r=(o=e.child).sibling;var s={mode:\"hidden\",children:a.children};return 0==(1&l)&&t.child!==o?((a=t.child).childLanes=0,a.pendingProps=s,t.deletions=null):(a=As(o,s)).subtreeFlags=14680064&o.subtreeFlags,null!==r?u=As(r,u):(u=Ds(u,l,n,null)).flags|=2,u.return=t,a.return=t,a.sibling=u,t.child=a,a=u,u=t.child,l=null===(l=e.child.memoizedState)?Ru(n):{baseLanes:l.baseLanes|n,cachePool:null,transitions:l.transitions},u.memoizedState=l,u.childLanes=e.childLanes&~n,t.memoizedState=Du,a}return e=(u=e.child).sibling,a=As(u,{mode:\"visible\",children:a.children}),0==(1&t.mode)&&(a.lanes=n),a.return=t,a.sibling=null,null!==e&&(null===(n=t.deletions)?(t.deletions=[e],t.flags|=16):n.push(e)),t.child=a,t.memoizedState=null,a}function Uu(e,t){return(t=Rs({mode:\"visible\",children:t},e.mode,0,null)).return=e,e.child=t}function Iu(e,t,n,r){return null!==r&&hi(r),Ki(t,e.child,null,n),(e=Uu(t,t.pendingProps.children)).flags|=2,t.memoizedState=null,e}function $u(e,t,n){e.lanes|=t;var r=e.alternate;null!==r&&(r.lanes|=t),ki(e.return,t,n)}function Bu(e,t,n,r,a){var i=e.memoizedState;null===i?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:r,tail:n,tailMode:a}:(i.isBackwards=t,i.rendering=null,i.renderingStartTime=0,i.last=r,i.tail=n,i.tailMode=a)}function Wu(e,t,n){var r=t.pendingProps,a=r.revealOrder,i=r.tail;if(wu(e,t,r.children,n),0!=(2&(r=uo.current)))r=1&r|2,t.flags|=128;else{if(null!==e&&0!=(128&e.flags))e:for(e=t.child;null!==e;){if(13===e.tag)null!==e.memoizedState&&$u(e,n,t);else if(19===e.tag)$u(e,n,t);else if(null!==e.child){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;null===e.sibling;){if(null===e.return||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}r&=1}if(Ca(uo,r),0==(1&t.mode))t.memoizedState=null;else switch(a){case\"forwards\":for(n=t.child,a=null;null!==n;)null!==(e=n.alternate)&&null===lo(e)&&(a=n),n=n.sibling;null===(n=a)?(a=t.child,t.child=null):(a=n.sibling,n.sibling=null),Bu(t,!1,a,n,i);break;case\"backwards\":for(n=null,a=t.child,t.child=null;null!==a;){if(null!==(e=a.alternate)&&null===lo(e)){t.child=a;break}e=a.sibling,a.sibling=n,n=a,a=e}Bu(t,!0,n,null,i);break;case\"together\":Bu(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function Vu(e,t){0==(1&t.mode)&&null!==e&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Hu(e,t,n){if(null!==e&&(t.dependencies=e.dependencies),Rl|=t.lanes,0==(n&t.childLanes))return null;if(null!==e&&t.child!==e.child)throw Error(i(153));if(null!==t.child){for(n=As(e=t.child,e.pendingProps),t.child=n,n.return=t;null!==e.sibling;)e=e.sibling,(n=n.sibling=As(e,e.pendingProps)).return=t;n.sibling=null}return t.child}function qu(e,t){if(!ai)switch(e.tailMode){case\"hidden\":t=e.tail;for(var n=null;null!==t;)null!==t.alternate&&(n=t),t=t.sibling;null===n?e.tail=null:n.sibling=null;break;case\"collapsed\":n=e.tail;for(var r=null;null!==n;)null!==n.alternate&&(r=n),n=n.sibling;null===r?t||null===e.tail?e.tail=null:e.tail.sibling=null:r.sibling=null}}function Qu(e){var t=null!==e.alternate&&e.alternate.child===e.child,n=0,r=0;if(t)for(var a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=14680064&a.subtreeFlags,r|=14680064&a.flags,a.return=e,a=a.sibling;else for(a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=a.subtreeFlags,r|=a.flags,a.return=e,a=a.sibling;return e.subtreeFlags|=r,e.childLanes=n,t}function Yu(e,t,n){var r=t.pendingProps;switch(ti(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Qu(t),null;case 1:case 17:return La(t.type)&&Oa(),Qu(t),null;case 3:return r=t.stateNode,ao(),Ea(Na),Ea(Ma),co(),r.pendingContext&&(r.context=r.pendingContext,r.pendingContext=null),null!==e&&null!==e.child||(fi(t)?t.flags|=4:null===e||e.memoizedState.isDehydrated&&0==(256&t.flags)||(t.flags|=1024,null!==ii&&(us(ii),ii=null))),Ou(e,t),Qu(t),null;case 5:oo(t);var a=no(to.current);if(n=t.type,null!==e&&null!=t.stateNode)Au(e,t,n,r,a),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!r){if(null===t.stateNode)throw Error(i(166));return Qu(t),null}if(e=no(Ji.current),fi(t)){r=t.stateNode,n=t.type;var o=t.memoizedProps;switch(r[pa]=t,r[da]=o,e=0!=(1&t.mode),n){case\"dialog\":Ur(\"cancel\",r),Ur(\"close\",r);break;case\"iframe\":case\"object\":case\"embed\":Ur(\"load\",r);break;case\"video\":case\"audio\":for(a=0;a<Fr.length;a++)Ur(Fr[a],r);break;case\"source\":Ur(\"error\",r);break;case\"img\":case\"image\":case\"link\":Ur(\"error\",r),Ur(\"load\",r);break;case\"details\":Ur(\"toggle\",r);break;case\"input\":K(r,o),Ur(\"invalid\",r);break;case\"select\":r._wrapperState={wasMultiple:!!o.multiple},Ur(\"invalid\",r);break;case\"textarea\":ae(r,o),Ur(\"invalid\",r)}for(var l in me(n,o),a=null,o)if(o.hasOwnProperty(l)){var s=o[l];\"children\"===l?\"string\"==typeof s?r.textContent!==s&&(!0!==o.suppressHydrationWarning&&Xr(r.textContent,s,e),a=[\"children\",s]):\"number\"==typeof s&&r.textContent!==\"\"+s&&(!0!==o.suppressHydrationWarning&&Xr(r.textContent,s,e),a=[\"children\",\"\"+s]):u.hasOwnProperty(l)&&null!=s&&\"onScroll\"===l&&Ur(\"scroll\",r)}switch(n){case\"input\":q(r),J(r,o,!0);break;case\"textarea\":q(r),oe(r);break;case\"select\":case\"option\":break;default:\"function\"==typeof o.onClick&&(r.onclick=Jr)}r=a,t.updateQueue=r,null!==r&&(t.flags|=4)}else{l=9===a.nodeType?a:a.ownerDocument,\"http://www.w3.org/1999/xhtml\"===e&&(e=ue(n)),\"http://www.w3.org/1999/xhtml\"===e?\"script\"===n?((e=l.createElement(\"div\")).innerHTML=\"<script><\\/script>\",e=e.removeChild(e.firstChild)):\"string\"==typeof r.is?e=l.createElement(n,{is:r.is}):(e=l.createElement(n),\"select\"===n&&(l=e,r.multiple?l.multiple=!0:r.size&&(l.size=r.size))):e=l.createElementNS(e,n),e[pa]=t,e[da]=r,Lu(e,t,!1,!1),t.stateNode=e;e:{switch(l=be(n,r),n){case\"dialog\":Ur(\"cancel\",e),Ur(\"close\",e),a=r;break;case\"iframe\":case\"object\":case\"embed\":Ur(\"load\",e),a=r;break;case\"video\":case\"audio\":for(a=0;a<Fr.length;a++)Ur(Fr[a],e);a=r;break;case\"source\":Ur(\"error\",e),a=r;break;case\"img\":case\"image\":case\"link\":Ur(\"error\",e),Ur(\"load\",e),a=r;break;case\"details\":Ur(\"toggle\",e),a=r;break;case\"input\":K(e,r),a=G(e,r),Ur(\"invalid\",e);break;case\"option\":default:a=r;break;case\"select\":e._wrapperState={wasMultiple:!!r.multiple},a=R({},r,{value:void 0}),Ur(\"invalid\",e);break;case\"textarea\":ae(e,r),a=re(e,r),Ur(\"invalid\",e)}for(o in me(n,a),s=a)if(s.hasOwnProperty(o)){var c=s[o];\"style\"===o?ge(e,c):\"dangerouslySetInnerHTML\"===o?null!=(c=c?c.__html:void 0)&&fe(e,c):\"children\"===o?\"string\"==typeof c?(\"textarea\"!==n||\"\"!==c)&&pe(e,c):\"number\"==typeof c&&pe(e,\"\"+c):\"suppressContentEditableWarning\"!==o&&\"suppressHydrationWarning\"!==o&&\"autoFocus\"!==o&&(u.hasOwnProperty(o)?null!=c&&\"onScroll\"===o&&Ur(\"scroll\",e):null!=c&&b(e,o,c,l))}switch(n){case\"input\":q(e),J(e,r,!1);break;case\"textarea\":q(e),oe(e);break;case\"option\":null!=r.value&&e.setAttribute(\"value\",\"\"+V(r.value));break;case\"select\":e.multiple=!!r.multiple,null!=(o=r.value)?ne(e,!!r.multiple,o,!1):null!=r.defaultValue&&ne(e,!!r.multiple,r.defaultValue,!0);break;default:\"function\"==typeof a.onClick&&(e.onclick=Jr)}switch(n){case\"button\":case\"input\":case\"select\":case\"textarea\":r=!!r.autoFocus;break e;case\"img\":r=!0;break e;default:r=!1}}r&&(t.flags|=4)}null!==t.ref&&(t.flags|=512,t.flags|=2097152)}return Qu(t),null;case 6:if(e&&null!=t.stateNode)Fu(e,t,e.memoizedProps,r);else{if(\"string\"!=typeof r&&null===t.stateNode)throw Error(i(166));if(n=no(to.current),no(Ji.current),fi(t)){if(r=t.stateNode,n=t.memoizedProps,r[pa]=t,(o=r.nodeValue!==n)&&null!==(e=ni))switch(e.tag){case 3:Xr(r.nodeValue,n,0!=(1&e.mode));break;case 5:!0!==e.memoizedProps.suppressHydrationWarning&&Xr(r.nodeValue,n,0!=(1&e.mode))}o&&(t.flags|=4)}else(r=(9===n.nodeType?n:n.ownerDocument).createTextNode(r))[pa]=t,t.stateNode=r}return Qu(t),null;case 13:if(Ea(uo),r=t.memoizedState,null===e||null!==e.memoizedState&&null!==e.memoizedState.dehydrated){if(ai&&null!==ri&&0!=(1&t.mode)&&0==(128&t.flags))pi(),di(),t.flags|=98560,o=!1;else if(o=fi(t),null!==r&&null!==r.dehydrated){if(null===e){if(!o)throw Error(i(318));if(!(o=null!==(o=t.memoizedState)?o.dehydrated:null))throw Error(i(317));o[pa]=t}else di(),0==(128&t.flags)&&(t.memoizedState=null),t.flags|=4;Qu(t),o=!1}else null!==ii&&(us(ii),ii=null),o=!0;if(!o)return 65536&t.flags?t:null}return 0!=(128&t.flags)?(t.lanes=n,t):((r=null!==r)!=(null!==e&&null!==e.memoizedState)&&r&&(t.child.flags|=8192,0!=(1&t.mode)&&(null===e||0!=(1&uo.current)?0===Fl&&(Fl=3):gs())),null!==t.updateQueue&&(t.flags|=4),Qu(t),null);case 4:return ao(),Ou(e,t),null===e&&Br(t.stateNode.containerInfo),Qu(t),null;case 10:return xi(t.type._context),Qu(t),null;case 19:if(Ea(uo),null===(o=t.memoizedState))return Qu(t),null;if(r=0!=(128&t.flags),null===(l=o.rendering))if(r)qu(o,!1);else{if(0!==Fl||null!==e&&0!=(128&e.flags))for(e=t.child;null!==e;){if(null!==(l=lo(e))){for(t.flags|=128,qu(o,!1),null!==(r=l.updateQueue)&&(t.updateQueue=r,t.flags|=4),t.subtreeFlags=0,r=n,n=t.child;null!==n;)e=r,(o=n).flags&=14680066,null===(l=o.alternate)?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=l.childLanes,o.lanes=l.lanes,o.child=l.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=l.memoizedProps,o.memoizedState=l.memoizedState,o.updateQueue=l.updateQueue,o.type=l.type,e=l.dependencies,o.dependencies=null===e?null:{lanes:e.lanes,firstContext:e.firstContext}),n=n.sibling;return Ca(uo,1&uo.current|2),t.child}e=e.sibling}null!==o.tail&&Ze()>Wl&&(t.flags|=128,r=!0,qu(o,!1),t.lanes=4194304)}else{if(!r)if(null!==(e=lo(l))){if(t.flags|=128,r=!0,null!==(n=e.updateQueue)&&(t.updateQueue=n,t.flags|=4),qu(o,!0),null===o.tail&&\"hidden\"===o.tailMode&&!l.alternate&&!ai)return Qu(t),null}else 2*Ze()-o.renderingStartTime>Wl&&1073741824!==n&&(t.flags|=128,r=!0,qu(o,!1),t.lanes=4194304);o.isBackwards?(l.sibling=t.child,t.child=l):(null!==(n=o.last)?n.sibling=l:t.child=l,o.last=l)}return null!==o.tail?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=Ze(),t.sibling=null,n=uo.current,Ca(uo,r?1&n|2:1&n),t):(Qu(t),null);case 22:case 23:return ps(),r=null!==t.memoizedState,null!==e&&null!==e.memoizedState!==r&&(t.flags|=8192),r&&0!=(1&t.mode)?0!=(1073741824&Ol)&&(Qu(t),6&t.subtreeFlags&&(t.flags|=8192)):Qu(t),null;case 24:case 25:return null}throw Error(i(156,t.tag))}function Gu(e,t){switch(ti(t),t.tag){case 1:return La(t.type)&&Oa(),65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 3:return ao(),Ea(Na),Ea(Ma),co(),0!=(65536&(e=t.flags))&&0==(128&e)?(t.flags=-65537&e|128,t):null;case 5:return oo(t),null;case 13:if(Ea(uo),null!==(e=t.memoizedState)&&null!==e.dehydrated){if(null===t.alternate)throw Error(i(340));di()}return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 19:return Ea(uo),null;case 4:return ao(),null;case 10:return xi(t.type._context),null;case 22:case 23:return ps(),null;default:return null}}Lu=function(e,t){for(var n=t.child;null!==n;){if(5===n.tag||6===n.tag)e.appendChild(n.stateNode);else if(4!==n.tag&&null!==n.child){n.child.return=n,n=n.child;continue}if(n===t)break;for(;null===n.sibling;){if(null===n.return||n.return===t)return;n=n.return}n.sibling.return=n.return,n=n.sibling}},Ou=function(){},Au=function(e,t,n,r){var a=e.memoizedProps;if(a!==r){e=t.stateNode,no(Ji.current);var i,o=null;switch(n){case\"input\":a=G(e,a),r=G(e,r),o=[];break;case\"select\":a=R({},a,{value:void 0}),r=R({},r,{value:void 0}),o=[];break;case\"textarea\":a=re(e,a),r=re(e,r),o=[];break;default:\"function\"!=typeof a.onClick&&\"function\"==typeof r.onClick&&(e.onclick=Jr)}for(c in me(n,r),n=null,a)if(!r.hasOwnProperty(c)&&a.hasOwnProperty(c)&&null!=a[c])if(\"style\"===c){var l=a[c];for(i in l)l.hasOwnProperty(i)&&(n||(n={}),n[i]=\"\")}else\"dangerouslySetInnerHTML\"!==c&&\"children\"!==c&&\"suppressContentEditableWarning\"!==c&&\"suppressHydrationWarning\"!==c&&\"autoFocus\"!==c&&(u.hasOwnProperty(c)?o||(o=[]):(o=o||[]).push(c,null));for(c in r){var s=r[c];if(l=null!=a?a[c]:void 0,r.hasOwnProperty(c)&&s!==l&&(null!=s||null!=l))if(\"style\"===c)if(l){for(i in l)!l.hasOwnProperty(i)||s&&s.hasOwnProperty(i)||(n||(n={}),n[i]=\"\");for(i in s)s.hasOwnProperty(i)&&l[i]!==s[i]&&(n||(n={}),n[i]=s[i])}else n||(o||(o=[]),o.push(c,n)),n=s;else\"dangerouslySetInnerHTML\"===c?(s=s?s.__html:void 0,l=l?l.__html:void 0,null!=s&&l!==s&&(o=o||[]).push(c,s)):\"children\"===c?\"string\"!=typeof s&&\"number\"!=typeof s||(o=o||[]).push(c,\"\"+s):\"suppressContentEditableWarning\"!==c&&\"suppressHydrationWarning\"!==c&&(u.hasOwnProperty(c)?(null!=s&&\"onScroll\"===c&&Ur(\"scroll\",e),o||l===s||(o=[])):(o=o||[]).push(c,s))}n&&(o=o||[]).push(\"style\",n);var c=o;(t.updateQueue=c)&&(t.flags|=4)}},Fu=function(e,t,n,r){n!==r&&(t.flags|=4)};var Ku=!1,Zu=!1,Xu=\"function\"==typeof WeakSet?WeakSet:Set,Ju=null;function el(e,t){var n=e.ref;if(null!==n)if(\"function\"==typeof n)try{n(null)}catch(n){Es(e,t,n)}else n.current=null}function tl(e,t,n){try{n()}catch(n){Es(e,t,n)}}var nl=!1;function rl(e,t,n){var r=t.updateQueue;if(null!==(r=null!==r?r.lastEffect:null)){var a=r=r.next;do{if((a.tag&e)===e){var i=a.destroy;a.destroy=void 0,void 0!==i&&tl(t,n,i)}a=a.next}while(a!==r)}}function al(e,t){if(null!==(t=null!==(t=t.updateQueue)?t.lastEffect:null)){var n=t=t.next;do{if((n.tag&e)===e){var r=n.create;n.destroy=r()}n=n.next}while(n!==t)}}function il(e){var t=e.ref;if(null!==t){var n=e.stateNode;e.tag,e=n,\"function\"==typeof t?t(e):t.current=e}}function ol(e){var t=e.alternate;null!==t&&(e.alternate=null,ol(t)),e.child=null,e.deletions=null,e.sibling=null,5===e.tag&&null!==(t=e.stateNode)&&(delete t[pa],delete t[da],delete t[va],delete t[ga],delete t[ya]),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function ul(e){return 5===e.tag||3===e.tag||4===e.tag}function ll(e){e:for(;;){for(;null===e.sibling;){if(null===e.return||ul(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;5!==e.tag&&6!==e.tag&&18!==e.tag;){if(2&e.flags)continue e;if(null===e.child||4===e.tag)continue e;e.child.return=e,e=e.child}if(!(2&e.flags))return e.stateNode}}function sl(e,t,n){var r=e.tag;if(5===r||6===r)e=e.stateNode,t?8===n.nodeType?n.parentNode.insertBefore(e,t):n.insertBefore(e,t):(8===n.nodeType?(t=n.parentNode).insertBefore(e,n):(t=n).appendChild(e),null!=(n=n._reactRootContainer)||null!==t.onclick||(t.onclick=Jr));else if(4!==r&&null!==(e=e.child))for(sl(e,t,n),e=e.sibling;null!==e;)sl(e,t,n),e=e.sibling}function cl(e,t,n){var r=e.tag;if(5===r||6===r)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(4!==r&&null!==(e=e.child))for(cl(e,t,n),e=e.sibling;null!==e;)cl(e,t,n),e=e.sibling}var fl=null,pl=!1;function dl(e,t,n){for(n=n.child;null!==n;)hl(e,t,n),n=n.sibling}function hl(e,t,n){if(it&&\"function\"==typeof it.onCommitFiberUnmount)try{it.onCommitFiberUnmount(at,n)}catch(e){}switch(n.tag){case 5:Zu||el(n,t);case 6:var r=fl,a=pl;fl=null,dl(e,t,n),pl=a,null!==(fl=r)&&(pl?(e=fl,n=n.stateNode,8===e.nodeType?e.parentNode.removeChild(n):e.removeChild(n)):fl.removeChild(n.stateNode));break;case 18:null!==fl&&(pl?(e=fl,n=n.stateNode,8===e.nodeType?la(e.parentNode,n):1===e.nodeType&&la(e,n),Bt(e)):la(fl,n.stateNode));break;case 4:r=fl,a=pl,fl=n.stateNode.containerInfo,pl=!0,dl(e,t,n),fl=r,pl=a;break;case 0:case 11:case 14:case 15:if(!Zu&&null!==(r=n.updateQueue)&&null!==(r=r.lastEffect)){a=r=r.next;do{var i=a,o=i.destroy;i=i.tag,void 0!==o&&(0!=(2&i)||0!=(4&i))&&tl(n,t,o),a=a.next}while(a!==r)}dl(e,t,n);break;case 1:if(!Zu&&(el(n,t),\"function\"==typeof(r=n.stateNode).componentWillUnmount))try{r.props=n.memoizedProps,r.state=n.memoizedState,r.componentWillUnmount()}catch(e){Es(n,t,e)}dl(e,t,n);break;case 21:dl(e,t,n);break;case 22:1&n.mode?(Zu=(r=Zu)||null!==n.memoizedState,dl(e,t,n),Zu=r):dl(e,t,n);break;default:dl(e,t,n)}}function vl(e){var t=e.updateQueue;if(null!==t){e.updateQueue=null;var n=e.stateNode;null===n&&(n=e.stateNode=new Xu),t.forEach((function(t){var r=Ns.bind(null,e,t);n.has(t)||(n.add(t),t.then(r,r))}))}}function gl(e,t){var n=t.deletions;if(null!==n)for(var r=0;r<n.length;r++){var a=n[r];try{var o=e,u=t,l=u;e:for(;null!==l;){switch(l.tag){case 5:fl=l.stateNode,pl=!1;break e;case 3:case 4:fl=l.stateNode.containerInfo,pl=!0;break e}l=l.return}if(null===fl)throw Error(i(160));hl(o,u,a),fl=null,pl=!1;var s=a.alternate;null!==s&&(s.return=null),a.return=null}catch(e){Es(a,t,e)}}if(12854&t.subtreeFlags)for(t=t.child;null!==t;)yl(t,e),t=t.sibling}function yl(e,t){var n=e.alternate,r=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(gl(t,e),ml(e),4&r){try{rl(3,e,e.return),al(3,e)}catch(t){Es(e,e.return,t)}try{rl(5,e,e.return)}catch(t){Es(e,e.return,t)}}break;case 1:gl(t,e),ml(e),512&r&&null!==n&&el(n,n.return);break;case 5:if(gl(t,e),ml(e),512&r&&null!==n&&el(n,n.return),32&e.flags){var a=e.stateNode;try{pe(a,\"\")}catch(t){Es(e,e.return,t)}}if(4&r&&null!=(a=e.stateNode)){var o=e.memoizedProps,u=null!==n?n.memoizedProps:o,l=e.type,s=e.updateQueue;if(e.updateQueue=null,null!==s)try{\"input\"===l&&\"radio\"===o.type&&null!=o.name&&Z(a,o),be(l,u);var c=be(l,o);for(u=0;u<s.length;u+=2){var f=s[u],p=s[u+1];\"style\"===f?ge(a,p):\"dangerouslySetInnerHTML\"===f?fe(a,p):\"children\"===f?pe(a,p):b(a,f,p,c)}switch(l){case\"input\":X(a,o);break;case\"textarea\":ie(a,o);break;case\"select\":var d=a._wrapperState.wasMultiple;a._wrapperState.wasMultiple=!!o.multiple;var h=o.value;null!=h?ne(a,!!o.multiple,h,!1):d!==!!o.multiple&&(null!=o.defaultValue?ne(a,!!o.multiple,o.defaultValue,!0):ne(a,!!o.multiple,o.multiple?[]:\"\",!1))}a[da]=o}catch(t){Es(e,e.return,t)}}break;case 6:if(gl(t,e),ml(e),4&r){if(null===e.stateNode)throw Error(i(162));a=e.stateNode,o=e.memoizedProps;try{a.nodeValue=o}catch(t){Es(e,e.return,t)}}break;case 3:if(gl(t,e),ml(e),4&r&&null!==n&&n.memoizedState.isDehydrated)try{Bt(t.containerInfo)}catch(t){Es(e,e.return,t)}break;case 4:default:gl(t,e),ml(e);break;case 13:gl(t,e),ml(e),8192&(a=e.child).flags&&(o=null!==a.memoizedState,a.stateNode.isHidden=o,!o||null!==a.alternate&&null!==a.alternate.memoizedState||(Bl=Ze())),4&r&&vl(e);break;case 22:if(f=null!==n&&null!==n.memoizedState,1&e.mode?(Zu=(c=Zu)||f,gl(t,e),Zu=c):gl(t,e),ml(e),8192&r){if(c=null!==e.memoizedState,(e.stateNode.isHidden=c)&&!f&&0!=(1&e.mode))for(Ju=e,f=e.child;null!==f;){for(p=Ju=f;null!==Ju;){switch(h=(d=Ju).child,d.tag){case 0:case 11:case 14:case 15:rl(4,d,d.return);break;case 1:el(d,d.return);var v=d.stateNode;if(\"function\"==typeof v.componentWillUnmount){r=d,n=d.return;try{t=r,v.props=t.memoizedProps,v.state=t.memoizedState,v.componentWillUnmount()}catch(e){Es(r,n,e)}}break;case 5:el(d,d.return);break;case 22:if(null!==d.memoizedState){xl(p);continue}}null!==h?(h.return=d,Ju=h):xl(p)}f=f.sibling}e:for(f=null,p=e;;){if(5===p.tag){if(null===f){f=p;try{a=p.stateNode,c?\"function\"==typeof(o=a.style).setProperty?o.setProperty(\"display\",\"none\",\"important\"):o.display=\"none\":(l=p.stateNode,u=null!=(s=p.memoizedProps.style)&&s.hasOwnProperty(\"display\")?s.display:null,l.style.display=ve(\"display\",u))}catch(t){Es(e,e.return,t)}}}else if(6===p.tag){if(null===f)try{p.stateNode.nodeValue=c?\"\":p.memoizedProps}catch(t){Es(e,e.return,t)}}else if((22!==p.tag&&23!==p.tag||null===p.memoizedState||p===e)&&null!==p.child){p.child.return=p,p=p.child;continue}if(p===e)break e;for(;null===p.sibling;){if(null===p.return||p.return===e)break e;f===p&&(f=null),p=p.return}f===p&&(f=null),p.sibling.return=p.return,p=p.sibling}}break;case 19:gl(t,e),ml(e),4&r&&vl(e);case 21:}}function ml(e){var t=e.flags;if(2&t){try{e:{for(var n=e.return;null!==n;){if(ul(n)){var r=n;break e}n=n.return}throw Error(i(160))}switch(r.tag){case 5:var a=r.stateNode;32&r.flags&&(pe(a,\"\"),r.flags&=-33),cl(e,ll(e),a);break;case 3:case 4:var o=r.stateNode.containerInfo;sl(e,ll(e),o);break;default:throw Error(i(161))}}catch(t){Es(e,e.return,t)}e.flags&=-3}4096&t&&(e.flags&=-4097)}function bl(e,t,n){Ju=e,_l(e,t,n)}function _l(e,t,n){for(var r=0!=(1&e.mode);null!==Ju;){var a=Ju,i=a.child;if(22===a.tag&&r){var o=null!==a.memoizedState||Ku;if(!o){var u=a.alternate,l=null!==u&&null!==u.memoizedState||Zu;u=Ku;var s=Zu;if(Ku=o,(Zu=l)&&!s)for(Ju=a;null!==Ju;)l=(o=Ju).child,22===o.tag&&null!==o.memoizedState?kl(a):null!==l?(l.return=o,Ju=l):kl(a);for(;null!==i;)Ju=i,_l(i,t,n),i=i.sibling;Ju=a,Ku=u,Zu=s}wl(e)}else 0!=(8772&a.subtreeFlags)&&null!==i?(i.return=a,Ju=i):wl(e)}}function wl(e){for(;null!==Ju;){var t=Ju;if(0!=(8772&t.flags)){var n=t.alternate;try{if(0!=(8772&t.flags))switch(t.tag){case 0:case 11:case 15:Zu||al(5,t);break;case 1:var r=t.stateNode;if(4&t.flags&&!Zu)if(null===n)r.componentDidMount();else{var a=t.elementType===t.type?n.memoizedProps:gi(t.type,n.memoizedProps);r.componentDidUpdate(a,n.memoizedState,r.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;null!==o&&ji(t,o,r);break;case 3:var u=t.updateQueue;if(null!==u){if(n=null,null!==t.child)switch(t.child.tag){case 5:case 1:n=t.child.stateNode}ji(t,u,n)}break;case 5:var l=t.stateNode;if(null===n&&4&t.flags){n=l;var s=t.memoizedProps;switch(t.type){case\"button\":case\"input\":case\"select\":case\"textarea\":s.autoFocus&&n.focus();break;case\"img\":s.src&&(n.src=s.src)}}break;case 6:case 4:case 12:case 19:case 17:case 21:case 22:case 23:case 25:break;case 13:if(null===t.memoizedState){var c=t.alternate;if(null!==c){var f=c.memoizedState;if(null!==f){var p=f.dehydrated;null!==p&&Bt(p)}}}break;default:throw Error(i(163))}Zu||512&t.flags&&il(t)}catch(e){Es(t,t.return,e)}}if(t===e){Ju=null;break}if(null!==(n=t.sibling)){n.return=t.return,Ju=n;break}Ju=t.return}}function xl(e){for(;null!==Ju;){var t=Ju;if(t===e){Ju=null;break}var n=t.sibling;if(null!==n){n.return=t.return,Ju=n;break}Ju=t.return}}function kl(e){for(;null!==Ju;){var t=Ju;try{switch(t.tag){case 0:case 11:case 15:var n=t.return;try{al(4,t)}catch(e){Es(t,n,e)}break;case 1:var r=t.stateNode;if(\"function\"==typeof r.componentDidMount){var a=t.return;try{r.componentDidMount()}catch(e){Es(t,a,e)}}var i=t.return;try{il(t)}catch(e){Es(t,i,e)}break;case 5:var o=t.return;try{il(t)}catch(e){Es(t,o,e)}}}catch(e){Es(t,t.return,e)}if(t===e){Ju=null;break}var u=t.sibling;if(null!==u){u.return=t.return,Ju=u;break}Ju=t.return}}var Sl,El=Math.ceil,Cl=_.ReactCurrentDispatcher,Tl=_.ReactCurrentOwner,Ml=_.ReactCurrentBatchConfig,Nl=0,Pl=null,zl=null,Ll=0,Ol=0,Al=Sa(0),Fl=0,Dl=null,Rl=0,jl=0,Ul=0,Il=null,$l=null,Bl=0,Wl=1/0,Vl=null,Hl=!1,ql=null,Ql=null,Yl=!1,Gl=null,Kl=0,Zl=0,Xl=null,Jl=-1,es=0;function ts(){return 0!=(6&Nl)?Ze():-1!==Jl?Jl:Jl=Ze()}function ns(e){return 0==(1&e.mode)?1:0!=(2&Nl)&&0!==Ll?Ll&-Ll:null!==vi.transition?(0===es&&(es=vt()),es):0!==(e=bt)?e:e=void 0===(e=window.event)?16:Kt(e.type)}function rs(e,t,n,r){if(50<Zl)throw Zl=0,Xl=null,Error(i(185));yt(e,n,r),0!=(2&Nl)&&e===Pl||(e===Pl&&(0==(2&Nl)&&(jl|=n),4===Fl&&ls(e,Ll)),as(e,r),1===n&&0===Nl&&0==(1&t.mode)&&(Wl=Ze()+500,Ua&&Ba()))}function as(e,t){var n=e.callbackNode;!function(e,t){for(var n=e.suspendedLanes,r=e.pingedLanes,a=e.expirationTimes,i=e.pendingLanes;0<i;){var o=31-ot(i),u=1<<o,l=a[o];-1===l?0!=(u&n)&&0==(u&r)||(a[o]=dt(u,t)):l<=t&&(e.expiredLanes|=u),i&=~u}}(e,t);var r=pt(e,e===Pl?Ll:0);if(0===r)null!==n&&Ye(n),e.callbackNode=null,e.callbackPriority=0;else if(t=r&-r,e.callbackPriority!==t){if(null!=n&&Ye(n),1===t)0===e.tag?function(e){Ua=!0,$a(e)}(ss.bind(null,e)):$a(ss.bind(null,e)),oa((function(){0==(6&Nl)&&Ba()})),n=null;else{switch(_t(r)){case 1:n=Je;break;case 4:n=et;break;case 16:default:n=tt;break;case 536870912:n=rt}n=Ps(n,is.bind(null,e))}e.callbackPriority=t,e.callbackNode=n}}function is(e,t){if(Jl=-1,es=0,0!=(6&Nl))throw Error(i(327));var n=e.callbackNode;if(ks()&&e.callbackNode!==n)return null;var r=pt(e,e===Pl?Ll:0);if(0===r)return null;if(0!=(30&r)||0!=(r&e.expiredLanes)||t)t=ys(e,r);else{t=r;var a=Nl;Nl|=2;var o=vs();for(Pl===e&&Ll===t||(Vl=null,Wl=Ze()+500,ds(e,t));;)try{bs();break}catch(t){hs(e,t)}wi(),Cl.current=o,Nl=a,null!==zl?t=0:(Pl=null,Ll=0,t=Fl)}if(0!==t){if(2===t&&0!==(a=ht(e))&&(r=a,t=os(e,a)),1===t)throw n=Dl,ds(e,0),ls(e,r),as(e,Ze()),n;if(6===t)ls(e,r);else{if(a=e.current.alternate,0==(30&r)&&!function(e){for(var t=e;;){if(16384&t.flags){var n=t.updateQueue;if(null!==n&&null!==(n=n.stores))for(var r=0;r<n.length;r++){var a=n[r],i=a.getSnapshot;a=a.value;try{if(!ur(i(),a))return!1}catch(e){return!1}}}if(n=t.child,16384&t.subtreeFlags&&null!==n)n.return=t,t=n;else{if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}(a)&&(2===(t=ys(e,r))&&0!==(o=ht(e))&&(r=o,t=os(e,o)),1===t))throw n=Dl,ds(e,0),ls(e,r),as(e,Ze()),n;switch(e.finishedWork=a,e.finishedLanes=r,t){case 0:case 1:throw Error(i(345));case 2:case 5:xs(e,$l,Vl);break;case 3:if(ls(e,r),(130023424&r)===r&&10<(t=Bl+500-Ze())){if(0!==pt(e,0))break;if(((a=e.suspendedLanes)&r)!==r){ts(),e.pingedLanes|=e.suspendedLanes&a;break}e.timeoutHandle=ra(xs.bind(null,e,$l,Vl),t);break}xs(e,$l,Vl);break;case 4:if(ls(e,r),(4194240&r)===r)break;for(t=e.eventTimes,a=-1;0<r;){var u=31-ot(r);o=1<<u,(u=t[u])>a&&(a=u),r&=~o}if(r=a,10<(r=(120>(r=Ze()-r)?120:480>r?480:1080>r?1080:1920>r?1920:3e3>r?3e3:4320>r?4320:1960*El(r/1960))-r)){e.timeoutHandle=ra(xs.bind(null,e,$l,Vl),r);break}xs(e,$l,Vl);break;default:throw Error(i(329))}}}return as(e,Ze()),e.callbackNode===n?is.bind(null,e):null}function os(e,t){var n=Il;return e.current.memoizedState.isDehydrated&&(ds(e,t).flags|=256),2!==(e=ys(e,t))&&(t=$l,$l=n,null!==t&&us(t)),e}function us(e){null===$l?$l=e:$l.push.apply($l,e)}function ls(e,t){for(t&=~Ul,t&=~jl,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var n=31-ot(t),r=1<<n;e[n]=-1,t&=~r}}function ss(e){if(0!=(6&Nl))throw Error(i(327));ks();var t=pt(e,0);if(0==(1&t))return as(e,Ze()),null;var n=ys(e,t);if(0!==e.tag&&2===n){var r=ht(e);0!==r&&(t=r,n=os(e,r))}if(1===n)throw n=Dl,ds(e,0),ls(e,t),as(e,Ze()),n;if(6===n)throw Error(i(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,xs(e,$l,Vl),as(e,Ze()),null}function cs(e,t){var n=Nl;Nl|=1;try{return e(t)}finally{0===(Nl=n)&&(Wl=Ze()+500,Ua&&Ba())}}function fs(e){null!==Gl&&0===Gl.tag&&0==(6&Nl)&&ks();var t=Nl;Nl|=1;var n=Ml.transition,r=bt;try{if(Ml.transition=null,bt=1,e)return e()}finally{bt=r,Ml.transition=n,0==(6&(Nl=t))&&Ba()}}function ps(){Ol=Al.current,Ea(Al)}function ds(e,t){e.finishedWork=null,e.finishedLanes=0;var n=e.timeoutHandle;if(-1!==n&&(e.timeoutHandle=-1,aa(n)),null!==zl)for(n=zl.return;null!==n;){var r=n;switch(ti(r),r.tag){case 1:null!=(r=r.type.childContextTypes)&&Oa();break;case 3:ao(),Ea(Na),Ea(Ma),co();break;case 5:oo(r);break;case 4:ao();break;case 13:case 19:Ea(uo);break;case 10:xi(r.type._context);break;case 22:case 23:ps()}n=n.return}if(Pl=e,zl=e=As(e.current,null),Ll=Ol=t,Fl=0,Dl=null,Ul=jl=Rl=0,$l=Il=null,null!==Ci){for(t=0;t<Ci.length;t++)if(null!==(r=(n=Ci[t]).interleaved)){n.interleaved=null;var a=r.next,i=n.pending;if(null!==i){var o=i.next;i.next=a,r.next=o}n.pending=r}Ci=null}return e}function hs(e,t){for(;;){var n=zl;try{if(wi(),fo.current=ou,mo){for(var r=vo.memoizedState;null!==r;){var a=r.queue;null!==a&&(a.pending=null),r=r.next}mo=!1}if(ho=0,yo=go=vo=null,bo=!1,_o=0,Tl.current=null,null===n||null===n.return){Fl=1,Dl=t,zl=null;break}e:{var o=e,u=n.return,l=n,s=t;if(t=Ll,l.flags|=32768,null!==s&&\"object\"==typeof s&&\"function\"==typeof s.then){var c=s,f=l,p=f.tag;if(0==(1&f.mode)&&(0===p||11===p||15===p)){var d=f.alternate;d?(f.updateQueue=d.updateQueue,f.memoizedState=d.memoizedState,f.lanes=d.lanes):(f.updateQueue=null,f.memoizedState=null)}var h=yu(u);if(null!==h){h.flags&=-257,mu(h,u,l,0,t),1&h.mode&&gu(o,c,t),s=c;var v=(t=h).updateQueue;if(null===v){var g=new Set;g.add(s),t.updateQueue=g}else v.add(s);break e}if(0==(1&t)){gu(o,c,t),gs();break e}s=Error(i(426))}else if(ai&&1&l.mode){var y=yu(u);if(null!==y){0==(65536&y.flags)&&(y.flags|=256),mu(y,u,l,0,t),hi(cu(s,l));break e}}o=s=cu(s,l),4!==Fl&&(Fl=2),null===Il?Il=[o]:Il.push(o),o=u;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t,Di(o,hu(0,s,t));break e;case 1:l=s;var m=o.type,b=o.stateNode;if(0==(128&o.flags)&&(\"function\"==typeof m.getDerivedStateFromError||null!==b&&\"function\"==typeof b.componentDidCatch&&(null===Ql||!Ql.has(b)))){o.flags|=65536,t&=-t,o.lanes|=t,Di(o,vu(o,l,t));break e}}o=o.return}while(null!==o)}ws(n)}catch(e){t=e,zl===n&&null!==n&&(zl=n=n.return);continue}break}}function vs(){var e=Cl.current;return Cl.current=ou,null===e?ou:e}function gs(){0!==Fl&&3!==Fl&&2!==Fl||(Fl=4),null===Pl||0==(268435455&Rl)&&0==(268435455&jl)||ls(Pl,Ll)}function ys(e,t){var n=Nl;Nl|=2;var r=vs();for(Pl===e&&Ll===t||(Vl=null,ds(e,t));;)try{ms();break}catch(t){hs(e,t)}if(wi(),Nl=n,Cl.current=r,null!==zl)throw Error(i(261));return Pl=null,Ll=0,Fl}function ms(){for(;null!==zl;)_s(zl)}function bs(){for(;null!==zl&&!Ge();)_s(zl)}function _s(e){var t=Sl(e.alternate,e,Ol);e.memoizedProps=e.pendingProps,null===t?ws(e):zl=t,Tl.current=null}function ws(e){var t=e;do{var n=t.alternate;if(e=t.return,0==(32768&t.flags)){if(null!==(n=Yu(n,t,Ol)))return void(zl=n)}else{if(null!==(n=Gu(n,t)))return n.flags&=32767,void(zl=n);if(null===e)return Fl=6,void(zl=null);e.flags|=32768,e.subtreeFlags=0,e.deletions=null}if(null!==(t=t.sibling))return void(zl=t);zl=t=e}while(null!==t);0===Fl&&(Fl=5)}function xs(e,t,n){var r=bt,a=Ml.transition;try{Ml.transition=null,bt=1,function(e,t,n,r){do{ks()}while(null!==Gl);if(0!=(6&Nl))throw Error(i(327));n=e.finishedWork;var a=e.finishedLanes;if(null===n)return null;if(e.finishedWork=null,e.finishedLanes=0,n===e.current)throw Error(i(177));e.callbackNode=null,e.callbackPriority=0;var o=n.lanes|n.childLanes;if(function(e,t){var n=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var r=e.eventTimes;for(e=e.expirationTimes;0<n;){var a=31-ot(n),i=1<<a;t[a]=0,r[a]=-1,e[a]=-1,n&=~i}}(e,o),e===Pl&&(zl=Pl=null,Ll=0),0==(2064&n.subtreeFlags)&&0==(2064&n.flags)||Yl||(Yl=!0,Ps(tt,(function(){return ks(),null}))),o=0!=(15990&n.flags),0!=(15990&n.subtreeFlags)||o){o=Ml.transition,Ml.transition=null;var u=bt;bt=1;var l=Nl;Nl|=4,Tl.current=null,function(e,t){if(ea=Vt,dr(e=pr())){if(\"selectionStart\"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{var r=(n=(n=e.ownerDocument)&&n.defaultView||window).getSelection&&n.getSelection();if(r&&0!==r.rangeCount){n=r.anchorNode;var a=r.anchorOffset,o=r.focusNode;r=r.focusOffset;try{n.nodeType,o.nodeType}catch(e){n=null;break e}var u=0,l=-1,s=-1,c=0,f=0,p=e,d=null;t:for(;;){for(var h;p!==n||0!==a&&3!==p.nodeType||(l=u+a),p!==o||0!==r&&3!==p.nodeType||(s=u+r),3===p.nodeType&&(u+=p.nodeValue.length),null!==(h=p.firstChild);)d=p,p=h;for(;;){if(p===e)break t;if(d===n&&++c===a&&(l=u),d===o&&++f===r&&(s=u),null!==(h=p.nextSibling))break;d=(p=d).parentNode}p=h}n=-1===l||-1===s?null:{start:l,end:s}}else n=null}n=n||{start:0,end:0}}else n=null;for(ta={focusedElem:e,selectionRange:n},Vt=!1,Ju=t;null!==Ju;)if(e=(t=Ju).child,0!=(1028&t.subtreeFlags)&&null!==e)e.return=t,Ju=e;else for(;null!==Ju;){t=Ju;try{var v=t.alternate;if(0!=(1024&t.flags))switch(t.tag){case 0:case 11:case 15:case 5:case 6:case 4:case 17:break;case 1:if(null!==v){var g=v.memoizedProps,y=v.memoizedState,m=t.stateNode,b=m.getSnapshotBeforeUpdate(t.elementType===t.type?g:gi(t.type,g),y);m.__reactInternalSnapshotBeforeUpdate=b}break;case 3:var _=t.stateNode.containerInfo;1===_.nodeType?_.textContent=\"\":9===_.nodeType&&_.documentElement&&_.removeChild(_.documentElement);break;default:throw Error(i(163))}}catch(e){Es(t,t.return,e)}if(null!==(e=t.sibling)){e.return=t.return,Ju=e;break}Ju=t.return}v=nl,nl=!1}(e,n),yl(n,e),hr(ta),Vt=!!ea,ta=ea=null,e.current=n,bl(n,e,a),Ke(),Nl=l,bt=u,Ml.transition=o}else e.current=n;if(Yl&&(Yl=!1,Gl=e,Kl=a),0===(o=e.pendingLanes)&&(Ql=null),function(e){if(it&&\"function\"==typeof it.onCommitFiberRoot)try{it.onCommitFiberRoot(at,e,void 0,128==(128&e.current.flags))}catch(e){}}(n.stateNode),as(e,Ze()),null!==t)for(r=e.onRecoverableError,n=0;n<t.length;n++)r((a=t[n]).value,{componentStack:a.stack,digest:a.digest});if(Hl)throw Hl=!1,e=ql,ql=null,e;0!=(1&Kl)&&0!==e.tag&&ks(),0!=(1&(o=e.pendingLanes))?e===Xl?Zl++:(Zl=0,Xl=e):Zl=0,Ba()}(e,t,n,r)}finally{Ml.transition=a,bt=r}return null}function ks(){if(null!==Gl){var e=_t(Kl),t=Ml.transition,n=bt;try{if(Ml.transition=null,bt=16>e?16:e,null===Gl)var r=!1;else{if(e=Gl,Gl=null,Kl=0,0!=(6&Nl))throw Error(i(331));var a=Nl;for(Nl|=4,Ju=e.current;null!==Ju;){var o=Ju,u=o.child;if(0!=(16&Ju.flags)){var l=o.deletions;if(null!==l){for(var s=0;s<l.length;s++){var c=l[s];for(Ju=c;null!==Ju;){var f=Ju;switch(f.tag){case 0:case 11:case 15:rl(8,f,o)}var p=f.child;if(null!==p)p.return=f,Ju=p;else for(;null!==Ju;){var d=(f=Ju).sibling,h=f.return;if(ol(f),f===c){Ju=null;break}if(null!==d){d.return=h,Ju=d;break}Ju=h}}}var v=o.alternate;if(null!==v){var g=v.child;if(null!==g){v.child=null;do{var y=g.sibling;g.sibling=null,g=y}while(null!==g)}}Ju=o}}if(0!=(2064&o.subtreeFlags)&&null!==u)u.return=o,Ju=u;else e:for(;null!==Ju;){if(0!=(2048&(o=Ju).flags))switch(o.tag){case 0:case 11:case 15:rl(9,o,o.return)}var m=o.sibling;if(null!==m){m.return=o.return,Ju=m;break e}Ju=o.return}}var b=e.current;for(Ju=b;null!==Ju;){var _=(u=Ju).child;if(0!=(2064&u.subtreeFlags)&&null!==_)_.return=u,Ju=_;else e:for(u=b;null!==Ju;){if(0!=(2048&(l=Ju).flags))try{switch(l.tag){case 0:case 11:case 15:al(9,l)}}catch(e){Es(l,l.return,e)}if(l===u){Ju=null;break e}var w=l.sibling;if(null!==w){w.return=l.return,Ju=w;break e}Ju=l.return}}if(Nl=a,Ba(),it&&\"function\"==typeof it.onPostCommitFiberRoot)try{it.onPostCommitFiberRoot(at,e)}catch(e){}r=!0}return r}finally{bt=n,Ml.transition=t}}return!1}function Ss(e,t,n){e=Ai(e,t=hu(0,t=cu(n,t),1),1),t=ts(),null!==e&&(yt(e,1,t),as(e,t))}function Es(e,t,n){if(3===e.tag)Ss(e,e,n);else for(;null!==t;){if(3===t.tag){Ss(t,e,n);break}if(1===t.tag){var r=t.stateNode;if(\"function\"==typeof t.type.getDerivedStateFromError||\"function\"==typeof r.componentDidCatch&&(null===Ql||!Ql.has(r))){t=Ai(t,e=vu(t,e=cu(n,e),1),1),e=ts(),null!==t&&(yt(t,1,e),as(t,e));break}}t=t.return}}function Cs(e,t,n){var r=e.pingCache;null!==r&&r.delete(t),t=ts(),e.pingedLanes|=e.suspendedLanes&n,Pl===e&&(Ll&n)===n&&(4===Fl||3===Fl&&(130023424&Ll)===Ll&&500>Ze()-Bl?ds(e,0):Ul|=n),as(e,t)}function Ts(e,t){0===t&&(0==(1&e.mode)?t=1:(t=ct,0==(130023424&(ct<<=1))&&(ct=4194304)));var n=ts();null!==(e=Ni(e,t))&&(yt(e,t,n),as(e,n))}function Ms(e){var t=e.memoizedState,n=0;null!==t&&(n=t.retryLane),Ts(e,n)}function Ns(e,t){var n=0;switch(e.tag){case 13:var r=e.stateNode,a=e.memoizedState;null!==a&&(n=a.retryLane);break;case 19:r=e.stateNode;break;default:throw Error(i(314))}null!==r&&r.delete(t),Ts(e,n)}function Ps(e,t){return Qe(e,t)}function zs(e,t,n,r){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=r,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Ls(e,t,n,r){return new zs(e,t,n,r)}function Os(e){return!(!(e=e.prototype)||!e.isReactComponent)}function As(e,t){var n=e.alternate;return null===n?((n=Ls(e.tag,t,e.key,e.mode)).elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=14680064&e.flags,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=null===t?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n}function Fs(e,t,n,r,a,o){var u=2;if(r=e,\"function\"==typeof e)Os(e)&&(u=1);else if(\"string\"==typeof e)u=5;else e:switch(e){case k:return Ds(n.children,a,o,t);case S:u=8,a|=8;break;case E:return(e=Ls(12,n,t,2|a)).elementType=E,e.lanes=o,e;case N:return(e=Ls(13,n,t,a)).elementType=N,e.lanes=o,e;case P:return(e=Ls(19,n,t,a)).elementType=P,e.lanes=o,e;case O:return Rs(n,a,o,t);default:if(\"object\"==typeof e&&null!==e)switch(e.$$typeof){case C:u=10;break e;case T:u=9;break e;case M:u=11;break e;case z:u=14;break e;case L:u=16,r=null;break e}throw Error(i(130,null==e?e:typeof e,\"\"))}return(t=Ls(u,n,t,a)).elementType=e,t.type=r,t.lanes=o,t}function Ds(e,t,n,r){return(e=Ls(7,e,r,t)).lanes=n,e}function Rs(e,t,n,r){return(e=Ls(22,e,r,t)).elementType=O,e.lanes=n,e.stateNode={isHidden:!1},e}function js(e,t,n){return(e=Ls(6,e,null,t)).lanes=n,e}function Us(e,t,n){return(t=Ls(4,null!==e.children?e.children:[],e.key,t)).lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Is(e,t,n,r,a){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=gt(0),this.expirationTimes=gt(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=gt(0),this.identifierPrefix=r,this.onRecoverableError=a,this.mutableSourceEagerHydrationData=null}function $s(e,t,n,r,a,i,o,u,l){return e=new Is(e,t,n,u,l),1===t?(t=1,!0===i&&(t|=8)):t=0,i=Ls(3,null,null,t),e.current=i,i.stateNode=e,i.memoizedState={element:r,isDehydrated:n,cache:null,transitions:null,pendingSuspenseBoundaries:null},zi(i),e}function Bs(e){if(!e)return Ta;e:{if(Be(e=e._reactInternals)!==e||1!==e.tag)throw Error(i(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(La(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(null!==t);throw Error(i(171))}if(1===e.tag){var n=e.type;if(La(n))return Fa(e,n,t)}return t}function Ws(e,t,n,r,a,i,o,u,l){return(e=$s(n,r,!0,e,0,i,0,u,l)).context=Bs(null),n=e.current,(i=Oi(r=ts(),a=ns(n))).callback=null!=t?t:null,Ai(n,i,a),e.current.lanes=a,yt(e,a,r),as(e,r),e}function Vs(e,t,n,r){var a=t.current,i=ts(),o=ns(a);return n=Bs(n),null===t.context?t.context=n:t.pendingContext=n,(t=Oi(i,o)).payload={element:e},null!==(r=void 0===r?null:r)&&(t.callback=r),null!==(e=Ai(a,t,o))&&(rs(e,a,o,i),Fi(e,a,o)),o}function Hs(e){return(e=e.current).child?(e.child.tag,e.child.stateNode):null}function qs(e,t){if(null!==(e=e.memoizedState)&&null!==e.dehydrated){var n=e.retryLane;e.retryLane=0!==n&&n<t?n:t}}function Qs(e,t){qs(e,t),(e=e.alternate)&&qs(e,t)}Sl=function(e,t,n){if(null!==e)if(e.memoizedProps!==t.pendingProps||Na.current)_u=!0;else{if(0==(e.lanes&n)&&0==(128&t.flags))return _u=!1,function(e,t,n){switch(t.tag){case 3:Pu(t),di();break;case 5:io(t);break;case 1:La(t.type)&&Da(t);break;case 4:ro(t,t.stateNode.containerInfo);break;case 10:var r=t.type._context,a=t.memoizedProps.value;Ca(yi,r._currentValue),r._currentValue=a;break;case 13:if(null!==(r=t.memoizedState))return null!==r.dehydrated?(Ca(uo,1&uo.current),t.flags|=128,null):0!=(n&t.child.childLanes)?ju(e,t,n):(Ca(uo,1&uo.current),null!==(e=Hu(e,t,n))?e.sibling:null);Ca(uo,1&uo.current);break;case 19:if(r=0!=(n&t.childLanes),0!=(128&e.flags)){if(r)return Wu(e,t,n);t.flags|=128}if(null!==(a=t.memoizedState)&&(a.rendering=null,a.tail=null,a.lastEffect=null),Ca(uo,uo.current),r)break;return null;case 22:case 23:return t.lanes=0,Eu(e,t,n)}return Hu(e,t,n)}(e,t,n);_u=0!=(131072&e.flags)}else _u=!1,ai&&0!=(1048576&t.flags)&&Ja(t,qa,t.index);switch(t.lanes=0,t.tag){case 2:var r=t.type;Vu(e,t),e=t.pendingProps;var a=za(t,Ma.current);Si(t,n),a=So(null,t,r,e,a,n);var o=Eo();return t.flags|=1,\"object\"==typeof a&&null!==a&&\"function\"==typeof a.render&&void 0===a.$$typeof?(t.tag=1,t.memoizedState=null,t.updateQueue=null,La(r)?(o=!0,Da(t)):o=!1,t.memoizedState=null!==a.state&&void 0!==a.state?a.state:null,zi(t),a.updater=$i,t.stateNode=a,a._reactInternals=t,Hi(t,r,e,n),t=Nu(null,t,r,!0,o,n)):(t.tag=0,ai&&o&&ei(t),wu(null,t,a,n),t=t.child),t;case 16:r=t.elementType;e:{switch(Vu(e,t),e=t.pendingProps,r=(a=r._init)(r._payload),t.type=r,a=t.tag=function(e){if(\"function\"==typeof e)return Os(e)?1:0;if(null!=e){if((e=e.$$typeof)===M)return 11;if(e===z)return 14}return 2}(r),e=gi(r,e),a){case 0:t=Tu(null,t,r,e,n);break e;case 1:t=Mu(null,t,r,e,n);break e;case 11:t=xu(null,t,r,e,n);break e;case 14:t=ku(null,t,r,gi(r.type,e),n);break e}throw Error(i(306,r,\"\"))}return t;case 0:return r=t.type,a=t.pendingProps,Tu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 1:return r=t.type,a=t.pendingProps,Mu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 3:e:{if(Pu(t),null===e)throw Error(i(387));r=t.pendingProps,a=(o=t.memoizedState).element,Li(e,t),Ri(t,r,null,n);var u=t.memoizedState;if(r=u.element,o.isDehydrated){if(o={element:r,isDehydrated:!1,cache:u.cache,pendingSuspenseBoundaries:u.pendingSuspenseBoundaries,transitions:u.transitions},t.updateQueue.baseState=o,t.memoizedState=o,256&t.flags){t=zu(e,t,r,n,a=cu(Error(i(423)),t));break e}if(r!==a){t=zu(e,t,r,n,a=cu(Error(i(424)),t));break e}for(ri=sa(t.stateNode.containerInfo.firstChild),ni=t,ai=!0,ii=null,n=Zi(t,null,r,n),t.child=n;n;)n.flags=-3&n.flags|4096,n=n.sibling}else{if(di(),r===a){t=Hu(e,t,n);break e}wu(e,t,r,n)}t=t.child}return t;case 5:return io(t),null===e&&si(t),r=t.type,a=t.pendingProps,o=null!==e?e.memoizedProps:null,u=a.children,na(r,a)?u=null:null!==o&&na(r,o)&&(t.flags|=32),Cu(e,t),wu(e,t,u,n),t.child;case 6:return null===e&&si(t),null;case 13:return ju(e,t,n);case 4:return ro(t,t.stateNode.containerInfo),r=t.pendingProps,null===e?t.child=Ki(t,null,r,n):wu(e,t,r,n),t.child;case 11:return r=t.type,a=t.pendingProps,xu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 7:return wu(e,t,t.pendingProps,n),t.child;case 8:case 12:return wu(e,t,t.pendingProps.children,n),t.child;case 10:e:{if(r=t.type._context,a=t.pendingProps,o=t.memoizedProps,u=a.value,Ca(yi,r._currentValue),r._currentValue=u,null!==o)if(ur(o.value,u)){if(o.children===a.children&&!Na.current){t=Hu(e,t,n);break e}}else for(null!==(o=t.child)&&(o.return=t);null!==o;){var l=o.dependencies;if(null!==l){u=o.child;for(var s=l.firstContext;null!==s;){if(s.context===r){if(1===o.tag){(s=Oi(-1,n&-n)).tag=2;var c=o.updateQueue;if(null!==c){var f=(c=c.shared).pending;null===f?s.next=s:(s.next=f.next,f.next=s),c.pending=s}}o.lanes|=n,null!==(s=o.alternate)&&(s.lanes|=n),ki(o.return,n,t),l.lanes|=n;break}s=s.next}}else if(10===o.tag)u=o.type===t.type?null:o.child;else if(18===o.tag){if(null===(u=o.return))throw Error(i(341));u.lanes|=n,null!==(l=u.alternate)&&(l.lanes|=n),ki(u,n,t),u=o.sibling}else u=o.child;if(null!==u)u.return=o;else for(u=o;null!==u;){if(u===t){u=null;break}if(null!==(o=u.sibling)){o.return=u.return,u=o;break}u=u.return}o=u}wu(e,t,a.children,n),t=t.child}return t;case 9:return a=t.type,r=t.pendingProps.children,Si(t,n),r=r(a=Ei(a)),t.flags|=1,wu(e,t,r,n),t.child;case 14:return a=gi(r=t.type,t.pendingProps),ku(e,t,r,a=gi(r.type,a),n);case 15:return Su(e,t,t.type,t.pendingProps,n);case 17:return r=t.type,a=t.pendingProps,a=t.elementType===r?a:gi(r,a),Vu(e,t),t.tag=1,La(r)?(e=!0,Da(t)):e=!1,Si(t,n),Wi(t,r,a),Hi(t,r,a,n),Nu(null,t,r,!0,e,n);case 19:return Wu(e,t,n);case 22:return Eu(e,t,n)}throw Error(i(156,t.tag))};var Ys=\"function\"==typeof reportError?reportError:function(e){console.error(e)};function Gs(e){this._internalRoot=e}function Ks(e){this._internalRoot=e}function Zs(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType)}function Xs(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType&&(8!==e.nodeType||\" react-mount-point-unstable \"!==e.nodeValue))}function Js(){}function ec(e,t,n,r,a){var i=n._reactRootContainer;if(i){var o=i;if(\"function\"==typeof a){var u=a;a=function(){var e=Hs(o);u.call(e)}}Vs(t,o,e,a)}else o=function(e,t,n,r,a){if(a){if(\"function\"==typeof r){var i=r;r=function(){var e=Hs(o);i.call(e)}}var o=Ws(t,r,e,0,null,!1,0,\"\",Js);return e._reactRootContainer=o,e[ha]=o.current,Br(8===e.nodeType?e.parentNode:e),fs(),o}for(;a=e.lastChild;)e.removeChild(a);if(\"function\"==typeof r){var u=r;r=function(){var e=Hs(l);u.call(e)}}var l=$s(e,0,!1,null,0,!1,0,\"\",Js);return e._reactRootContainer=l,e[ha]=l.current,Br(8===e.nodeType?e.parentNode:e),fs((function(){Vs(t,l,n,r)})),l}(n,t,e,a,r);return Hs(o)}Ks.prototype.render=Gs.prototype.render=function(e){var t=this._internalRoot;if(null===t)throw Error(i(409));Vs(e,t,null,null)},Ks.prototype.unmount=Gs.prototype.unmount=function(){var e=this._internalRoot;if(null!==e){this._internalRoot=null;var t=e.containerInfo;fs((function(){Vs(null,e,null,null)})),t[ha]=null}},Ks.prototype.unstable_scheduleHydration=function(e){if(e){var t=St();e={blockedOn:null,target:e,priority:t};for(var n=0;n<Ot.length&&0!==t&&t<Ot[n].priority;n++);Ot.splice(n,0,e),0===n&&Rt(e)}},wt=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var n=ft(t.pendingLanes);0!==n&&(mt(t,1|n),as(t,Ze()),0==(6&Nl)&&(Wl=Ze()+500,Ba()))}break;case 13:fs((function(){var t=Ni(e,1);if(null!==t){var n=ts();rs(t,e,1,n)}})),Qs(e,1)}},xt=function(e){if(13===e.tag){var t=Ni(e,134217728);null!==t&&rs(t,e,134217728,ts()),Qs(e,134217728)}},kt=function(e){if(13===e.tag){var t=ns(e),n=Ni(e,t);null!==n&&rs(n,e,t,ts()),Qs(e,t)}},St=function(){return bt},Et=function(e,t){var n=bt;try{return bt=e,t()}finally{bt=n}},xe=function(e,t,n){switch(t){case\"input\":if(X(e,n),t=n.name,\"radio\"===n.type&&null!=t){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+t)+'][type=\"radio\"]'),t=0;t<n.length;t++){var r=n[t];if(r!==e&&r.form===e.form){var a=wa(r);if(!a)throw Error(i(90));Q(r),X(r,a)}}}break;case\"textarea\":ie(e,n);break;case\"select\":null!=(t=n.value)&&ne(e,!!n.multiple,t,!1)}},Me=cs,Ne=fs;var tc={usingClientEntryPoint:!1,Events:[ba,_a,wa,Ce,Te,cs]},nc={findFiberByHostInstance:ma,bundleType:0,version:\"18.2.0\",rendererPackageName:\"react-dom\"},rc={bundleType:nc.bundleType,version:nc.version,rendererPackageName:nc.rendererPackageName,rendererConfig:nc.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:_.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return null===(e=He(e))?null:e.stateNode},findFiberByHostInstance:nc.findFiberByHostInstance||function(){return null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:\"18.2.0-next-9e3b772b8-20220608\"};if(\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var ac=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!ac.isDisabled&&ac.supportsFiber)try{at=ac.inject(rc),it=ac}catch(ce){}}t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=tc,t.createPortal=function(e,t){var n=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!Zs(t))throw Error(i(200));return function(e,t,n){var r=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:x,key:null==r?null:\"\"+r,children:e,containerInfo:t,implementation:n}}(e,t,null,n)},t.createRoot=function(e,t){if(!Zs(e))throw Error(i(299));var n=!1,r=\"\",a=Ys;return null!=t&&(!0===t.unstable_strictMode&&(n=!0),void 0!==t.identifierPrefix&&(r=t.identifierPrefix),void 0!==t.onRecoverableError&&(a=t.onRecoverableError)),t=$s(e,1,!1,null,0,n,0,r,a),e[ha]=t.current,Br(8===e.nodeType?e.parentNode:e),new Gs(t)},t.findDOMNode=function(e){if(null==e)return null;if(1===e.nodeType)return e;var t=e._reactInternals;if(void 0===t){if(\"function\"==typeof e.render)throw Error(i(188));throw e=Object.keys(e).join(\",\"),Error(i(268,e))}return null===(e=He(t))?null:e.stateNode},t.flushSync=function(e){return fs(e)},t.hydrate=function(e,t,n){if(!Xs(t))throw Error(i(200));return ec(null,e,t,!0,n)},t.hydrateRoot=function(e,t,n){if(!Zs(e))throw Error(i(405));var r=null!=n&&n.hydratedSources||null,a=!1,o=\"\",u=Ys;if(null!=n&&(!0===n.unstable_strictMode&&(a=!0),void 0!==n.identifierPrefix&&(o=n.identifierPrefix),void 0!==n.onRecoverableError&&(u=n.onRecoverableError)),t=Ws(t,null,e,1,null!=n?n:null,a,0,o,u),e[ha]=t.current,Br(e),r)for(e=0;e<r.length;e++)a=(a=(n=r[e])._getVersion)(n._source),null==t.mutableSourceEagerHydrationData?t.mutableSourceEagerHydrationData=[n,a]:t.mutableSourceEagerHydrationData.push(n,a);return new Ks(t)},t.render=function(e,t,n){if(!Xs(t))throw Error(i(200));return ec(null,e,t,!1,n)},t.unmountComponentAtNode=function(e){if(!Xs(e))throw Error(i(40));return!!e._reactRootContainer&&(fs((function(){ec(null,null,e,!1,(function(){e._reactRootContainer=null,e[ha]=null}))})),!0)},t.unstable_batchedUpdates=cs,t.unstable_renderSubtreeIntoContainer=function(e,t,n,r){if(!Xs(n))throw Error(i(200));if(null==e||void 0===e._reactInternals)throw Error(i(38));return ec(e,t,n,!1,r)},t.version=\"18.2.0-next-9e3b772b8-20220608\"},935:(e,t,n)=>{\"use strict\";!function e(){if(\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&\"function\"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(e){console.error(e)}}(),e.exports=n(448)},408:(e,t)=>{\"use strict\";var n=Symbol.for(\"react.element\"),r=Symbol.for(\"react.portal\"),a=Symbol.for(\"react.fragment\"),i=Symbol.for(\"react.strict_mode\"),o=Symbol.for(\"react.profiler\"),u=Symbol.for(\"react.provider\"),l=Symbol.for(\"react.context\"),s=Symbol.for(\"react.forward_ref\"),c=Symbol.for(\"react.suspense\"),f=Symbol.for(\"react.memo\"),p=Symbol.for(\"react.lazy\"),d=Symbol.iterator,h={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},v=Object.assign,g={};function y(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||h}function m(){}function b(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||h}y.prototype.isReactComponent={},y.prototype.setState=function(e,t){if(\"object\"!=typeof e&&\"function\"!=typeof e&&null!=e)throw Error(\"setState(...): takes an object of state variables to update or a function which returns an object of state variables.\");this.updater.enqueueSetState(this,e,t,\"setState\")},y.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,\"forceUpdate\")},m.prototype=y.prototype;var _=b.prototype=new m;_.constructor=b,v(_,y.prototype),_.isPureReactComponent=!0;var w=Array.isArray,x=Object.prototype.hasOwnProperty,k={current:null},S={key:!0,ref:!0,__self:!0,__source:!0};function E(e,t,r){var a,i={},o=null,u=null;if(null!=t)for(a in void 0!==t.ref&&(u=t.ref),void 0!==t.key&&(o=\"\"+t.key),t)x.call(t,a)&&!S.hasOwnProperty(a)&&(i[a]=t[a]);var l=arguments.length-2;if(1===l)i.children=r;else if(1<l){for(var s=Array(l),c=0;c<l;c++)s[c]=arguments[c+2];i.children=s}if(e&&e.defaultProps)for(a in l=e.defaultProps)void 0===i[a]&&(i[a]=l[a]);return{$$typeof:n,type:e,key:o,ref:u,props:i,_owner:k.current}}function C(e){return\"object\"==typeof e&&null!==e&&e.$$typeof===n}var T=/\\/+/g;function M(e,t){return\"object\"==typeof e&&null!==e&&null!=e.key?function(e){var t={\"=\":\"=0\",\":\":\"=2\"};return\"$\"+e.replace(/[=:]/g,(function(e){return t[e]}))}(\"\"+e.key):t.toString(36)}function N(e,t,a,i,o){var u=typeof e;\"undefined\"!==u&&\"boolean\"!==u||(e=null);var l=!1;if(null===e)l=!0;else switch(u){case\"string\":case\"number\":l=!0;break;case\"object\":switch(e.$$typeof){case n:case r:l=!0}}if(l)return o=o(l=e),e=\"\"===i?\".\"+M(l,0):i,w(o)?(a=\"\",null!=e&&(a=e.replace(T,\"$&/\")+\"/\"),N(o,t,a,\"\",(function(e){return e}))):null!=o&&(C(o)&&(o=function(e,t){return{$$typeof:n,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(o,a+(!o.key||l&&l.key===o.key?\"\":(\"\"+o.key).replace(T,\"$&/\")+\"/\")+e)),t.push(o)),1;if(l=0,i=\"\"===i?\".\":i+\":\",w(e))for(var s=0;s<e.length;s++){var c=i+M(u=e[s],s);l+=N(u,t,a,c,o)}else if(c=function(e){return null===e||\"object\"!=typeof e?null:\"function\"==typeof(e=d&&e[d]||e[\"@@iterator\"])?e:null}(e),\"function\"==typeof c)for(e=c.call(e),s=0;!(u=e.next()).done;)l+=N(u=u.value,t,a,c=i+M(u,s++),o);else if(\"object\"===u)throw t=String(e),Error(\"Objects are not valid as a React child (found: \"+(\"[object Object]\"===t?\"object with keys {\"+Object.keys(e).join(\", \")+\"}\":t)+\"). If you meant to render a collection of children, use an array instead.\");return l}function P(e,t,n){if(null==e)return e;var r=[],a=0;return N(e,r,\"\",\"\",(function(e){return t.call(n,e,a++)})),r}function z(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var L={current:null},O={transition:null},A={ReactCurrentDispatcher:L,ReactCurrentBatchConfig:O,ReactCurrentOwner:k};t.Children={map:P,forEach:function(e,t,n){P(e,(function(){t.apply(this,arguments)}),n)},count:function(e){var t=0;return P(e,(function(){t++})),t},toArray:function(e){return P(e,(function(e){return e}))||[]},only:function(e){if(!C(e))throw Error(\"React.Children.only expected to receive a single React element child.\");return e}},t.Component=y,t.Fragment=a,t.Profiler=o,t.PureComponent=b,t.StrictMode=i,t.Suspense=c,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=A,t.cloneElement=function(e,t,r){if(null==e)throw Error(\"React.cloneElement(...): The argument must be a React element, but you passed \"+e+\".\");var a=v({},e.props),i=e.key,o=e.ref,u=e._owner;if(null!=t){if(void 0!==t.ref&&(o=t.ref,u=k.current),void 0!==t.key&&(i=\"\"+t.key),e.type&&e.type.defaultProps)var l=e.type.defaultProps;for(s in t)x.call(t,s)&&!S.hasOwnProperty(s)&&(a[s]=void 0===t[s]&&void 0!==l?l[s]:t[s])}var s=arguments.length-2;if(1===s)a.children=r;else if(1<s){l=Array(s);for(var c=0;c<s;c++)l[c]=arguments[c+2];a.children=l}return{$$typeof:n,type:e.type,key:i,ref:o,props:a,_owner:u}},t.createContext=function(e){return(e={$$typeof:l,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:u,_context:e},e.Consumer=e},t.createElement=E,t.createFactory=function(e){var t=E.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:s,render:e}},t.isValidElement=C,t.lazy=function(e){return{$$typeof:p,_payload:{_status:-1,_result:e},_init:z}},t.memo=function(e,t){return{$$typeof:f,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=O.transition;O.transition={};try{e()}finally{O.transition=t}},t.unstable_act=function(){throw Error(\"act(...) is not supported in production builds of React.\")},t.useCallback=function(e,t){return L.current.useCallback(e,t)},t.useContext=function(e){return L.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return L.current.useDeferredValue(e)},t.useEffect=function(e,t){return L.current.useEffect(e,t)},t.useId=function(){return L.current.useId()},t.useImperativeHandle=function(e,t,n){return L.current.useImperativeHandle(e,t,n)},t.useInsertionEffect=function(e,t){return L.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return L.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return L.current.useMemo(e,t)},t.useReducer=function(e,t,n){return L.current.useReducer(e,t,n)},t.useRef=function(e){return L.current.useRef(e)},t.useState=function(e){return L.current.useState(e)},t.useSyncExternalStore=function(e,t,n){return L.current.useSyncExternalStore(e,t,n)},t.useTransition=function(){return L.current.useTransition()},t.version=\"18.2.0\"},294:(e,t,n)=>{\"use strict\";e.exports=n(408)},53:(e,t)=>{\"use strict\";function n(e,t){var n=e.length;e.push(t);e:for(;0<n;){var r=n-1>>>1,a=e[r];if(!(0<i(a,t)))break e;e[r]=t,e[n]=a,n=r}}function r(e){return 0===e.length?null:e[0]}function a(e){if(0===e.length)return null;var t=e[0],n=e.pop();if(n!==t){e[0]=n;e:for(var r=0,a=e.length,o=a>>>1;r<o;){var u=2*(r+1)-1,l=e[u],s=u+1,c=e[s];if(0>i(l,n))s<a&&0>i(c,l)?(e[r]=c,e[s]=n,r=s):(e[r]=l,e[u]=n,r=u);else{if(!(s<a&&0>i(c,n)))break e;e[r]=c,e[s]=n,r=s}}}return t}function i(e,t){var n=e.sortIndex-t.sortIndex;return 0!==n?n:e.id-t.id}if(\"object\"==typeof performance&&\"function\"==typeof performance.now){var o=performance;t.unstable_now=function(){return o.now()}}else{var u=Date,l=u.now();t.unstable_now=function(){return u.now()-l}}var s=[],c=[],f=1,p=null,d=3,h=!1,v=!1,g=!1,y=\"function\"==typeof setTimeout?setTimeout:null,m=\"function\"==typeof clearTimeout?clearTimeout:null,b=\"undefined\"!=typeof setImmediate?setImmediate:null;function _(e){for(var t=r(c);null!==t;){if(null===t.callback)a(c);else{if(!(t.startTime<=e))break;a(c),t.sortIndex=t.expirationTime,n(s,t)}t=r(c)}}function w(e){if(g=!1,_(e),!v)if(null!==r(s))v=!0,O(x);else{var t=r(c);null!==t&&A(w,t.startTime-e)}}function x(e,n){v=!1,g&&(g=!1,m(C),C=-1),h=!0;var i=d;try{for(_(n),p=r(s);null!==p&&(!(p.expirationTime>n)||e&&!N());){var o=p.callback;if(\"function\"==typeof o){p.callback=null,d=p.priorityLevel;var u=o(p.expirationTime<=n);n=t.unstable_now(),\"function\"==typeof u?p.callback=u:p===r(s)&&a(s),_(n)}else a(s);p=r(s)}if(null!==p)var l=!0;else{var f=r(c);null!==f&&A(w,f.startTime-n),l=!1}return l}finally{p=null,d=i,h=!1}}\"undefined\"!=typeof navigator&&void 0!==navigator.scheduling&&void 0!==navigator.scheduling.isInputPending&&navigator.scheduling.isInputPending.bind(navigator.scheduling);var k,S=!1,E=null,C=-1,T=5,M=-1;function N(){return!(t.unstable_now()-M<T)}function P(){if(null!==E){var e=t.unstable_now();M=e;var n=!0;try{n=E(!0,e)}finally{n?k():(S=!1,E=null)}}else S=!1}if(\"function\"==typeof b)k=function(){b(P)};else if(\"undefined\"!=typeof MessageChannel){var z=new MessageChannel,L=z.port2;z.port1.onmessage=P,k=function(){L.postMessage(null)}}else k=function(){y(P,0)};function O(e){E=e,S||(S=!0,k())}function A(e,n){C=y((function(){e(t.unstable_now())}),n)}t.unstable_IdlePriority=5,t.unstable_ImmediatePriority=1,t.unstable_LowPriority=4,t.unstable_NormalPriority=3,t.unstable_Profiling=null,t.unstable_UserBlockingPriority=2,t.unstable_cancelCallback=function(e){e.callback=null},t.unstable_continueExecution=function(){v||h||(v=!0,O(x))},t.unstable_forceFrameRate=function(e){0>e||125<e?console.error(\"forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported\"):T=0<e?Math.floor(1e3/e):5},t.unstable_getCurrentPriorityLevel=function(){return d},t.unstable_getFirstCallbackNode=function(){return r(s)},t.unstable_next=function(e){switch(d){case 1:case 2:case 3:var t=3;break;default:t=d}var n=d;d=t;try{return e()}finally{d=n}},t.unstable_pauseExecution=function(){},t.unstable_requestPaint=function(){},t.unstable_runWithPriority=function(e,t){switch(e){case 1:case 2:case 3:case 4:case 5:break;default:e=3}var n=d;d=e;try{return t()}finally{d=n}},t.unstable_scheduleCallback=function(e,a,i){var o=t.unstable_now();switch(i=\"object\"==typeof i&&null!==i&&\"number\"==typeof(i=i.delay)&&0<i?o+i:o,e){case 1:var u=-1;break;case 2:u=250;break;case 5:u=1073741823;break;case 4:u=1e4;break;default:u=5e3}return e={id:f++,callback:a,priorityLevel:e,startTime:i,expirationTime:u=i+u,sortIndex:-1},i>o?(e.sortIndex=i,n(c,e),null===r(s)&&e===r(c)&&(g?(m(C),C=-1):g=!0,A(w,i-o))):(e.sortIndex=u,n(s,e),v||h||(v=!0,O(x))),e},t.unstable_shouldYield=N,t.unstable_wrapCallback=function(e){var t=d;return function(){var n=d;d=t;try{return e.apply(this,arguments)}finally{d=n}}}},840:(e,t,n)=>{\"use strict\";e.exports=n(53)}},t={};function n(r){var a=t[r];if(void 0!==a)return a.exports;var i=t[r]={id:r,loaded:!1,exports:{}};return e[r].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(e){if(\"object\"==typeof window)return window}}(),n.nmd=e=>(e.paths=[],e.children||(e.children=[]),e),(()=>{\"use strict\";var e=n(294),t=n(935);const r=Math.sqrt(50),a=Math.sqrt(10),i=Math.sqrt(2);function o(e,t,n){const u=(t-e)/Math.max(0,n),l=Math.floor(Math.log10(u)),s=u/Math.pow(10,l),c=s>=r?10:s>=a?5:s>=i?2:1;let f,p,d;return l<0?(d=Math.pow(10,-l)/c,f=Math.round(e*d),p=Math.round(t*d),f/d<e&&++f,p/d>t&&--p,d=-d):(d=Math.pow(10,l)*c,f=Math.round(e/d),p=Math.round(t/d),f*d<e&&++f,p*d>t&&--p),p<f&&.5<=n&&n<2?o(e,t,2*n):[f,p,d]}function u(e,t,n){return o(e=+e,t=+t,n=+n)[2]}function l(e,t,n){n=+n;const r=(t=+t)<(e=+e),a=r?u(t,e,n):u(e,t,n);return(r?-1:1)*(a<0?1/-a:a)}function s(e,t){return null==e||null==t?NaN:e<t?-1:e>t?1:e>=t?0:NaN}function c(e,t){return null==e||null==t?NaN:t<e?-1:t>e?1:t>=e?0:NaN}function f(e){let t,n,r;function a(e,r,a=0,i=e.length){if(a<i){if(0!==t(r,r))return i;do{const t=a+i>>>1;n(e[t],r)<0?a=t+1:i=t}while(a<i)}return a}return 2!==e.length?(t=s,n=(t,n)=>s(e(t),n),r=(t,n)=>e(t)-n):(t=e===s||e===c?e:p,n=e,r=e),{left:a,center:function(e,t,n=0,i=e.length){const o=a(e,t,n,i-1);return o>n&&r(e[o-1],t)>-r(e[o],t)?o-1:o},right:function(e,r,a=0,i=e.length){if(a<i){if(0!==t(r,r))return i;do{const t=a+i>>>1;n(e[t],r)<=0?a=t+1:i=t}while(a<i)}return a}}}function p(){return 0}const d=f(s),h=d.right,v=(d.left,f((function(e){return null===e?NaN:+e})).center,h);function g(e,t,n){e.prototype=t.prototype=n,n.constructor=e}function y(e,t){var n=Object.create(e.prototype);for(var r in t)n[r]=t[r];return n}function m(){}var b=.7,_=1/b,w=\"\\\\s*([+-]?\\\\d+)\\\\s*\",x=\"\\\\s*([+-]?(?:\\\\d*\\\\.)?\\\\d+(?:[eE][+-]?\\\\d+)?)\\\\s*\",k=\"\\\\s*([+-]?(?:\\\\d*\\\\.)?\\\\d+(?:[eE][+-]?\\\\d+)?)%\\\\s*\",S=/^#([0-9a-f]{3,8})$/,E=new RegExp(`^rgb\\\\(${w},${w},${w}\\\\)$`),C=new RegExp(`^rgb\\\\(${k},${k},${k}\\\\)$`),T=new RegExp(`^rgba\\\\(${w},${w},${w},${x}\\\\)$`),M=new RegExp(`^rgba\\\\(${k},${k},${k},${x}\\\\)$`),N=new RegExp(`^hsl\\\\(${x},${k},${k}\\\\)$`),P=new RegExp(`^hsla\\\\(${x},${k},${k},${x}\\\\)$`),z={aliceblue:15792383,antiquewhite:16444375,aqua:65535,aquamarine:8388564,azure:15794175,beige:16119260,bisque:16770244,black:0,blanchedalmond:16772045,blue:255,blueviolet:9055202,brown:10824234,burlywood:14596231,cadetblue:6266528,chartreuse:8388352,chocolate:13789470,coral:16744272,cornflowerblue:6591981,cornsilk:16775388,crimson:14423100,cyan:65535,darkblue:139,darkcyan:35723,darkgoldenrod:12092939,darkgray:11119017,darkgreen:25600,darkgrey:11119017,darkkhaki:12433259,darkmagenta:9109643,darkolivegreen:5597999,darkorange:16747520,darkorchid:10040012,darkred:9109504,darksalmon:15308410,darkseagreen:9419919,darkslateblue:4734347,darkslategray:3100495,darkslategrey:3100495,darkturquoise:52945,darkviolet:9699539,deeppink:16716947,deepskyblue:49151,dimgray:6908265,dimgrey:6908265,dodgerblue:2003199,firebrick:11674146,floralwhite:16775920,forestgreen:2263842,fuchsia:16711935,gainsboro:14474460,ghostwhite:16316671,gold:16766720,goldenrod:14329120,gray:8421504,green:32768,greenyellow:11403055,grey:8421504,honeydew:15794160,hotpink:16738740,indianred:13458524,indigo:4915330,ivory:16777200,khaki:15787660,lavender:15132410,lavenderblush:16773365,lawngreen:8190976,lemonchiffon:16775885,lightblue:11393254,lightcoral:15761536,lightcyan:14745599,lightgoldenrodyellow:16448210,lightgray:13882323,lightgreen:9498256,lightgrey:13882323,lightpink:16758465,lightsalmon:16752762,lightseagreen:2142890,lightskyblue:8900346,lightslategray:7833753,lightslategrey:7833753,lightsteelblue:11584734,lightyellow:16777184,lime:65280,limegreen:3329330,linen:16445670,magenta:16711935,maroon:8388608,mediumaquamarine:6737322,mediumblue:205,mediumorchid:12211667,mediumpurple:9662683,mediumseagreen:3978097,mediumslateblue:8087790,mediumspringgreen:64154,mediumturquoise:4772300,mediumvioletred:13047173,midnightblue:1644912,mintcream:16121850,mistyrose:16770273,moccasin:16770229,navajowhite:16768685,navy:128,oldlace:16643558,olive:8421376,olivedrab:7048739,orange:16753920,orangered:16729344,orchid:14315734,palegoldenrod:15657130,palegreen:10025880,paleturquoise:11529966,palevioletred:14381203,papayawhip:16773077,peachpuff:16767673,peru:13468991,pink:16761035,plum:14524637,powderblue:11591910,purple:8388736,rebeccapurple:6697881,red:16711680,rosybrown:12357519,royalblue:4286945,saddlebrown:9127187,salmon:16416882,sandybrown:16032864,seagreen:3050327,seashell:16774638,sienna:10506797,silver:12632256,skyblue:8900331,slateblue:6970061,slategray:7372944,slategrey:7372944,snow:16775930,springgreen:65407,steelblue:4620980,tan:13808780,teal:32896,thistle:14204888,tomato:16737095,turquoise:4251856,violet:15631086,wheat:16113331,white:16777215,whitesmoke:16119285,yellow:16776960,yellowgreen:10145074};function L(){return this.rgb().formatHex()}function O(){return this.rgb().formatRgb()}function A(e){var t,n;return e=(e+\"\").trim().toLowerCase(),(t=S.exec(e))?(n=t[1].length,t=parseInt(t[1],16),6===n?F(t):3===n?new j(t>>8&15|t>>4&240,t>>4&15|240&t,(15&t)<<4|15&t,1):8===n?D(t>>24&255,t>>16&255,t>>8&255,(255&t)/255):4===n?D(t>>12&15|t>>8&240,t>>8&15|t>>4&240,t>>4&15|240&t,((15&t)<<4|15&t)/255):null):(t=E.exec(e))?new j(t[1],t[2],t[3],1):(t=C.exec(e))?new j(255*t[1]/100,255*t[2]/100,255*t[3]/100,1):(t=T.exec(e))?D(t[1],t[2],t[3],t[4]):(t=M.exec(e))?D(255*t[1]/100,255*t[2]/100,255*t[3]/100,t[4]):(t=N.exec(e))?V(t[1],t[2]/100,t[3]/100,1):(t=P.exec(e))?V(t[1],t[2]/100,t[3]/100,t[4]):z.hasOwnProperty(e)?F(z[e]):\"transparent\"===e?new j(NaN,NaN,NaN,0):null}function F(e){return new j(e>>16&255,e>>8&255,255&e,1)}function D(e,t,n,r){return r<=0&&(e=t=n=NaN),new j(e,t,n,r)}function R(e,t,n,r){return 1===arguments.length?((a=e)instanceof m||(a=A(a)),a?new j((a=a.rgb()).r,a.g,a.b,a.opacity):new j):new j(e,t,n,null==r?1:r);var a}function j(e,t,n,r){this.r=+e,this.g=+t,this.b=+n,this.opacity=+r}function U(){return`#${W(this.r)}${W(this.g)}${W(this.b)}`}function I(){const e=$(this.opacity);return`${1===e?\"rgb(\":\"rgba(\"}${B(this.r)}, ${B(this.g)}, ${B(this.b)}${1===e?\")\":`, ${e})`}`}function $(e){return isNaN(e)?1:Math.max(0,Math.min(1,e))}function B(e){return Math.max(0,Math.min(255,Math.round(e)||0))}function W(e){return((e=B(e))<16?\"0\":\"\")+e.toString(16)}function V(e,t,n,r){return r<=0?e=t=n=NaN:n<=0||n>=1?e=t=NaN:t<=0&&(e=NaN),new Q(e,t,n,r)}function H(e){if(e instanceof Q)return new Q(e.h,e.s,e.l,e.opacity);if(e instanceof m||(e=A(e)),!e)return new Q;if(e instanceof Q)return e;var t=(e=e.rgb()).r/255,n=e.g/255,r=e.b/255,a=Math.min(t,n,r),i=Math.max(t,n,r),o=NaN,u=i-a,l=(i+a)/2;return u?(o=t===i?(n-r)/u+6*(n<r):n===i?(r-t)/u+2:(t-n)/u+4,u/=l<.5?i+a:2-i-a,o*=60):u=l>0&&l<1?0:o,new Q(o,u,l,e.opacity)}function q(e,t,n,r){return 1===arguments.length?H(e):new Q(e,t,n,null==r?1:r)}function Q(e,t,n,r){this.h=+e,this.s=+t,this.l=+n,this.opacity=+r}function Y(e){return(e=(e||0)%360)<0?e+360:e}function G(e){return Math.max(0,Math.min(1,e||0))}function K(e,t,n){return 255*(e<60?t+(n-t)*e/60:e<180?n:e<240?t+(n-t)*(240-e)/60:t)}function Z(e,t,n,r,a){var i=e*e,o=i*e;return((1-3*e+3*i-o)*t+(4-6*i+3*o)*n+(1+3*e+3*i-3*o)*r+o*a)/6}g(m,A,{copy(e){return Object.assign(new this.constructor,this,e)},displayable(){return this.rgb().displayable()},hex:L,formatHex:L,formatHex8:function(){return this.rgb().formatHex8()},formatHsl:function(){return H(this).formatHsl()},formatRgb:O,toString:O}),g(j,R,y(m,{brighter(e){return e=null==e?_:Math.pow(_,e),new j(this.r*e,this.g*e,this.b*e,this.opacity)},darker(e){return e=null==e?b:Math.pow(b,e),new j(this.r*e,this.g*e,this.b*e,this.opacity)},rgb(){return this},clamp(){return new j(B(this.r),B(this.g),B(this.b),$(this.opacity))},displayable(){return-.5<=this.r&&this.r<255.5&&-.5<=this.g&&this.g<255.5&&-.5<=this.b&&this.b<255.5&&0<=this.opacity&&this.opacity<=1},hex:U,formatHex:U,formatHex8:function(){return`#${W(this.r)}${W(this.g)}${W(this.b)}${W(255*(isNaN(this.opacity)?1:this.opacity))}`},formatRgb:I,toString:I})),g(Q,q,y(m,{brighter(e){return e=null==e?_:Math.pow(_,e),new Q(this.h,this.s,this.l*e,this.opacity)},darker(e){return e=null==e?b:Math.pow(b,e),new Q(this.h,this.s,this.l*e,this.opacity)},rgb(){var e=this.h%360+360*(this.h<0),t=isNaN(e)||isNaN(this.s)?0:this.s,n=this.l,r=n+(n<.5?n:1-n)*t,a=2*n-r;return new j(K(e>=240?e-240:e+120,a,r),K(e,a,r),K(e<120?e+240:e-120,a,r),this.opacity)},clamp(){return new Q(Y(this.h),G(this.s),G(this.l),$(this.opacity))},displayable(){return(0<=this.s&&this.s<=1||isNaN(this.s))&&0<=this.l&&this.l<=1&&0<=this.opacity&&this.opacity<=1},formatHsl(){const e=$(this.opacity);return`${1===e?\"hsl(\":\"hsla(\"}${Y(this.h)}, ${100*G(this.s)}%, ${100*G(this.l)}%${1===e?\")\":`, ${e})`}`}}));const X=e=>()=>e;function J(e,t){var n=t-e;return n?function(e,t){return function(n){return e+n*t}}(e,n):X(isNaN(e)?t:e)}const ee=function e(t){var n=function(e){return 1==(e=+e)?J:function(t,n){return n-t?function(e,t,n){return e=Math.pow(e,n),t=Math.pow(t,n)-e,n=1/n,function(r){return Math.pow(e+r*t,n)}}(t,n,e):X(isNaN(t)?n:t)}}(t);function r(e,t){var r=n((e=R(e)).r,(t=R(t)).r),a=n(e.g,t.g),i=n(e.b,t.b),o=J(e.opacity,t.opacity);return function(t){return e.r=r(t),e.g=a(t),e.b=i(t),e.opacity=o(t),e+\"\"}}return r.gamma=e,r}(1);function te(e){return function(t){var n,r,a=t.length,i=new Array(a),o=new Array(a),u=new Array(a);for(n=0;n<a;++n)r=R(t[n]),i[n]=r.r||0,o[n]=r.g||0,u[n]=r.b||0;return i=e(i),o=e(o),u=e(u),r.opacity=1,function(e){return r.r=i(e),r.g=o(e),r.b=u(e),r+\"\"}}}function ne(e,t){var n,r=t?t.length:0,a=e?Math.min(r,e.length):0,i=new Array(a),o=new Array(r);for(n=0;n<a;++n)i[n]=ce(e[n],t[n]);for(;n<r;++n)o[n]=t[n];return function(e){for(n=0;n<a;++n)o[n]=i[n](e);return o}}function re(e,t){var n=new Date;return e=+e,t=+t,function(r){return n.setTime(e*(1-r)+t*r),n}}function ae(e,t){return e=+e,t=+t,function(n){return e*(1-n)+t*n}}function ie(e,t){var n,r={},a={};for(n in null!==e&&\"object\"==typeof e||(e={}),null!==t&&\"object\"==typeof t||(t={}),t)n in e?r[n]=ce(e[n],t[n]):a[n]=t[n];return function(e){for(n in r)a[n]=r[n](e);return a}}te((function(e){var t=e.length-1;return function(n){var r=n<=0?n=0:n>=1?(n=1,t-1):Math.floor(n*t),a=e[r],i=e[r+1],o=r>0?e[r-1]:2*a-i,u=r<t-1?e[r+2]:2*i-a;return Z((n-r/t)*t,o,a,i,u)}})),te((function(e){var t=e.length;return function(n){var r=Math.floor(((n%=1)<0?++n:n)*t),a=e[(r+t-1)%t],i=e[r%t],o=e[(r+1)%t],u=e[(r+2)%t];return Z((n-r/t)*t,a,i,o,u)}}));var oe=/[-+]?(?:\\d+\\.?\\d*|\\.?\\d+)(?:[eE][-+]?\\d+)?/g,ue=new RegExp(oe.source,\"g\");function le(e,t){var n,r,a,i=oe.lastIndex=ue.lastIndex=0,o=-1,u=[],l=[];for(e+=\"\",t+=\"\";(n=oe.exec(e))&&(r=ue.exec(t));)(a=r.index)>i&&(a=t.slice(i,a),u[o]?u[o]+=a:u[++o]=a),(n=n[0])===(r=r[0])?u[o]?u[o]+=r:u[++o]=r:(u[++o]=null,l.push({i:o,x:ae(n,r)})),i=ue.lastIndex;return i<t.length&&(a=t.slice(i),u[o]?u[o]+=a:u[++o]=a),u.length<2?l[0]?function(e){return function(t){return e(t)+\"\"}}(l[0].x):function(e){return function(){return e}}(t):(t=l.length,function(e){for(var n,r=0;r<t;++r)u[(n=l[r]).i]=n.x(e);return u.join(\"\")})}function se(e,t){t||(t=[]);var n,r=e?Math.min(t.length,e.length):0,a=t.slice();return function(i){for(n=0;n<r;++n)a[n]=e[n]*(1-i)+t[n]*i;return a}}function ce(e,t){var n,r,a=typeof t;return null==t||\"boolean\"===a?X(t):(\"number\"===a?ae:\"string\"===a?(n=A(t))?(t=n,ee):le:t instanceof A?ee:t instanceof Date?re:(r=t,!ArrayBuffer.isView(r)||r instanceof DataView?Array.isArray(t)?ne:\"function\"!=typeof t.valueOf&&\"function\"!=typeof t.toString||isNaN(t)?ie:ae:se))(e,t)}function fe(e,t){return e=+e,t=+t,function(n){return Math.round(e*(1-n)+t*n)}}function pe(e){return+e}var de=[0,1];function he(e){return e}function ve(e,t){return(t-=e=+e)?function(n){return(n-e)/t}:(n=isNaN(t)?NaN:.5,function(){return n});var n}function ge(e,t,n){var r=e[0],a=e[1],i=t[0],o=t[1];return a<r?(r=ve(a,r),i=n(o,i)):(r=ve(r,a),i=n(i,o)),function(e){return i(r(e))}}function ye(e,t,n){var r=Math.min(e.length,t.length)-1,a=new Array(r),i=new Array(r),o=-1;for(e[r]<e[0]&&(e=e.slice().reverse(),t=t.slice().reverse());++o<r;)a[o]=ve(e[o],e[o+1]),i[o]=n(t[o],t[o+1]);return function(t){var n=v(e,t,1,r)-1;return i[n](a[n](t))}}function me(e,t){return t.domain(e.domain()).range(e.range()).interpolate(e.interpolate()).clamp(e.clamp()).unknown(e.unknown())}function be(){return function(){var e,t,n,r,a,i,o=de,u=de,l=ce,s=he;function c(){var e,t,n,l=Math.min(o.length,u.length);return s!==he&&(e=o[0],t=o[l-1],e>t&&(n=e,e=t,t=n),s=function(n){return Math.max(e,Math.min(t,n))}),r=l>2?ye:ge,a=i=null,f}function f(t){return null==t||isNaN(t=+t)?n:(a||(a=r(o.map(e),u,l)))(e(s(t)))}return f.invert=function(n){return s(t((i||(i=r(u,o.map(e),ae)))(n)))},f.domain=function(e){return arguments.length?(o=Array.from(e,pe),c()):o.slice()},f.range=function(e){return arguments.length?(u=Array.from(e),c()):u.slice()},f.rangeRound=function(e){return u=Array.from(e),l=fe,c()},f.clamp=function(e){return arguments.length?(s=!!e||he,c()):s!==he},f.interpolate=function(e){return arguments.length?(l=e,c()):l},f.unknown=function(e){return arguments.length?(n=e,f):n},function(n,r){return e=n,t=r,c()}}()(he,he)}function _e(e,t){switch(arguments.length){case 0:break;case 1:this.range(e);break;default:this.range(t).domain(e)}return this}var we,xe=/^(?:(.)?([<>=^]))?([+\\-( ])?([$#])?(0)?(\\d+)?(,)?(\\.\\d+)?(~)?([a-z%])?$/i;function ke(e){if(!(t=xe.exec(e)))throw new Error(\"invalid format: \"+e);var t;return new Se({fill:t[1],align:t[2],sign:t[3],symbol:t[4],zero:t[5],width:t[6],comma:t[7],precision:t[8]&&t[8].slice(1),trim:t[9],type:t[10]})}function Se(e){this.fill=void 0===e.fill?\" \":e.fill+\"\",this.align=void 0===e.align?\">\":e.align+\"\",this.sign=void 0===e.sign?\"-\":e.sign+\"\",this.symbol=void 0===e.symbol?\"\":e.symbol+\"\",this.zero=!!e.zero,this.width=void 0===e.width?void 0:+e.width,this.comma=!!e.comma,this.precision=void 0===e.precision?void 0:+e.precision,this.trim=!!e.trim,this.type=void 0===e.type?\"\":e.type+\"\"}function Ee(e,t){if((n=(e=t?e.toExponential(t-1):e.toExponential()).indexOf(\"e\"))<0)return null;var n,r=e.slice(0,n);return[r.length>1?r[0]+r.slice(2):r,+e.slice(n+1)]}function Ce(e){return(e=Ee(Math.abs(e)))?e[1]:NaN}function Te(e,t){var n=Ee(e,t);if(!n)return e+\"\";var r=n[0],a=n[1];return a<0?\"0.\"+new Array(-a).join(\"0\")+r:r.length>a+1?r.slice(0,a+1)+\".\"+r.slice(a+1):r+new Array(a-r.length+2).join(\"0\")}ke.prototype=Se.prototype,Se.prototype.toString=function(){return this.fill+this.align+this.sign+this.symbol+(this.zero?\"0\":\"\")+(void 0===this.width?\"\":Math.max(1,0|this.width))+(this.comma?\",\":\"\")+(void 0===this.precision?\"\":\".\"+Math.max(0,0|this.precision))+(this.trim?\"~\":\"\")+this.type};const Me={\"%\":(e,t)=>(100*e).toFixed(t),b:e=>Math.round(e).toString(2),c:e=>e+\"\",d:function(e){return Math.abs(e=Math.round(e))>=1e21?e.toLocaleString(\"en\").replace(/,/g,\"\"):e.toString(10)},e:(e,t)=>e.toExponential(t),f:(e,t)=>e.toFixed(t),g:(e,t)=>e.toPrecision(t),o:e=>Math.round(e).toString(8),p:(e,t)=>Te(100*e,t),r:Te,s:function(e,t){var n=Ee(e,t);if(!n)return e+\"\";var r=n[0],a=n[1],i=a-(we=3*Math.max(-8,Math.min(8,Math.floor(a/3))))+1,o=r.length;return i===o?r:i>o?r+new Array(i-o+1).join(\"0\"):i>0?r.slice(0,i)+\".\"+r.slice(i):\"0.\"+new Array(1-i).join(\"0\")+Ee(e,Math.max(0,t+i-1))[0]},X:e=>Math.round(e).toString(16).toUpperCase(),x:e=>Math.round(e).toString(16)};function Ne(e){return e}var Pe,ze,Le,Oe=Array.prototype.map,Ae=[\"y\",\"z\",\"a\",\"f\",\"p\",\"n\",\"µ\",\"m\",\"\",\"k\",\"M\",\"G\",\"T\",\"P\",\"E\",\"Z\",\"Y\"];function Fe(e){var t=e.domain;return e.ticks=function(e){var n=t();return function(e,t,n){if(!((n=+n)>0))return[];if((e=+e)==(t=+t))return[e];const r=t<e,[a,i,u]=r?o(t,e,n):o(e,t,n);if(!(i>=a))return[];const l=i-a+1,s=new Array(l);if(r)if(u<0)for(let e=0;e<l;++e)s[e]=(i-e)/-u;else for(let e=0;e<l;++e)s[e]=(i-e)*u;else if(u<0)for(let e=0;e<l;++e)s[e]=(a+e)/-u;else for(let e=0;e<l;++e)s[e]=(a+e)*u;return s}(n[0],n[n.length-1],null==e?10:e)},e.tickFormat=function(e,n){var r=t();return function(e,t,n,r){var a,i=l(e,t,n);switch((r=ke(null==r?\",f\":r)).type){case\"s\":var o=Math.max(Math.abs(e),Math.abs(t));return null!=r.precision||isNaN(a=function(e,t){return Math.max(0,3*Math.max(-8,Math.min(8,Math.floor(Ce(t)/3)))-Ce(Math.abs(e)))}(i,o))||(r.precision=a),Le(r,o);case\"\":case\"e\":case\"g\":case\"p\":case\"r\":null!=r.precision||isNaN(a=function(e,t){return e=Math.abs(e),t=Math.abs(t)-e,Math.max(0,Ce(t)-Ce(e))+1}(i,Math.max(Math.abs(e),Math.abs(t))))||(r.precision=a-(\"e\"===r.type));break;case\"f\":case\"%\":null!=r.precision||isNaN(a=function(e){return Math.max(0,-Ce(Math.abs(e)))}(i))||(r.precision=a-2*(\"%\"===r.type))}return ze(r)}(r[0],r[r.length-1],null==e?10:e,n)},e.nice=function(n){null==n&&(n=10);var r,a,i=t(),o=0,l=i.length-1,s=i[o],c=i[l],f=10;for(c<s&&(a=s,s=c,c=a,a=o,o=l,l=a);f-- >0;){if((a=u(s,c,n))===r)return i[o]=s,i[l]=c,t(i);if(a>0)s=Math.floor(s/a)*a,c=Math.ceil(c/a)*a;else{if(!(a<0))break;s=Math.ceil(s*a)/a,c=Math.floor(c*a)/a}r=a}return e},e}function De(){var e=be();return e.copy=function(){return me(e,De())},_e.apply(e,arguments),Fe(e)}Pe=function(e){var t,n,r=void 0===e.grouping||void 0===e.thousands?Ne:(t=Oe.call(e.grouping,Number),n=e.thousands+\"\",function(e,r){for(var a=e.length,i=[],o=0,u=t[0],l=0;a>0&&u>0&&(l+u+1>r&&(u=Math.max(1,r-l)),i.push(e.substring(a-=u,a+u)),!((l+=u+1)>r));)u=t[o=(o+1)%t.length];return i.reverse().join(n)}),a=void 0===e.currency?\"\":e.currency[0]+\"\",i=void 0===e.currency?\"\":e.currency[1]+\"\",o=void 0===e.decimal?\".\":e.decimal+\"\",u=void 0===e.numerals?Ne:function(e){return function(t){return t.replace(/[0-9]/g,(function(t){return e[+t]}))}}(Oe.call(e.numerals,String)),l=void 0===e.percent?\"%\":e.percent+\"\",s=void 0===e.minus?\"−\":e.minus+\"\",c=void 0===e.nan?\"NaN\":e.nan+\"\";function f(e){var t=(e=ke(e)).fill,n=e.align,f=e.sign,p=e.symbol,d=e.zero,h=e.width,v=e.comma,g=e.precision,y=e.trim,m=e.type;\"n\"===m?(v=!0,m=\"g\"):Me[m]||(void 0===g&&(g=12),y=!0,m=\"g\"),(d||\"0\"===t&&\"=\"===n)&&(d=!0,t=\"0\",n=\"=\");var b=\"$\"===p?a:\"#\"===p&&/[boxX]/.test(m)?\"0\"+m.toLowerCase():\"\",_=\"$\"===p?i:/[%p]/.test(m)?l:\"\",w=Me[m],x=/[defgprs%]/.test(m);function k(e){var a,i,l,p=b,k=_;if(\"c\"===m)k=w(e)+k,e=\"\";else{var S=(e=+e)<0||1/e<0;if(e=isNaN(e)?c:w(Math.abs(e),g),y&&(e=function(e){e:for(var t,n=e.length,r=1,a=-1;r<n;++r)switch(e[r]){case\".\":a=t=r;break;case\"0\":0===a&&(a=r),t=r;break;default:if(!+e[r])break e;a>0&&(a=0)}return a>0?e.slice(0,a)+e.slice(t+1):e}(e)),S&&0==+e&&\"+\"!==f&&(S=!1),p=(S?\"(\"===f?f:s:\"-\"===f||\"(\"===f?\"\":f)+p,k=(\"s\"===m?Ae[8+we/3]:\"\")+k+(S&&\"(\"===f?\")\":\"\"),x)for(a=-1,i=e.length;++a<i;)if(48>(l=e.charCodeAt(a))||l>57){k=(46===l?o+e.slice(a+1):e.slice(a))+k,e=e.slice(0,a);break}}v&&!d&&(e=r(e,1/0));var E=p.length+e.length+k.length,C=E<h?new Array(h-E+1).join(t):\"\";switch(v&&d&&(e=r(C+e,C.length?h-k.length:1/0),C=\"\"),n){case\"<\":e=p+e+k+C;break;case\"=\":e=p+C+e+k;break;case\"^\":e=C.slice(0,E=C.length>>1)+p+e+k+C.slice(E);break;default:e=C+p+e+k}return u(e)}return g=void 0===g?6:/[gprs]/.test(m)?Math.max(1,Math.min(21,g)):Math.max(0,Math.min(20,g)),k.toString=function(){return e+\"\"},k}return{format:f,formatPrefix:function(e,t){var n=f(((e=ke(e)).type=\"f\",e)),r=3*Math.max(-8,Math.min(8,Math.floor(Ce(t)/3))),a=Math.pow(10,-r),i=Ae[8+r/3];return function(e){return n(a*e)+i}}}}({thousands:\",\",grouping:[3],currency:[\"$\",\"\"]}),ze=Pe.format,Le=Pe.formatPrefix;var Re=n(486);const je={colors:{RdBu:[\"rgb(255, 13, 87)\",\"rgb(30, 136, 229)\"],GnPR:[\"rgb(24, 196, 93)\",\"rgb(124, 82, 255)\"],CyPU:[\"#0099C6\",\"#990099\"],PkYg:[\"#DD4477\",\"#66AA00\"],DrDb:[\"#B82E2E\",\"#316395\"],LpLb:[\"#994499\",\"#22AA99\"],YlDp:[\"#AAAA11\",\"#6633CC\"],OrId:[\"#E67300\",\"#3E0099\"]},gray:\"#777\"};function Ue(e){return Ue=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Ue(e)}function Ie(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Ue(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Ue(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Ue(a)?a:String(a)),r)}var a}function $e(e,t){return $e=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},$e(e,t)}function Be(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function We(e){return We=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},We(e)}var Ve=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&$e(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=We(a);if(i){var n=We(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Ue(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return Be(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),(e=o.call(this)).width=100,window.lastSimpleListInstance=Be(e),e.effectFormat=ze(\".2\"),e}return n=u,(r=[{key:\"render\",value:function(){var t=this,n=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?n=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),n=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(n=this.props.plot_cmap),console.log(this.props.features,this.props.features),this.scale=De().domain([0,(0,Re.max)((0,Re.map)(this.props.features,(function(e){return Math.abs(e.effect)})))]).range([0,this.width]);var r=(0,Re.reverse)((0,Re.sortBy)(Object.keys(this.props.features),(function(e){return Math.abs(t.props.features[e].effect)}))).map((function(r){var a,i,o=t.props.features[r],u=t.props.featureNames[r],l={width:t.scale(Math.abs(o.effect)),height:\"20px\",background:o.effect<0?n[0]:n[1],display:\"inline-block\"},s={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginRight:\"5px\",textAlign:\"right\"},c={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginLeft:\"5px\"};return o.effect<0?(i=e.createElement(\"span\",{style:c},u),s.width=40+t.width-t.scale(Math.abs(o.effect)),s.textAlign=\"right\",s.color=\"#999\",s.fontSize=\"13px\",a=e.createElement(\"span\",{style:s},t.effectFormat(o.effect))):(s.textAlign=\"right\",a=e.createElement(\"span\",{style:s},u),c.width=40,c.textAlign=\"left\",c.color=\"#999\",c.fontSize=\"13px\",i=e.createElement(\"span\",{style:c},t.effectFormat(o.effect))),e.createElement(\"div\",{key:r,style:{marginTop:\"2px\"}},a,e.createElement(\"div\",{style:l}),i)}));return e.createElement(\"span\",null,r)}}])&&Ie(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);Ve.defaultProps={plot_cmap:\"RdBu\"};const He=Ve;function qe(){}function Qe(e){return null==e?qe:function(){return this.querySelector(e)}}function Ye(){return[]}function Ge(e){return function(t){return t.matches(e)}}var Ke=Array.prototype.find;function Ze(){return this.firstElementChild}var Xe=Array.prototype.filter;function Je(){return Array.from(this.children)}function et(e){return new Array(e.length)}function tt(e,t){this.ownerDocument=e.ownerDocument,this.namespaceURI=e.namespaceURI,this._next=null,this._parent=e,this.__data__=t}function nt(e,t,n,r,a,i){for(var o,u=0,l=t.length,s=i.length;u<s;++u)(o=t[u])?(o.__data__=i[u],r[u]=o):n[u]=new tt(e,i[u]);for(;u<l;++u)(o=t[u])&&(a[u]=o)}function rt(e,t,n,r,a,i,o){var u,l,s,c=new Map,f=t.length,p=i.length,d=new Array(f);for(u=0;u<f;++u)(l=t[u])&&(d[u]=s=o.call(l,l.__data__,u,t)+\"\",c.has(s)?a[u]=l:c.set(s,l));for(u=0;u<p;++u)s=o.call(e,i[u],u,i)+\"\",(l=c.get(s))?(r[u]=l,l.__data__=i[u],c.delete(s)):n[u]=new tt(e,i[u]);for(u=0;u<f;++u)(l=t[u])&&c.get(d[u])===l&&(a[u]=l)}function at(e){return e.__data__}function it(e){return\"object\"==typeof e&&\"length\"in e?e:Array.from(e)}function ot(e,t){return e<t?-1:e>t?1:e>=t?0:NaN}tt.prototype={constructor:tt,appendChild:function(e){return this._parent.insertBefore(e,this._next)},insertBefore:function(e,t){return this._parent.insertBefore(e,t)},querySelector:function(e){return this._parent.querySelector(e)},querySelectorAll:function(e){return this._parent.querySelectorAll(e)}};var ut=\"http://www.w3.org/1999/xhtml\";const lt={svg:\"http://www.w3.org/2000/svg\",xhtml:ut,xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\",xmlns:\"http://www.w3.org/2000/xmlns/\"};function st(e){var t=e+=\"\",n=t.indexOf(\":\");return n>=0&&\"xmlns\"!==(t=e.slice(0,n))&&(e=e.slice(n+1)),lt.hasOwnProperty(t)?{space:lt[t],local:e}:e}function ct(e){return function(){this.removeAttribute(e)}}function ft(e){return function(){this.removeAttributeNS(e.space,e.local)}}function pt(e,t){return function(){this.setAttribute(e,t)}}function dt(e,t){return function(){this.setAttributeNS(e.space,e.local,t)}}function ht(e,t){return function(){var n=t.apply(this,arguments);null==n?this.removeAttribute(e):this.setAttribute(e,n)}}function vt(e,t){return function(){var n=t.apply(this,arguments);null==n?this.removeAttributeNS(e.space,e.local):this.setAttributeNS(e.space,e.local,n)}}function gt(e){return e.ownerDocument&&e.ownerDocument.defaultView||e.document&&e||e.defaultView}function yt(e){return function(){this.style.removeProperty(e)}}function mt(e,t,n){return function(){this.style.setProperty(e,t,n)}}function bt(e,t,n){return function(){var r=t.apply(this,arguments);null==r?this.style.removeProperty(e):this.style.setProperty(e,r,n)}}function _t(e){return function(){delete this[e]}}function wt(e,t){return function(){this[e]=t}}function xt(e,t){return function(){var n=t.apply(this,arguments);null==n?delete this[e]:this[e]=n}}function kt(e){return e.trim().split(/^|\\s+/)}function St(e){return e.classList||new Et(e)}function Et(e){this._node=e,this._names=kt(e.getAttribute(\"class\")||\"\")}function Ct(e,t){for(var n=St(e),r=-1,a=t.length;++r<a;)n.add(t[r])}function Tt(e,t){for(var n=St(e),r=-1,a=t.length;++r<a;)n.remove(t[r])}function Mt(e){return function(){Ct(this,e)}}function Nt(e){return function(){Tt(this,e)}}function Pt(e,t){return function(){(t.apply(this,arguments)?Ct:Tt)(this,e)}}function zt(){this.textContent=\"\"}function Lt(e){return function(){this.textContent=e}}function Ot(e){return function(){var t=e.apply(this,arguments);this.textContent=null==t?\"\":t}}function At(){this.innerHTML=\"\"}function Ft(e){return function(){this.innerHTML=e}}function Dt(e){return function(){var t=e.apply(this,arguments);this.innerHTML=null==t?\"\":t}}function Rt(){this.nextSibling&&this.parentNode.appendChild(this)}function jt(){this.previousSibling&&this.parentNode.insertBefore(this,this.parentNode.firstChild)}function Ut(e){return function(){var t=this.ownerDocument,n=this.namespaceURI;return n===ut&&t.documentElement.namespaceURI===ut?t.createElement(e):t.createElementNS(n,e)}}function It(e){return function(){return this.ownerDocument.createElementNS(e.space,e.local)}}function $t(e){var t=st(e);return(t.local?It:Ut)(t)}function Bt(){return null}function Wt(){var e=this.parentNode;e&&e.removeChild(this)}function Vt(){var e=this.cloneNode(!1),t=this.parentNode;return t?t.insertBefore(e,this.nextSibling):e}function Ht(){var e=this.cloneNode(!0),t=this.parentNode;return t?t.insertBefore(e,this.nextSibling):e}function qt(e){return function(){var t=this.__on;if(t){for(var n,r=0,a=-1,i=t.length;r<i;++r)n=t[r],e.type&&n.type!==e.type||n.name!==e.name?t[++a]=n:this.removeEventListener(n.type,n.listener,n.options);++a?t.length=a:delete this.__on}}}function Qt(e,t,n){return function(){var r,a=this.__on,i=function(e){return function(t){e.call(this,t,this.__data__)}}(t);if(a)for(var o=0,u=a.length;o<u;++o)if((r=a[o]).type===e.type&&r.name===e.name)return this.removeEventListener(r.type,r.listener,r.options),this.addEventListener(r.type,r.listener=i,r.options=n),void(r.value=t);this.addEventListener(e.type,i,n),r={type:e.type,name:e.name,value:t,listener:i,options:n},a?a.push(r):this.__on=[r]}}function Yt(e,t,n){var r=gt(e),a=r.CustomEvent;\"function\"==typeof a?a=new a(t,n):(a=r.document.createEvent(\"Event\"),n?(a.initEvent(t,n.bubbles,n.cancelable),a.detail=n.detail):a.initEvent(t,!1,!1)),e.dispatchEvent(a)}function Gt(e,t){return function(){return Yt(this,e,t)}}function Kt(e,t){return function(){return Yt(this,e,t.apply(this,arguments))}}Et.prototype={add:function(e){this._names.indexOf(e)<0&&(this._names.push(e),this._node.setAttribute(\"class\",this._names.join(\" \")))},remove:function(e){var t=this._names.indexOf(e);t>=0&&(this._names.splice(t,1),this._node.setAttribute(\"class\",this._names.join(\" \")))},contains:function(e){return this._names.indexOf(e)>=0}};var Zt=[null];function Xt(e,t){this._groups=e,this._parents=t}function Jt(e){return\"string\"==typeof e?new Xt([[document.querySelector(e)]],[document.documentElement]):new Xt([[e]],Zt)}function en(e){return e}Xt.prototype=function(){return new Xt([[document.documentElement]],Zt)}.prototype={constructor:Xt,select:function(e){\"function\"!=typeof e&&(e=Qe(e));for(var t=this._groups,n=t.length,r=new Array(n),a=0;a<n;++a)for(var i,o,u=t[a],l=u.length,s=r[a]=new Array(l),c=0;c<l;++c)(i=u[c])&&(o=e.call(i,i.__data__,c,u))&&(\"__data__\"in i&&(o.__data__=i.__data__),s[c]=o);return new Xt(r,this._parents)},selectAll:function(e){e=\"function\"==typeof e?function(e){return function(){return null==(t=e.apply(this,arguments))?[]:Array.isArray(t)?t:Array.from(t);var t}}(e):function(e){return null==e?Ye:function(){return this.querySelectorAll(e)}}(e);for(var t=this._groups,n=t.length,r=[],a=[],i=0;i<n;++i)for(var o,u=t[i],l=u.length,s=0;s<l;++s)(o=u[s])&&(r.push(e.call(o,o.__data__,s,u)),a.push(o));return new Xt(r,a)},selectChild:function(e){return this.select(null==e?Ze:function(e){return function(){return Ke.call(this.children,e)}}(\"function\"==typeof e?e:Ge(e)))},selectChildren:function(e){return this.selectAll(null==e?Je:function(e){return function(){return Xe.call(this.children,e)}}(\"function\"==typeof e?e:Ge(e)))},filter:function(e){\"function\"!=typeof e&&(e=function(e){return function(){return this.matches(e)}}(e));for(var t=this._groups,n=t.length,r=new Array(n),a=0;a<n;++a)for(var i,o=t[a],u=o.length,l=r[a]=[],s=0;s<u;++s)(i=o[s])&&e.call(i,i.__data__,s,o)&&l.push(i);return new Xt(r,this._parents)},data:function(e,t){if(!arguments.length)return Array.from(this,at);var n,r=t?rt:nt,a=this._parents,i=this._groups;\"function\"!=typeof e&&(n=e,e=function(){return n});for(var o=i.length,u=new Array(o),l=new Array(o),s=new Array(o),c=0;c<o;++c){var f=a[c],p=i[c],d=p.length,h=it(e.call(f,f&&f.__data__,c,a)),v=h.length,g=l[c]=new Array(v),y=u[c]=new Array(v);r(f,p,g,y,s[c]=new Array(d),h,t);for(var m,b,_=0,w=0;_<v;++_)if(m=g[_]){for(_>=w&&(w=_+1);!(b=y[w])&&++w<v;);m._next=b||null}}return(u=new Xt(u,a))._enter=l,u._exit=s,u},enter:function(){return new Xt(this._enter||this._groups.map(et),this._parents)},exit:function(){return new Xt(this._exit||this._groups.map(et),this._parents)},join:function(e,t,n){var r=this.enter(),a=this,i=this.exit();return\"function\"==typeof e?(r=e(r))&&(r=r.selection()):r=r.append(e+\"\"),null!=t&&(a=t(a))&&(a=a.selection()),null==n?i.remove():n(i),r&&a?r.merge(a).order():a},merge:function(e){for(var t=e.selection?e.selection():e,n=this._groups,r=t._groups,a=n.length,i=r.length,o=Math.min(a,i),u=new Array(a),l=0;l<o;++l)for(var s,c=n[l],f=r[l],p=c.length,d=u[l]=new Array(p),h=0;h<p;++h)(s=c[h]||f[h])&&(d[h]=s);for(;l<a;++l)u[l]=n[l];return new Xt(u,this._parents)},selection:function(){return this},order:function(){for(var e=this._groups,t=-1,n=e.length;++t<n;)for(var r,a=e[t],i=a.length-1,o=a[i];--i>=0;)(r=a[i])&&(o&&4^r.compareDocumentPosition(o)&&o.parentNode.insertBefore(r,o),o=r);return this},sort:function(e){function t(t,n){return t&&n?e(t.__data__,n.__data__):!t-!n}e||(e=ot);for(var n=this._groups,r=n.length,a=new Array(r),i=0;i<r;++i){for(var o,u=n[i],l=u.length,s=a[i]=new Array(l),c=0;c<l;++c)(o=u[c])&&(s[c]=o);s.sort(t)}return new Xt(a,this._parents).order()},call:function(){var e=arguments[0];return arguments[0]=this,e.apply(null,arguments),this},nodes:function(){return Array.from(this)},node:function(){for(var e=this._groups,t=0,n=e.length;t<n;++t)for(var r=e[t],a=0,i=r.length;a<i;++a){var o=r[a];if(o)return o}return null},size:function(){let e=0;for(const t of this)++e;return e},empty:function(){return!this.node()},each:function(e){for(var t=this._groups,n=0,r=t.length;n<r;++n)for(var a,i=t[n],o=0,u=i.length;o<u;++o)(a=i[o])&&e.call(a,a.__data__,o,i);return this},attr:function(e,t){var n=st(e);if(arguments.length<2){var r=this.node();return n.local?r.getAttributeNS(n.space,n.local):r.getAttribute(n)}return this.each((null==t?n.local?ft:ct:\"function\"==typeof t?n.local?vt:ht:n.local?dt:pt)(n,t))},style:function(e,t,n){return arguments.length>1?this.each((null==t?yt:\"function\"==typeof t?bt:mt)(e,t,null==n?\"\":n)):function(e,t){return e.style.getPropertyValue(t)||gt(e).getComputedStyle(e,null).getPropertyValue(t)}(this.node(),e)},property:function(e,t){return arguments.length>1?this.each((null==t?_t:\"function\"==typeof t?xt:wt)(e,t)):this.node()[e]},classed:function(e,t){var n=kt(e+\"\");if(arguments.length<2){for(var r=St(this.node()),a=-1,i=n.length;++a<i;)if(!r.contains(n[a]))return!1;return!0}return this.each((\"function\"==typeof t?Pt:t?Mt:Nt)(n,t))},text:function(e){return arguments.length?this.each(null==e?zt:(\"function\"==typeof e?Ot:Lt)(e)):this.node().textContent},html:function(e){return arguments.length?this.each(null==e?At:(\"function\"==typeof e?Dt:Ft)(e)):this.node().innerHTML},raise:function(){return this.each(Rt)},lower:function(){return this.each(jt)},append:function(e){var t=\"function\"==typeof e?e:$t(e);return this.select((function(){return this.appendChild(t.apply(this,arguments))}))},insert:function(e,t){var n=\"function\"==typeof e?e:$t(e),r=null==t?Bt:\"function\"==typeof t?t:Qe(t);return this.select((function(){return this.insertBefore(n.apply(this,arguments),r.apply(this,arguments)||null)}))},remove:function(){return this.each(Wt)},clone:function(e){return this.select(e?Ht:Vt)},datum:function(e){return arguments.length?this.property(\"__data__\",e):this.node().__data__},on:function(e,t,n){var r,a,i=function(e){return e.trim().split(/^|\\s+/).map((function(e){var t=\"\",n=e.indexOf(\".\");return n>=0&&(t=e.slice(n+1),e=e.slice(0,n)),{type:e,name:t}}))}(e+\"\"),o=i.length;if(!(arguments.length<2)){for(u=t?Qt:qt,r=0;r<o;++r)this.each(u(i[r],t,n));return this}var u=this.node().__on;if(u)for(var l,s=0,c=u.length;s<c;++s)for(r=0,l=u[s];r<o;++r)if((a=i[r]).type===l.type&&a.name===l.name)return l.value},dispatch:function(e,t){return this.each((\"function\"==typeof t?Kt:Gt)(e,t))},[Symbol.iterator]:function*(){for(var e=this._groups,t=0,n=e.length;t<n;++t)for(var r,a=e[t],i=0,o=a.length;i<o;++i)(r=a[i])&&(yield r)}};var tn=1,nn=2,rn=3,an=4,on=1e-6;function un(e){return\"translate(\"+e+\",0)\"}function ln(e){return\"translate(0,\"+e+\")\"}function sn(e){return t=>+e(t)}function cn(e,t){return t=Math.max(0,e.bandwidth()-2*t)/2,e.round()&&(t=Math.round(t)),n=>+e(n)+t}function fn(){return!this.__axis}function pn(e,t){var n=[],r=null,a=null,i=6,o=6,u=3,l=\"undefined\"!=typeof window&&window.devicePixelRatio>1?0:.5,s=e===tn||e===an?-1:1,c=e===an||e===nn?\"x\":\"y\",f=e===tn||e===rn?un:ln;function p(p){var d=null==r?t.ticks?t.ticks.apply(t,n):t.domain():r,h=null==a?t.tickFormat?t.tickFormat.apply(t,n):en:a,v=Math.max(i,0)+u,g=t.range(),y=+g[0]+l,m=+g[g.length-1]+l,b=(t.bandwidth?cn:sn)(t.copy(),l),_=p.selection?p.selection():p,w=_.selectAll(\".domain\").data([null]),x=_.selectAll(\".tick\").data(d,t).order(),k=x.exit(),S=x.enter().append(\"g\").attr(\"class\",\"tick\"),E=x.select(\"line\"),C=x.select(\"text\");w=w.merge(w.enter().insert(\"path\",\".tick\").attr(\"class\",\"domain\").attr(\"stroke\",\"currentColor\")),x=x.merge(S),E=E.merge(S.append(\"line\").attr(\"stroke\",\"currentColor\").attr(c+\"2\",s*i)),C=C.merge(S.append(\"text\").attr(\"fill\",\"currentColor\").attr(c,s*v).attr(\"dy\",e===tn?\"0em\":e===rn?\"0.71em\":\"0.32em\")),p!==_&&(w=w.transition(p),x=x.transition(p),E=E.transition(p),C=C.transition(p),k=k.transition(p).attr(\"opacity\",on).attr(\"transform\",(function(e){return isFinite(e=b(e))?f(e+l):this.getAttribute(\"transform\")})),S.attr(\"opacity\",on).attr(\"transform\",(function(e){var t=this.parentNode.__axis;return f((t&&isFinite(t=t(e))?t:b(e))+l)}))),k.remove(),w.attr(\"d\",e===an||e===nn?o?\"M\"+s*o+\",\"+y+\"H\"+l+\"V\"+m+\"H\"+s*o:\"M\"+l+\",\"+y+\"V\"+m:o?\"M\"+y+\",\"+s*o+\"V\"+l+\"H\"+m+\"V\"+s*o:\"M\"+y+\",\"+l+\"H\"+m),x.attr(\"opacity\",1).attr(\"transform\",(function(e){return f(b(e)+l)})),E.attr(c+\"2\",s*i),C.attr(c,s*v).text(h),_.filter(fn).attr(\"fill\",\"none\").attr(\"font-size\",10).attr(\"font-family\",\"sans-serif\").attr(\"text-anchor\",e===nn?\"start\":e===an?\"end\":\"middle\"),_.each((function(){this.__axis=b}))}return p.scale=function(e){return arguments.length?(t=e,p):t},p.ticks=function(){return n=Array.from(arguments),p},p.tickArguments=function(e){return arguments.length?(n=null==e?[]:Array.from(e),p):n.slice()},p.tickValues=function(e){return arguments.length?(r=null==e?null:Array.from(e),p):r&&r.slice()},p.tickFormat=function(e){return arguments.length?(a=e,p):a},p.tickSize=function(e){return arguments.length?(i=o=+e,p):i},p.tickSizeInner=function(e){return arguments.length?(i=+e,p):i},p.tickSizeOuter=function(e){return arguments.length?(o=+e,p):o},p.tickPadding=function(e){return arguments.length?(u=+e,p):u},p.offset=function(e){return arguments.length?(l=+e,p):l},p}function dn(e){return pn(rn,e)}function hn(e){return function(){return e}}function vn(e){this._context=e}function gn(e){return new vn(e)}Array.prototype.slice,vn.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._point=0},lineEnd:function(){(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(e,t){switch(e=+e,t=+t,this._point){case 0:this._point=1,this._line?this._context.lineTo(e,t):this._context.moveTo(e,t);break;case 1:this._point=2;default:this._context.lineTo(e,t)}}};const yn=Math.PI,mn=2*yn,bn=1e-6,_n=mn-bn;function wn(e){this._+=e[0];for(let t=1,n=e.length;t<n;++t)this._+=arguments[t]+e[t]}class xn{constructor(e){this._x0=this._y0=this._x1=this._y1=null,this._=\"\",this._append=null==e?wn:function(e){let t=Math.floor(e);if(!(t>=0))throw new Error(`invalid digits: ${e}`);if(t>15)return wn;const n=10**t;return function(e){this._+=e[0];for(let t=1,r=e.length;t<r;++t)this._+=Math.round(arguments[t]*n)/n+e[t]}}(e)}moveTo(e,t){this._append`M${this._x0=this._x1=+e},${this._y0=this._y1=+t}`}closePath(){null!==this._x1&&(this._x1=this._x0,this._y1=this._y0,this._append`Z`)}lineTo(e,t){this._append`L${this._x1=+e},${this._y1=+t}`}quadraticCurveTo(e,t,n,r){this._append`Q${+e},${+t},${this._x1=+n},${this._y1=+r}`}bezierCurveTo(e,t,n,r,a,i){this._append`C${+e},${+t},${+n},${+r},${this._x1=+a},${this._y1=+i}`}arcTo(e,t,n,r,a){if(e=+e,t=+t,n=+n,r=+r,(a=+a)<0)throw new Error(`negative radius: ${a}`);let i=this._x1,o=this._y1,u=n-e,l=r-t,s=i-e,c=o-t,f=s*s+c*c;if(null===this._x1)this._append`M${this._x1=e},${this._y1=t}`;else if(f>bn)if(Math.abs(c*u-l*s)>bn&&a){let p=n-i,d=r-o,h=u*u+l*l,v=p*p+d*d,g=Math.sqrt(h),y=Math.sqrt(f),m=a*Math.tan((yn-Math.acos((h+f-v)/(2*g*y)))/2),b=m/y,_=m/g;Math.abs(b-1)>bn&&this._append`L${e+b*s},${t+b*c}`,this._append`A${a},${a},0,0,${+(c*p>s*d)},${this._x1=e+_*u},${this._y1=t+_*l}`}else this._append`L${this._x1=e},${this._y1=t}`}arc(e,t,n,r,a,i){if(e=+e,t=+t,i=!!i,(n=+n)<0)throw new Error(`negative radius: ${n}`);let o=n*Math.cos(r),u=n*Math.sin(r),l=e+o,s=t+u,c=1^i,f=i?r-a:a-r;null===this._x1?this._append`M${l},${s}`:(Math.abs(this._x1-l)>bn||Math.abs(this._y1-s)>bn)&&this._append`L${l},${s}`,n&&(f<0&&(f=f%mn+mn),f>_n?this._append`A${n},${n},0,1,${c},${e-o},${t-u}A${n},${n},0,1,${c},${this._x1=l},${this._y1=s}`:f>bn&&this._append`A${n},${n},0,${+(f>=yn)},${c},${this._x1=e+n*Math.cos(a)},${this._y1=t+n*Math.sin(a)}`)}rect(e,t,n,r){this._append`M${this._x0=this._x1=+e},${this._y0=this._y1=+t}h${n=+n}v${+r}h${-n}Z`}toString(){return this._}}function kn(e){return e[0]}function Sn(e){return e[1]}function En(e,t){var n=hn(!0),r=null,a=gn,i=null,o=function(e){let t=3;return e.digits=function(n){if(!arguments.length)return t;if(null==n)t=null;else{const e=Math.floor(n);if(!(e>=0))throw new RangeError(`invalid digits: ${n}`);t=e}return e},()=>new xn(t)}(u);function u(u){var l,s,c,f=(u=function(e){return\"object\"==typeof e&&\"length\"in e?e:Array.from(e)}(u)).length,p=!1;for(null==r&&(i=a(c=o())),l=0;l<=f;++l)!(l<f&&n(s=u[l],l,u))===p&&((p=!p)?i.lineStart():i.lineEnd()),p&&i.point(+e(s,l,u),+t(s,l,u));if(c)return i=null,c+\"\"||null}return e=\"function\"==typeof e?e:void 0===e?kn:hn(e),t=\"function\"==typeof t?t:void 0===t?Sn:hn(t),u.x=function(t){return arguments.length?(e=\"function\"==typeof t?t:hn(+t),u):e},u.y=function(e){return arguments.length?(t=\"function\"==typeof e?e:hn(+e),u):t},u.defined=function(e){return arguments.length?(n=\"function\"==typeof e?e:hn(!!e),u):n},u.curve=function(e){return arguments.length?(a=e,null!=r&&(i=a(r)),u):a},u.context=function(e){return arguments.length?(null==e?r=i=null:i=a(r=e),u):r},u}function Cn(e){return Cn=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Cn(e)}function Tn(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Cn(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Cn(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Cn(a)?a:String(a)),r)}var a}function Mn(e,t){return Mn=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},Mn(e,t)}function Nn(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function Pn(e){return Pn=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},Pn(e)}var zn=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&Mn(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=Pn(a);if(i){var n=Pn(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Cn(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return Nn(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),e=o.call(this),window.lastAdditiveForceVisualizer=Nn(e),e.effectFormat=ze(\".2\"),e.redraw=(0,Re.debounce)((function(){return e.draw()}),200),e}return n=u,(r=[{key:\"componentDidMount\",value:function(){var e=this;this.mainGroup=this.svg.append(\"g\"),this.axisElement=this.mainGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-axis\"),this.onTopGroup=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.joinPointLine=this.svg.append(\"line\"),this.joinPointLabelOutline=this.svg.append(\"text\"),this.joinPointLabel=this.svg.append(\"text\"),this.joinPointTitleLeft=this.svg.append(\"text\"),this.joinPointTitleLeftArrow=this.svg.append(\"text\"),this.joinPointTitle=this.svg.append(\"text\"),this.joinPointTitleRightArrow=this.svg.append(\"text\"),this.joinPointTitleRight=this.svg.append(\"text\"),this.hoverLabelBacking=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").text(\"\").on(\"mouseover\",(function(){e.hoverLabel.attr(\"opacity\",1),e.hoverLabelBacking.attr(\"opacity\",1)})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)})),this.hoverLabel=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"fill\",\"#0f0\").text(\"\").on(\"mouseover\",(function(){e.hoverLabel.attr(\"opacity\",1),e.hoverLabelBacking.attr(\"opacity\",1)})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)}));var t=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?t=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),t=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(t=this.props.plot_cmap),this.colors=t.map((function(e){return q(e)})),this.brighterColors=[1.45,1.6].map((function(t,n){return e.colors[n].brighter(t)})),this.colors.map((function(t,n){var r=e.svg.append(\"linearGradient\").attr(\"id\",\"linear-grad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");r.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",t).attr(\"stop-opacity\",.6),r.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",t).attr(\"stop-opacity\",0);var a=e.svg.append(\"linearGradient\").attr(\"id\",\"linear-backgrad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");a.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",t).attr(\"stop-opacity\",.5),a.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",t).attr(\"stop-opacity\",0)})),this.tickFormat=ze(\",.4\"),this.scaleCentered=De(),this.axis=dn().scale(this.scaleCentered).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.tickFormat(e.invLinkFunction(t))})).tickPadding(-18),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"draw\",value:function(){var e=this;(0,Re.each)(this.props.featureNames,(function(t,n){e.props.features[n]&&(e.props.features[n].name=t)})),\"identity\"===this.props.link?this.invLinkFunction=function(t){return e.props.baseValue+t}:\"logit\"===this.props.link?this.invLinkFunction=function(t){return 1/(1+Math.exp(-(e.props.baseValue+t)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link);var t=this.svg.node().parentNode.offsetWidth;if(0==t)return setTimeout((function(){return e.draw(e.props)}),500);this.svg.style(\"height\",\"150px\"),this.svg.style(\"width\",t+\"px\");var n=(0,Re.sortBy)(this.props.features,(function(e){return-1/(e.effect+1e-10)})),r=(0,Re.sum)((0,Re.map)(n,(function(e){return Math.abs(e.effect)}))),a=(0,Re.sum)((0,Re.map)((0,Re.filter)(n,(function(e){return e.effect>0})),(function(e){return e.effect})))||0,i=(0,Re.sum)((0,Re.map)((0,Re.filter)(n,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0;this.domainSize=3*Math.max(a,i);var o=De().domain([0,this.domainSize]).range([0,t]),u=t/2-o(i);this.scaleCentered.domain([-this.domainSize/2,this.domainSize/2]).range([0,t]).clamp(!0),this.axisElement.attr(\"transform\",\"translate(0,50)\").call(this.axis);var l,s,c,f=0;for(l=0;l<n.length;++l)n[l].x=f,n[l].effect<0&&void 0===s&&(s=f,c=l),f+=Math.abs(n[l].effect);void 0===s&&(s=f,c=l);var p=En().x((function(e){return e[0]})).y((function(e){return e[1]})),d=function(t){return void 0!==t.value&&null!==t.value&&\"\"!==t.value?t.name+\" = \"+(isNaN(t.value)?t.value:e.tickFormat(t.value)):t.name};n=this.props.hideBars?[]:n;var h=this.mainGroup.selectAll(\".force-bar-blocks\").data(n);h.enter().append(\"path\").attr(\"class\",\"force-bar-blocks\").merge(h).attr(\"d\",(function(e,t){var n=o(e.x)+u,r=o(Math.abs(e.effect)),a=e.effect<0?-4:4,i=a;return t===c&&(a=0),t===c-1&&(i=0),p([[n,56],[n+r,56],[n+r+i,64.5],[n+r,73],[n,73],[n+a,64.5]])})).attr(\"fill\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})).on(\"mouseover\",(function(t){if(o(Math.abs(t.effect))<o(r)/50||o(Math.abs(t.effect))<10){var n=o(t.x)+u,a=o(Math.abs(t.effect));e.hoverLabel.attr(\"opacity\",1).attr(\"x\",n+a/2).attr(\"y\",50.5).attr(\"fill\",t.effect>0?e.colors[0]:e.colors[1]).text(d(t)),e.hoverLabelBacking.attr(\"opacity\",1).attr(\"x\",n+a/2).attr(\"y\",50.5).text(d(t))}})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)})),h.exit().remove();var v=(0,Re.filter)(n,(function(e){return o(Math.abs(e.effect))>o(r)/50&&o(Math.abs(e.effect))>10})),g=this.onTopGroup.selectAll(\".force-bar-labels\").data(v);if(g.exit().remove(),g=g.enter().append(\"text\").attr(\"class\",\"force-bar-labels\").attr(\"font-size\",\"12px\").attr(\"y\",98).merge(g).text((function(t){return void 0!==t.value&&null!==t.value&&\"\"!==t.value?t.name+\" = \"+(isNaN(t.value)?t.value:e.tickFormat(t.value)):t.name})).attr(\"fill\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})).attr(\"stroke\",(function(e){return e.textWidth=Math.max(this.getComputedTextLength(),o(Math.abs(e.effect))-10),e.innerTextWidth=this.getComputedTextLength(),\"none\"})),this.filteredData=v,n.length>0){f=s+o.invert(5);for(var y=c;y<n.length;++y)n[y].textx=f,f+=o.invert(n[y].textWidth+10);f=s-o.invert(5);for(var m=c-1;m>=0;--m)n[m].textx=f,f-=o.invert(n[m].textWidth+10)}g.attr(\"x\",(function(e){return o(e.textx)+u+(e.effect>0?-e.textWidth/2:e.textWidth/2)})).attr(\"text-anchor\",\"middle\"),v=(0,Re.filter)(v,(function(n){return o(n.textx)+u>e.props.labelMargin&&o(n.textx)+u<t-e.props.labelMargin})),this.filteredData2=v;var b=v.slice(),_=(0,Re.findIndex)(n,v[0])-1;_>=0&&b.unshift(n[_]);var w=this.mainGroup.selectAll(\".force-bar-labelBacking\").data(v);w.enter().append(\"path\").attr(\"class\",\"force-bar-labelBacking\").attr(\"stroke\",\"none\").attr(\"opacity\",.2).merge(w).attr(\"d\",(function(e){return p([[o(e.x)+o(Math.abs(e.effect))+u,73],[(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5,83],[(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5,104],[(e.effect>0?o(e.textx)-e.textWidth:o(e.textx))+u-5,104],[(e.effect>0?o(e.textx)-e.textWidth:o(e.textx))+u-5,83],[o(e.x)+u,73]])})).attr(\"fill\",(function(e){return\"url(#linear-backgrad-\".concat(e.effect>0?0:1,\")\")})),w.exit().remove();var x=this.mainGroup.selectAll(\".force-bar-labelDividers\").data(v.slice(0,-1));x.enter().append(\"rect\").attr(\"class\",\"force-bar-labelDividers\").attr(\"height\",\"21px\").attr(\"width\",\"1px\").attr(\"y\",83).merge(x).attr(\"x\",(function(e){return(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+4.5})).attr(\"fill\",(function(e){return\"url(#linear-grad-\".concat(e.effect>0?0:1,\")\")})),x.exit().remove();var k=this.mainGroup.selectAll(\".force-bar-labelLinks\").data(v.slice(0,-1));k.enter().append(\"line\").attr(\"class\",\"force-bar-labelLinks\").attr(\"y1\",73).attr(\"y2\",83).attr(\"stroke-opacity\",.5).attr(\"stroke-width\",1).merge(k).attr(\"x1\",(function(e){return o(e.x)+o(Math.abs(e.effect))+u})).attr(\"x2\",(function(e){return(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5})).attr(\"stroke\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})),k.exit().remove();var S=this.mainGroup.selectAll(\".force-bar-blockDividers\").data(n.slice(0,-1));S.enter().append(\"path\").attr(\"class\",\"force-bar-blockDividers\").attr(\"stroke-width\",2).attr(\"fill\",\"none\").merge(S).attr(\"d\",(function(e){var t=o(e.x)+o(Math.abs(e.effect))+u;return p([[t,56],[t+(e.effect<0?-4:4),64.5],[t,73]])})).attr(\"stroke\",(function(t,n){return c===n+1||Math.abs(t.effect)<1e-8?\"#rgba(0,0,0,0)\":t.effect>0?e.brighterColors[0]:e.brighterColors[1]})),S.exit().remove(),this.joinPointLine.attr(\"x1\",o(s)+u).attr(\"x2\",o(s)+u).attr(\"y1\",50).attr(\"y2\",56).attr(\"stroke\",\"#F2F2F2\").attr(\"stroke-width\",1).attr(\"opacity\",1),this.joinPointLabelOutline.attr(\"x\",o(s)+u).attr(\"y\",45).attr(\"color\",\"#fff\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",6).text(ze(\",.2f\")(this.invLinkFunction(s-i))).attr(\"opacity\",1),console.log(\"joinPoint\",s,u,50,i),this.joinPointLabel.attr(\"x\",o(s)+u).attr(\"y\",45).attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").text(ze(\",.2f\")(this.invLinkFunction(s-i))).attr(\"opacity\",1),this.joinPointTitle.attr(\"x\",o(s)+u).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(this.props.outNames[0]).attr(\"opacity\",.5),this.props.hideBars||(this.joinPointTitleLeft.attr(\"x\",o(s)+u-16).attr(\"y\",12).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"higher\").attr(\"opacity\",1),this.joinPointTitleRight.attr(\"x\",o(s)+u+16).attr(\"y\",12).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"lower\").attr(\"opacity\",1),this.joinPointTitleLeftArrow.attr(\"x\",o(s)+u+7).attr(\"y\",8).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"→\").attr(\"opacity\",1),this.joinPointTitleRightArrow.attr(\"x\",o(s)+u-7).attr(\"y\",14).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"←\").attr(\"opacity\",1)),this.props.hideBaseValueLabel||this.baseValueTitle.attr(\"x\",this.scaleCentered(0)).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(\"base value\").attr(\"opacity\",.5)}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return e.createElement(\"svg\",{ref:function(e){return t.svg=Jt(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}},e.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-axis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-axis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\"}}))}}])&&Tn(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);zn.defaultProps={plot_cmap:\"RdBu\"};const Ln=zn,On=1e3,An=6e4,Fn=36e5,Dn=864e5,Rn=6048e5,jn=31536e6,Un=new Date,In=new Date;function $n(e,t,n,r){function a(t){return e(t=0===arguments.length?new Date:new Date(+t)),t}return a.floor=t=>(e(t=new Date(+t)),t),a.ceil=n=>(e(n=new Date(n-1)),t(n,1),e(n),n),a.round=e=>{const t=a(e),n=a.ceil(e);return e-t<n-e?t:n},a.offset=(e,n)=>(t(e=new Date(+e),null==n?1:Math.floor(n)),e),a.range=(n,r,i)=>{const o=[];if(n=a.ceil(n),i=null==i?1:Math.floor(i),!(n<r&&i>0))return o;let u;do{o.push(u=new Date(+n)),t(n,i),e(n)}while(u<n&&n<r);return o},a.filter=n=>$n((t=>{if(t>=t)for(;e(t),!n(t);)t.setTime(t-1)}),((e,r)=>{if(e>=e)if(r<0)for(;++r<=0;)for(;t(e,-1),!n(e););else for(;--r>=0;)for(;t(e,1),!n(e););})),n&&(a.count=(t,r)=>(Un.setTime(+t),In.setTime(+r),e(Un),e(In),Math.floor(n(Un,In))),a.every=e=>(e=Math.floor(e),isFinite(e)&&e>0?e>1?a.filter(r?t=>r(t)%e==0:t=>a.count(0,t)%e==0):a:null)),a}const Bn=$n((()=>{}),((e,t)=>{e.setTime(+e+t)}),((e,t)=>t-e));Bn.every=e=>(e=Math.floor(e),isFinite(e)&&e>0?e>1?$n((t=>{t.setTime(Math.floor(t/e)*e)}),((t,n)=>{t.setTime(+t+n*e)}),((t,n)=>(n-t)/e)):Bn:null),Bn.range;const Wn=$n((e=>{e.setTime(e-e.getMilliseconds())}),((e,t)=>{e.setTime(+e+t*On)}),((e,t)=>(t-e)/On),(e=>e.getUTCSeconds())),Vn=(Wn.range,$n((e=>{e.setTime(e-e.getMilliseconds()-e.getSeconds()*On)}),((e,t)=>{e.setTime(+e+t*An)}),((e,t)=>(t-e)/An),(e=>e.getMinutes()))),Hn=(Vn.range,$n((e=>{e.setUTCSeconds(0,0)}),((e,t)=>{e.setTime(+e+t*An)}),((e,t)=>(t-e)/An),(e=>e.getUTCMinutes()))),qn=(Hn.range,$n((e=>{e.setTime(e-e.getMilliseconds()-e.getSeconds()*On-e.getMinutes()*An)}),((e,t)=>{e.setTime(+e+t*Fn)}),((e,t)=>(t-e)/Fn),(e=>e.getHours()))),Qn=(qn.range,$n((e=>{e.setUTCMinutes(0,0,0)}),((e,t)=>{e.setTime(+e+t*Fn)}),((e,t)=>(t-e)/Fn),(e=>e.getUTCHours()))),Yn=(Qn.range,$n((e=>e.setHours(0,0,0,0)),((e,t)=>e.setDate(e.getDate()+t)),((e,t)=>(t-e-(t.getTimezoneOffset()-e.getTimezoneOffset())*An)/Dn),(e=>e.getDate()-1))),Gn=(Yn.range,$n((e=>{e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+t)}),((e,t)=>(t-e)/Dn),(e=>e.getUTCDate()-1))),Kn=(Gn.range,$n((e=>{e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+t)}),((e,t)=>(t-e)/Dn),(e=>Math.floor(e/Dn))));function Zn(e){return $n((t=>{t.setDate(t.getDate()-(t.getDay()+7-e)%7),t.setHours(0,0,0,0)}),((e,t)=>{e.setDate(e.getDate()+7*t)}),((e,t)=>(t-e-(t.getTimezoneOffset()-e.getTimezoneOffset())*An)/Rn))}Kn.range;const Xn=Zn(0),Jn=Zn(1),er=Zn(2),tr=Zn(3),nr=Zn(4),rr=Zn(5),ar=Zn(6);function ir(e){return $n((t=>{t.setUTCDate(t.getUTCDate()-(t.getUTCDay()+7-e)%7),t.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+7*t)}),((e,t)=>(t-e)/Rn))}Xn.range,Jn.range,er.range,tr.range,nr.range,rr.range,ar.range;const or=ir(0),ur=ir(1),lr=ir(2),sr=ir(3),cr=ir(4),fr=ir(5),pr=ir(6),dr=(or.range,ur.range,lr.range,sr.range,cr.range,fr.range,pr.range,$n((e=>{e.setDate(1),e.setHours(0,0,0,0)}),((e,t)=>{e.setMonth(e.getMonth()+t)}),((e,t)=>t.getMonth()-e.getMonth()+12*(t.getFullYear()-e.getFullYear())),(e=>e.getMonth()))),hr=(dr.range,$n((e=>{e.setUTCDate(1),e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCMonth(e.getUTCMonth()+t)}),((e,t)=>t.getUTCMonth()-e.getUTCMonth()+12*(t.getUTCFullYear()-e.getUTCFullYear())),(e=>e.getUTCMonth()))),vr=(hr.range,$n((e=>{e.setMonth(0,1),e.setHours(0,0,0,0)}),((e,t)=>{e.setFullYear(e.getFullYear()+t)}),((e,t)=>t.getFullYear()-e.getFullYear()),(e=>e.getFullYear())));vr.every=e=>isFinite(e=Math.floor(e))&&e>0?$n((t=>{t.setFullYear(Math.floor(t.getFullYear()/e)*e),t.setMonth(0,1),t.setHours(0,0,0,0)}),((t,n)=>{t.setFullYear(t.getFullYear()+n*e)})):null,vr.range;const gr=$n((e=>{e.setUTCMonth(0,1),e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCFullYear(e.getUTCFullYear()+t)}),((e,t)=>t.getUTCFullYear()-e.getUTCFullYear()),(e=>e.getUTCFullYear()));function yr(e,t,n,r,a,i){const o=[[Wn,1,On],[Wn,5,5e3],[Wn,15,15e3],[Wn,30,3e4],[i,1,An],[i,5,3e5],[i,15,9e5],[i,30,18e5],[a,1,Fn],[a,3,108e5],[a,6,216e5],[a,12,432e5],[r,1,Dn],[r,2,1728e5],[n,1,Rn],[t,1,2592e6],[t,3,7776e6],[e,1,jn]];function u(t,n,r){const a=Math.abs(n-t)/r,i=f((([,,e])=>e)).right(o,a);if(i===o.length)return e.every(l(t/jn,n/jn,r));if(0===i)return Bn.every(Math.max(l(t,n,r),1));const[u,s]=o[a/o[i-1][2]<o[i][2]/a?i-1:i];return u.every(s)}return[function(e,t,n){const r=t<e;r&&([e,t]=[t,e]);const a=n&&\"function\"==typeof n.range?n:u(e,t,n),i=a?a.range(e,+t+1):[];return r?i.reverse():i},u]}gr.every=e=>isFinite(e=Math.floor(e))&&e>0?$n((t=>{t.setUTCFullYear(Math.floor(t.getUTCFullYear()/e)*e),t.setUTCMonth(0,1),t.setUTCHours(0,0,0,0)}),((t,n)=>{t.setUTCFullYear(t.getUTCFullYear()+n*e)})):null,gr.range;const[mr,br]=yr(gr,hr,or,Kn,Qn,Hn),[_r,wr]=yr(vr,dr,Xn,Yn,qn,Vn);function xr(e){if(0<=e.y&&e.y<100){var t=new Date(-1,e.m,e.d,e.H,e.M,e.S,e.L);return t.setFullYear(e.y),t}return new Date(e.y,e.m,e.d,e.H,e.M,e.S,e.L)}function kr(e){if(0<=e.y&&e.y<100){var t=new Date(Date.UTC(-1,e.m,e.d,e.H,e.M,e.S,e.L));return t.setUTCFullYear(e.y),t}return new Date(Date.UTC(e.y,e.m,e.d,e.H,e.M,e.S,e.L))}function Sr(e,t,n){return{y:e,m:t,d:n,H:0,M:0,S:0,L:0}}var Er,Cr,Tr,Mr={\"-\":\"\",_:\" \",0:\"0\"},Nr=/^\\s*\\d+/,Pr=/^%/,zr=/[\\\\^$*+?|[\\]().{}]/g;function Lr(e,t,n){var r=e<0?\"-\":\"\",a=(r?-e:e)+\"\",i=a.length;return r+(i<n?new Array(n-i+1).join(t)+a:a)}function Or(e){return e.replace(zr,\"\\\\$&\")}function Ar(e){return new RegExp(\"^(?:\"+e.map(Or).join(\"|\")+\")\",\"i\")}function Fr(e){return new Map(e.map(((e,t)=>[e.toLowerCase(),t])))}function Dr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.w=+r[0],n+r[0].length):-1}function Rr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.u=+r[0],n+r[0].length):-1}function jr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.U=+r[0],n+r[0].length):-1}function Ur(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.V=+r[0],n+r[0].length):-1}function Ir(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.W=+r[0],n+r[0].length):-1}function $r(e,t,n){var r=Nr.exec(t.slice(n,n+4));return r?(e.y=+r[0],n+r[0].length):-1}function Br(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.y=+r[0]+(+r[0]>68?1900:2e3),n+r[0].length):-1}function Wr(e,t,n){var r=/^(Z)|([+-]\\d\\d)(?::?(\\d\\d))?/.exec(t.slice(n,n+6));return r?(e.Z=r[1]?0:-(r[2]+(r[3]||\"00\")),n+r[0].length):-1}function Vr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.q=3*r[0]-3,n+r[0].length):-1}function Hr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.m=r[0]-1,n+r[0].length):-1}function qr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.d=+r[0],n+r[0].length):-1}function Qr(e,t,n){var r=Nr.exec(t.slice(n,n+3));return r?(e.m=0,e.d=+r[0],n+r[0].length):-1}function Yr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.H=+r[0],n+r[0].length):-1}function Gr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.M=+r[0],n+r[0].length):-1}function Kr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.S=+r[0],n+r[0].length):-1}function Zr(e,t,n){var r=Nr.exec(t.slice(n,n+3));return r?(e.L=+r[0],n+r[0].length):-1}function Xr(e,t,n){var r=Nr.exec(t.slice(n,n+6));return r?(e.L=Math.floor(r[0]/1e3),n+r[0].length):-1}function Jr(e,t,n){var r=Pr.exec(t.slice(n,n+1));return r?n+r[0].length:-1}function ea(e,t,n){var r=Nr.exec(t.slice(n));return r?(e.Q=+r[0],n+r[0].length):-1}function ta(e,t,n){var r=Nr.exec(t.slice(n));return r?(e.s=+r[0],n+r[0].length):-1}function na(e,t){return Lr(e.getDate(),t,2)}function ra(e,t){return Lr(e.getHours(),t,2)}function aa(e,t){return Lr(e.getHours()%12||12,t,2)}function ia(e,t){return Lr(1+Yn.count(vr(e),e),t,3)}function oa(e,t){return Lr(e.getMilliseconds(),t,3)}function ua(e,t){return oa(e,t)+\"000\"}function la(e,t){return Lr(e.getMonth()+1,t,2)}function sa(e,t){return Lr(e.getMinutes(),t,2)}function ca(e,t){return Lr(e.getSeconds(),t,2)}function fa(e){var t=e.getDay();return 0===t?7:t}function pa(e,t){return Lr(Xn.count(vr(e)-1,e),t,2)}function da(e){var t=e.getDay();return t>=4||0===t?nr(e):nr.ceil(e)}function ha(e,t){return e=da(e),Lr(nr.count(vr(e),e)+(4===vr(e).getDay()),t,2)}function va(e){return e.getDay()}function ga(e,t){return Lr(Jn.count(vr(e)-1,e),t,2)}function ya(e,t){return Lr(e.getFullYear()%100,t,2)}function ma(e,t){return Lr((e=da(e)).getFullYear()%100,t,2)}function ba(e,t){return Lr(e.getFullYear()%1e4,t,4)}function _a(e,t){var n=e.getDay();return Lr((e=n>=4||0===n?nr(e):nr.ceil(e)).getFullYear()%1e4,t,4)}function wa(e){var t=e.getTimezoneOffset();return(t>0?\"-\":(t*=-1,\"+\"))+Lr(t/60|0,\"0\",2)+Lr(t%60,\"0\",2)}function xa(e,t){return Lr(e.getUTCDate(),t,2)}function ka(e,t){return Lr(e.getUTCHours(),t,2)}function Sa(e,t){return Lr(e.getUTCHours()%12||12,t,2)}function Ea(e,t){return Lr(1+Gn.count(gr(e),e),t,3)}function Ca(e,t){return Lr(e.getUTCMilliseconds(),t,3)}function Ta(e,t){return Ca(e,t)+\"000\"}function Ma(e,t){return Lr(e.getUTCMonth()+1,t,2)}function Na(e,t){return Lr(e.getUTCMinutes(),t,2)}function Pa(e,t){return Lr(e.getUTCSeconds(),t,2)}function za(e){var t=e.getUTCDay();return 0===t?7:t}function La(e,t){return Lr(or.count(gr(e)-1,e),t,2)}function Oa(e){var t=e.getUTCDay();return t>=4||0===t?cr(e):cr.ceil(e)}function Aa(e,t){return e=Oa(e),Lr(cr.count(gr(e),e)+(4===gr(e).getUTCDay()),t,2)}function Fa(e){return e.getUTCDay()}function Da(e,t){return Lr(ur.count(gr(e)-1,e),t,2)}function Ra(e,t){return Lr(e.getUTCFullYear()%100,t,2)}function ja(e,t){return Lr((e=Oa(e)).getUTCFullYear()%100,t,2)}function Ua(e,t){return Lr(e.getUTCFullYear()%1e4,t,4)}function Ia(e,t){var n=e.getUTCDay();return Lr((e=n>=4||0===n?cr(e):cr.ceil(e)).getUTCFullYear()%1e4,t,4)}function $a(){return\"+0000\"}function Ba(){return\"%\"}function Wa(e){return+e}function Va(e){return Math.floor(+e/1e3)}function Ha(e){return new Date(e)}function qa(e){return e instanceof Date?+e:+new Date(+e)}function Qa(e,t,n,r,a,i,o,u,l,s){var c=be(),f=c.invert,p=c.domain,d=s(\".%L\"),h=s(\":%S\"),v=s(\"%I:%M\"),g=s(\"%I %p\"),y=s(\"%a %d\"),m=s(\"%b %d\"),b=s(\"%B\"),_=s(\"%Y\");function w(e){return(l(e)<e?d:u(e)<e?h:o(e)<e?v:i(e)<e?g:r(e)<e?a(e)<e?y:m:n(e)<e?b:_)(e)}return c.invert=function(e){return new Date(f(e))},c.domain=function(e){return arguments.length?p(Array.from(e,qa)):p().map(Ha)},c.ticks=function(t){var n=p();return e(n[0],n[n.length-1],null==t?10:t)},c.tickFormat=function(e,t){return null==t?w:s(t)},c.nice=function(e){var n=p();return e&&\"function\"==typeof e.range||(e=t(n[0],n[n.length-1],null==e?10:e)),e?p(function(e,t){var n,r=0,a=(e=e.slice()).length-1,i=e[r],o=e[a];return o<i&&(n=r,r=a,a=n,n=i,i=o,o=n),e[r]=t.floor(i),e[a]=t.ceil(o),e}(n,e)):c},c.copy=function(){return me(c,Qa(e,t,n,r,a,i,o,u,l,s))},c}function Ya(){return _e.apply(Qa(_r,wr,vr,dr,Xn,Yn,qn,Vn,Wn,Cr).domain([new Date(2e3,0,1),new Date(2e3,0,2)]),arguments)}function Ga(e,t){var n=\"undefined\"!=typeof Symbol&&e[Symbol.iterator]||e[\"@@iterator\"];if(!n){if(Array.isArray(e)||(n=function(e,t){if(e){if(\"string\"==typeof e)return Ka(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return\"Object\"===n&&e.constructor&&(n=e.constructor.name),\"Map\"===n||\"Set\"===n?Array.from(e):\"Arguments\"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?Ka(e,t):void 0}}(e))||t&&e&&\"number\"==typeof e.length){n&&(e=n);var r=0,a=function(){};return{s:a,n:function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}},e:function(e){throw e},f:a}}throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\")}var i,o=!0,u=!1;return{s:function(){n=n.call(e)},n:function(){var e=n.next();return o=e.done,e},e:function(e){u=!0,i=e},f:function(){try{o||null==n.return||n.return()}finally{if(u)throw i}}}}function Ka(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}function Za(e){return Za=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Za(e)}function Xa(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Za(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Za(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Za(a)?a:String(a)),r)}var a}function Ja(e,t){return Ja=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},Ja(e,t)}function ei(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function ti(e){return ti=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},ti(e)}Er=function(e){var t=e.dateTime,n=e.date,r=e.time,a=e.periods,i=e.days,o=e.shortDays,u=e.months,l=e.shortMonths,s=Ar(a),c=Fr(a),f=Ar(i),p=Fr(i),d=Ar(o),h=Fr(o),v=Ar(u),g=Fr(u),y=Ar(l),m=Fr(l),b={a:function(e){return o[e.getDay()]},A:function(e){return i[e.getDay()]},b:function(e){return l[e.getMonth()]},B:function(e){return u[e.getMonth()]},c:null,d:na,e:na,f:ua,g:ma,G:_a,H:ra,I:aa,j:ia,L:oa,m:la,M:sa,p:function(e){return a[+(e.getHours()>=12)]},q:function(e){return 1+~~(e.getMonth()/3)},Q:Wa,s:Va,S:ca,u:fa,U:pa,V:ha,w:va,W:ga,x:null,X:null,y:ya,Y:ba,Z:wa,\"%\":Ba},_={a:function(e){return o[e.getUTCDay()]},A:function(e){return i[e.getUTCDay()]},b:function(e){return l[e.getUTCMonth()]},B:function(e){return u[e.getUTCMonth()]},c:null,d:xa,e:xa,f:Ta,g:ja,G:Ia,H:ka,I:Sa,j:Ea,L:Ca,m:Ma,M:Na,p:function(e){return a[+(e.getUTCHours()>=12)]},q:function(e){return 1+~~(e.getUTCMonth()/3)},Q:Wa,s:Va,S:Pa,u:za,U:La,V:Aa,w:Fa,W:Da,x:null,X:null,y:Ra,Y:Ua,Z:$a,\"%\":Ba},w={a:function(e,t,n){var r=d.exec(t.slice(n));return r?(e.w=h.get(r[0].toLowerCase()),n+r[0].length):-1},A:function(e,t,n){var r=f.exec(t.slice(n));return r?(e.w=p.get(r[0].toLowerCase()),n+r[0].length):-1},b:function(e,t,n){var r=y.exec(t.slice(n));return r?(e.m=m.get(r[0].toLowerCase()),n+r[0].length):-1},B:function(e,t,n){var r=v.exec(t.slice(n));return r?(e.m=g.get(r[0].toLowerCase()),n+r[0].length):-1},c:function(e,n,r){return S(e,t,n,r)},d:qr,e:qr,f:Xr,g:Br,G:$r,H:Yr,I:Yr,j:Qr,L:Zr,m:Hr,M:Gr,p:function(e,t,n){var r=s.exec(t.slice(n));return r?(e.p=c.get(r[0].toLowerCase()),n+r[0].length):-1},q:Vr,Q:ea,s:ta,S:Kr,u:Rr,U:jr,V:Ur,w:Dr,W:Ir,x:function(e,t,r){return S(e,n,t,r)},X:function(e,t,n){return S(e,r,t,n)},y:Br,Y:$r,Z:Wr,\"%\":Jr};function x(e,t){return function(n){var r,a,i,o=[],u=-1,l=0,s=e.length;for(n instanceof Date||(n=new Date(+n));++u<s;)37===e.charCodeAt(u)&&(o.push(e.slice(l,u)),null!=(a=Mr[r=e.charAt(++u)])?r=e.charAt(++u):a=\"e\"===r?\" \":\"0\",(i=t[r])&&(r=i(n,a)),o.push(r),l=u+1);return o.push(e.slice(l,u)),o.join(\"\")}}function k(e,t){return function(n){var r,a,i=Sr(1900,void 0,1);if(S(i,e,n+=\"\",0)!=n.length)return null;if(\"Q\"in i)return new Date(i.Q);if(\"s\"in i)return new Date(1e3*i.s+(\"L\"in i?i.L:0));if(t&&!(\"Z\"in i)&&(i.Z=0),\"p\"in i&&(i.H=i.H%12+12*i.p),void 0===i.m&&(i.m=\"q\"in i?i.q:0),\"V\"in i){if(i.V<1||i.V>53)return null;\"w\"in i||(i.w=1),\"Z\"in i?(a=(r=kr(Sr(i.y,0,1))).getUTCDay(),r=a>4||0===a?ur.ceil(r):ur(r),r=Gn.offset(r,7*(i.V-1)),i.y=r.getUTCFullYear(),i.m=r.getUTCMonth(),i.d=r.getUTCDate()+(i.w+6)%7):(a=(r=xr(Sr(i.y,0,1))).getDay(),r=a>4||0===a?Jn.ceil(r):Jn(r),r=Yn.offset(r,7*(i.V-1)),i.y=r.getFullYear(),i.m=r.getMonth(),i.d=r.getDate()+(i.w+6)%7)}else(\"W\"in i||\"U\"in i)&&(\"w\"in i||(i.w=\"u\"in i?i.u%7:\"W\"in i?1:0),a=\"Z\"in i?kr(Sr(i.y,0,1)).getUTCDay():xr(Sr(i.y,0,1)).getDay(),i.m=0,i.d=\"W\"in i?(i.w+6)%7+7*i.W-(a+5)%7:i.w+7*i.U-(a+6)%7);return\"Z\"in i?(i.H+=i.Z/100|0,i.M+=i.Z%100,kr(i)):xr(i)}}function S(e,t,n,r){for(var a,i,o=0,u=t.length,l=n.length;o<u;){if(r>=l)return-1;if(37===(a=t.charCodeAt(o++))){if(a=t.charAt(o++),!(i=w[a in Mr?t.charAt(o++):a])||(r=i(e,n,r))<0)return-1}else if(a!=n.charCodeAt(r++))return-1}return r}return b.x=x(n,b),b.X=x(r,b),b.c=x(t,b),_.x=x(n,_),_.X=x(r,_),_.c=x(t,_),{format:function(e){var t=x(e+=\"\",b);return t.toString=function(){return e},t},parse:function(e){var t=k(e+=\"\",!1);return t.toString=function(){return e},t},utcFormat:function(e){var t=x(e+=\"\",_);return t.toString=function(){return e},t},utcParse:function(e){var t=k(e+=\"\",!0);return t.toString=function(){return e},t}}}({dateTime:\"%x, %X\",date:\"%-m/%-d/%Y\",time:\"%-I:%M:%S %p\",periods:[\"AM\",\"PM\"],days:[\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"],shortDays:[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],months:[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],shortMonths:[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]}),Cr=Er.format,Tr=Er.parse,Er.utcFormat,Er.utcParse;var ni=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&Ja(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=ti(a);if(i){var n=ti(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Za(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return ei(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),e=o.call(this),window.lastAdditiveForceArrayVisualizer=ei(e),e.topOffset=28,e.leftOffset=80,e.height=350,e.effectFormat=ze(\".2\"),e.redraw=(0,Re.debounce)((function(){return e.draw()}),200),e}return n=u,(r=[{key:\"componentDidMount\",value:function(){var e=this;this.mainGroup=this.svg.append(\"g\"),this.onTopGroup=this.svg.append(\"g\"),this.xaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-xaxis\"),this.yaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-yaxis\"),this.hoverGroup1=this.svg.append(\"g\"),this.hoverGroup2=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.hoverLine=this.svg.append(\"line\"),this.hoverxOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hoverx=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.hoverxTitle=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"opacity\",.6).attr(\"font-size\",\"12px\"),this.hoveryOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hovery=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.xlabel=this.wrapper.select(\".additive-force-array-xlabel\"),this.ylabel=this.wrapper.select(\".additive-force-array-ylabel\");var t=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?t=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),t=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(t=this.props.plot_cmap),this.colors=t.map((function(e){return q(e)})),this.brighterColors=[1.45,1.6].map((function(t,n){return e.colors[n].brighter(t)}));var n=ze(\",.4\");null!=this.props.ordering_keys&&null!=this.props.ordering_keys_time_format?(this.parseTime=Tr(this.props.ordering_keys_time_format),this.formatTime=Cr(this.props.ordering_keys_time_format),this.xtickFormat=function(e){return\"object\"==Za(e)?this.formatTime(e):n(e)}):(this.parseTime=null,this.formatTime=null,this.xtickFormat=n),this.xscale=De(),this.xaxis=dn().scale(this.xscale).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.xtickFormat(t)})).tickPadding(-18),this.ytickFormat=n,this.yscale=De(),this.yaxis=pn(an,undefined).scale(this.yscale).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.ytickFormat(e.invLinkFunction(t))})).tickPadding(2),this.xlabel.node().onchange=function(){return e.internalDraw()},this.ylabel.node().onchange=function(){return e.internalDraw()},this.svg.on(\"mousemove\",(function(t){return e.mouseMoved(t)})),this.svg.on(\"click\",(function(){return alert(\"This original index of the sample you clicked is \"+e.nearestExpIndex)})),this.svg.on(\"mouseout\",(function(t){return e.mouseOut(t)})),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"mouseOut\",value:function(){this.hoverLine.attr(\"display\",\"none\"),this.hoverx.attr(\"display\",\"none\"),this.hoverxOutline.attr(\"display\",\"none\"),this.hoverxTitle.attr(\"display\",\"none\"),this.hovery.attr(\"display\",\"none\"),this.hoveryOutline.attr(\"display\",\"none\"),this.hoverGroup1.attr(\"display\",\"none\"),this.hoverGroup2.attr(\"display\",\"none\")}},{key:\"mouseMoved\",value:function(e){var t,n,r=this;this.hoverLine.attr(\"display\",\"\"),this.hoverx.attr(\"display\",\"\"),this.hoverxOutline.attr(\"display\",\"\"),this.hoverxTitle.attr(\"display\",\"\"),this.hovery.attr(\"display\",\"\"),this.hoveryOutline.attr(\"display\",\"\"),this.hoverGroup1.attr(\"display\",\"\"),this.hoverGroup2.attr(\"display\",\"\");var a=function(e,t){if(e=function(e){let t;for(;t=e.sourceEvent;)e=t;return e}(e),void 0===t&&(t=e.currentTarget),t){var n=t.ownerSVGElement||t;if(n.createSVGPoint){var r=n.createSVGPoint();return r.x=e.clientX,r.y=e.clientY,[(r=r.matrixTransform(t.getScreenCTM().inverse())).x,r.y]}if(t.getBoundingClientRect){var a=t.getBoundingClientRect();return[e.clientX-a.left-t.clientLeft,e.clientY-a.top-t.clientTop]}}return[e.pageX,e.pageY]}(e,this.svg.node())[0];if(this.props.explanations){for(t=0;t<this.currExplanations.length;++t)(!n||Math.abs(n.xmapScaled-a)>Math.abs(this.currExplanations[t].xmapScaled-a))&&(n=this.currExplanations[t]);this.nearestExpIndex=n.origInd,this.hoverLine.attr(\"x1\",n.xmapScaled).attr(\"x2\",n.xmapScaled).attr(\"y1\",0+this.topOffset).attr(\"y2\",this.height),this.hoverx.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxOutline.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxTitle.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-18).text(n.count>1?n.count+\" averaged samples\":\"\"),this.hovery.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint))),this.hoveryOutline.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint)));for(var i,o,u=[],l=this.currPosOrderedFeatures.length-1;l>=0;--l){var s=this.currPosOrderedFeatures[l],c=n.features[s];o=5+(c.posyTop+c.posyBottom)/2,(!i||o-i>=15)&&c.posyTop-c.posyBottom>=6&&(u.push(c),i=o)}var f=[];i=void 0;var p,d=Ga(this.currNegOrderedFeatures);try{for(d.s();!(p=d.n()).done;){var h=p.value,v=n.features[h];o=5+(v.negyTop+v.negyBottom)/2,(!i||i-o>=15)&&v.negyTop-v.negyBottom>=6&&(f.push(v),i=o)}}catch(e){d.e(e)}finally{d.f()}var g=function(e){var t=\"\";return null!==e.value&&void 0!==e.value&&(t=\" = \"+(isNaN(e.value)?e.value:r.ytickFormat(e.value))),n.count>1?\"mean(\"+r.props.featureNames[e.ind]+\")\"+t:r.props.featureNames[e.ind]+t},y=this.hoverGroup1.selectAll(\".pos-values\").data(u);y.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(y).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.posyTop+e.posyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(g),y.exit().remove();var m=this.hoverGroup2.selectAll(\".pos-values\").data(u);m.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(m).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.posyTop+e.posyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[0]).text(g),m.exit().remove();var b=this.hoverGroup1.selectAll(\".neg-values\").data(f);b.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(b).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.negyTop+e.negyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(g),b.exit().remove();var _=this.hoverGroup2.selectAll(\".neg-values\").data(f);_.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(_).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.negyTop+e.negyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[1]).text(g),_.exit().remove()}}},{key:\"draw\",value:function(){var e=this;if(this.props.explanations&&0!==this.props.explanations.length){(0,Re.each)(this.props.explanations,(function(e,t){return e.origInd=t}));var t,n={},r={},a={},i=Ga(this.props.explanations);try{for(i.s();!(t=i.n()).done;){var o=t.value;for(var u in o.features)void 0===n[u]&&(n[u]=0,r[u]=0,a[u]=0),o.features[u].effect>0?n[u]+=o.features[u].effect:r[u]-=o.features[u].effect,null!==o.features[u].value&&void 0!==o.features[u].value&&(a[u]+=1)}}catch(e){i.e(e)}finally{i.f()}this.usedFeatures=(0,Re.sortBy)((0,Re.keys)(n),(function(e){return-(n[e]+r[e])})),console.log(\"found \",this.usedFeatures.length,\" used features\"),this.posOrderedFeatures=(0,Re.sortBy)(this.usedFeatures,(function(e){return n[e]})),this.negOrderedFeatures=(0,Re.sortBy)(this.usedFeatures,(function(e){return-r[e]})),this.singleValueFeatures=(0,Re.filter)(this.usedFeatures,(function(e){return a[e]>0}));var l=[\"sample order by similarity\",\"sample order by output value\",\"original sample ordering\"].concat(this.singleValueFeatures.map((function(t){return e.props.featureNames[t]})));null!=this.props.ordering_keys&&l.unshift(\"sample order by key\");var s=this.xlabel.selectAll(\"option\").data(l);s.enter().append(\"option\").merge(s).attr(\"value\",(function(e){return e})).text((function(e){return e})),s.exit().remove();var c=this.props.outNames[0]?this.props.outNames[0]:\"model output value\";(l=(0,Re.map)(this.usedFeatures,(function(t){return[e.props.featureNames[t],e.props.featureNames[t]+\" effects\"]}))).unshift([\"model output value\",c]);var f=this.ylabel.selectAll(\"option\").data(l);f.enter().append(\"option\").merge(f).attr(\"value\",(function(e){return e[0]})).text((function(e){return e[1]})),f.exit().remove(),this.ylabel.style(\"top\",(this.height-10-this.topOffset)/2+this.topOffset+\"px\").style(\"left\",10-this.ylabel.node().offsetWidth/2+\"px\"),this.internalDraw()}}},{key:\"internalDraw\",value:function(){var e,t,n=this,r=Ga(this.props.explanations);try{for(r.s();!(e=r.n()).done;){var a,i=e.value,o=Ga(this.usedFeatures);try{for(o.s();!(a=o.n()).done;){var u=a.value;i.features.hasOwnProperty(u)||(i.features[u]={effect:0,value:0}),i.features[u].ind=u}}catch(e){o.e(e)}finally{o.f()}}}catch(e){r.e(e)}finally{r.f()}var l=this.xlabel.node().value,s=\"sample order by key\"===l&&null!=this.props.ordering_keys_time_format;if(this.xscale=s?Ya():De(),this.xaxis.scale(this.xscale),\"sample order by similarity\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return e.simIndex})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"sample order by output value\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return-e.outValue})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"original sample ordering\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return e.origInd})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"sample order by key\"===l)t=this.props.explanations,s?(0,Re.each)(t,(function(e,t){return e.xmap=n.parseTime(n.props.ordering_keys[t])})):(0,Re.each)(t,(function(e,t){return e.xmap=n.props.ordering_keys[t]})),t=(0,Re.sortBy)(t,(function(e){return e.xmap}));else{var c=(0,Re.findKey)(this.props.featureNames,(function(e){return e===l}));(0,Re.each)(this.props.explanations,(function(e,t){return e.xmap=e.features[c].value}));var f=(0,Re.sortBy)(this.props.explanations,(function(e){return e.xmap})),p=(0,Re.map)(f,(function(e){return e.xmap}));if(\"string\"==typeof p[0])return void alert(\"Ordering by category names is not yet supported.\");var d,h,v=(0,Re.min)(p),g=((0,Re.max)(p)-v)/100;t=[];for(var y=0;y<f.length;++y){var m=f[y];if(d&&!h&&m.xmap-d.xmap<=g||h&&m.xmap-h.xmap<=g){h||((h=(0,Re.cloneDeep)(d)).count=1);var b,_=Ga(this.usedFeatures);try{for(_.s();!(b=_.n()).done;){var w=b.value;h.features[w].effect+=m.features[w].effect,h.features[w].value+=m.features[w].value}}catch(e){_.e(e)}finally{_.f()}h.count+=1}else if(d)if(h){var x,k=Ga(this.usedFeatures);try{for(k.s();!(x=k.n()).done;){var S=x.value;h.features[S].effect/=h.count,h.features[S].value/=h.count}}catch(e){k.e(e)}finally{k.f()}t.push(h),h=void 0}else t.push(d);d=m}d.xmap-t[t.length-1].xmap>g&&t.push(d)}this.currUsedFeatures=this.usedFeatures,this.currPosOrderedFeatures=this.posOrderedFeatures,this.currNegOrderedFeatures=this.negOrderedFeatures;var E=this.ylabel.node().value;if(\"model output value\"!==E){var C=t;t=(0,Re.cloneDeep)(t);for(var T=(0,Re.findKey)(this.props.featureNames,(function(e){return e===E})),M=0;M<t.length;++M){var N=t[M].features[T];t[M].features={},t[M].features[T]=N,C[M].remapped_version=t[M]}this.currUsedFeatures=[T],this.currPosOrderedFeatures=[T],this.currNegOrderedFeatures=[T]}this.currExplanations=t,\"identity\"===this.props.link?this.invLinkFunction=function(e){return n.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(n.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link),this.predValues=(0,Re.map)(t,(function(e){return(0,Re.sum)((0,Re.map)(e.features,(function(e){return e.effect})))}));var P=this.wrapper.node().offsetWidth;if(0==P)return setTimeout((function(){return n.draw(t)}),500);this.svg.style(\"height\",this.height+\"px\"),this.svg.style(\"width\",P+\"px\");var z=(0,Re.map)(t,(function(e){return e.xmap}));this.xscale.domain([(0,Re.min)(z),(0,Re.max)(z)]).range([this.leftOffset,P]).clamp(!0),this.xaxisElement.attr(\"transform\",\"translate(0,\"+this.topOffset+\")\").call(this.xaxis);for(var L=0;L<this.currExplanations.length;++L)this.currExplanations[L].xmapScaled=this.xscale(this.currExplanations[L].xmap);for(var O=t.length,A=0,F=0;F<O;++F){var D=t[F].features,R=(0,Re.sum)((0,Re.map)((0,Re.filter)(D,(function(e){return e.effect>0})),(function(e){return e.effect})))||0,j=(0,Re.sum)((0,Re.map)((0,Re.filter)(D,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0;A=Math.max(A,2.2*Math.max(R,j))}this.yscale.domain([-A/2,A/2]).range([this.height-10,this.topOffset]),this.yaxisElement.attr(\"transform\",\"translate(\"+this.leftOffset+\",0)\").call(this.yaxis);for(var U=0;U<O;++U){var I,$=t[U].features,B=-((0,Re.sum)((0,Re.map)((0,Re.filter)($,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0),W=void 0,V=Ga(this.currPosOrderedFeatures);try{for(V.s();!(I=V.n()).done;)$[W=I.value].posyTop=this.yscale(B),$[W].effect>0&&(B+=$[W].effect),$[W].posyBottom=this.yscale(B),$[W].ind=W}catch(e){V.e(e)}finally{V.f()}var H,q=B,Q=Ga(this.currNegOrderedFeatures);try{for(Q.s();!(H=Q.n()).done;)$[W=H.value].negyTop=this.yscale(B),$[W].effect<0&&(B-=$[W].effect),$[W].negyBottom=this.yscale(B)}catch(e){Q.e(e)}finally{Q.f()}t[U].joinPoint=q,t[U].joinPointy=this.yscale(q)}var Y=En().x((function(e){return e[0]})).y((function(e){return e[1]})),G=this.mainGroup.selectAll(\".force-bar-array-area-pos\").data(this.currUsedFeatures);G.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-pos\").merge(G).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyTop]})),r=(0,Re.map)((0,Re.rangeRight)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyBottom]}));return Y(n.concat(r))})).attr(\"fill\",this.colors[0]),G.exit().remove();var K=this.mainGroup.selectAll(\".force-bar-array-area-neg\").data(this.currUsedFeatures);K.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-neg\").merge(K).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyTop]})),r=(0,Re.map)((0,Re.rangeRight)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyBottom]}));return Y(n.concat(r))})).attr(\"fill\",this.colors[1]),K.exit().remove();var Z=this.mainGroup.selectAll(\".force-bar-array-divider-pos\").data(this.currUsedFeatures);Z.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-pos\").merge(Z).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyBottom]}));return Y(n)})).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",(function(){return n.colors[0].brighter(1.2)})),Z.exit().remove();var X=this.mainGroup.selectAll(\".force-bar-array-divider-neg\").data(this.currUsedFeatures);X.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-neg\").merge(X).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyTop]}));return Y(n)})).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",(function(){return n.colors[1].brighter(1.5)})),X.exit().remove();for(var J=function(e,t,n,r,a){var i,o,u,l;\"pos\"===a?(i=e[n].features[t].posyBottom,o=e[n].features[t].posyTop):(i=e[n].features[t].negyBottom,o=e[n].features[t].negyTop);for(var s=n+1;s<=r;++s)\"pos\"===a?(u=e[s].features[t].posyBottom,l=e[s].features[t].posyTop):(u=e[s].features[t].negyBottom,l=e[s].features[t].negyTop),u>i&&(i=u),l<o&&(o=l);return{top:i,bottom:o}},ee=[],te=0,ne=[\"pos\",\"neg\"];te<ne.length;te++){var re,ae=ne[te],ie=Ga(this.currUsedFeatures);try{for(ie.s();!(re=ie.n()).done;)for(var oe=re.value,ue=0,le=0,se=0,ce={top:0,bottom:0},fe=void 0;le<O-1;){for(;se<100&&le<O-1;)++le,se=t[le].xmapScaled-t[ue].xmapScaled;for(ce=J(t,oe,ue,le,ae);ce.bottom-ce.top<20&&ue<le;)++ue,ce=J(t,oe,ue,le,ae);if(se=t[le].xmapScaled-t[ue].xmapScaled,ce.bottom-ce.top>=20&&se>=100){for(;le<O-1;){if(++le,!((fe=J(t,oe,ue,le,ae)).bottom-fe.top>20)){--le;break}ce=fe}se=t[le].xmapScaled-t[ue].xmapScaled,ee.push([(t[le].xmapScaled+t[ue].xmapScaled)/2,(ce.top+ce.bottom)/2,this.props.featureNames[oe]]);var pe=t[le].xmapScaled;for(ue=le;pe+100>t[ue].xmapScaled&&ue<O-1;)++ue;le=ue}}}catch(e){ie.e(e)}finally{ie.f()}}var de=this.onTopGroup.selectAll(\".force-bar-array-flabels\").data(ee);de.enter().append(\"text\").attr(\"class\",\"force-bar-array-flabels\").merge(de).attr(\"x\",(function(e){return e[0]})).attr(\"y\",(function(e){return e[1]+4})).text((function(e){return e[2]})),de.exit().remove()}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return e.createElement(\"div\",{ref:function(e){return t.wrapper=Jt(e)},style:{textAlign:\"center\"}},e.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-array-wrapper {\\n            text-align: center;\\n          }\\n          .force-bar-array-xaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-xaxis .domain {\\n            opacity: 0;\\n          }\\n          .force-bar-array-xaxis paths {\\n            display: none;\\n          }\\n          .force-bar-array-yaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-yaxis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\\n          .force-bar-array-flabels {\\n            font-size: 12px;\\n            fill: #fff;\\n            text-anchor: middle;\\n          }\\n          .additive-force-array-xlabel {\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            margin-left: 80px;\\n            max-width: 300px;\\n          }\\n          .additive-force-array-xlabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-ylabel {\\n            position: relative;\\n            top: 0px;\\n            left: 0px;\\n            transform: rotate(-90deg);\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            max-width: 150px;\\n          }\\n          .additive-force-array-ylabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-hoverLine {\\n            stroke-width: 1px;\\n            stroke: #fff;\\n            opacity: 1;\\n          }\"}}),e.createElement(\"select\",{className:\"additive-force-array-xlabel\"}),e.createElement(\"div\",{style:{height:\"0px\",textAlign:\"left\"}},e.createElement(\"select\",{className:\"additive-force-array-ylabel\"})),e.createElement(\"svg\",{ref:function(e){return t.svg=Jt(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}}))}}])&&Xa(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);ni.defaultProps={plot_cmap:\"RdBu\",ordering_keys:null,ordering_keys_time_format:null};const ri=ni;window.SHAP={SimpleListVisualizer:He,AdditiveForceVisualizer:Ln,AdditiveForceArrayVisualizer:ri,React:e,ReactDom:t}})()})();\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1c74f",
   "metadata": {},
   "source": [
    "En primer lugar calculamos los Shap Valus y el Explainer. \n",
    "Los SHAP values nos permitirán entender cómo cada variable contribuye a la salida del modelo. \n",
    "El explainer encapsula el modelo entrenado y los datos para calcular los SHAP values de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef9d09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n"
     ]
    }
   ],
   "source": [
    "# Calcular SHAP values y el explainer\n",
    "explainer = shap.TreeExplainer(best_lgbm_model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be71635",
   "metadata": {},
   "source": [
    "#### Bloque 1: Visualizar el gráfico de explicación de SHAP para la primera predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af689704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='iD79QZS4WM71H6EC4212I'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 2.911426181818031, \"outValue\": 2.4614496727842656, \"link\": \"identity\", \"featureNames\": [\"phone_home_valid\", \"email_is_free\", \"device_os_2\", \"credit_risk_score\", \"device_distinct_emails_8w\", \"source_1\", \"proposed_credit_limit\", \"employment_status\", \"device_os_3\", \"source_2\", \"has_other_cards\", \"housing_status\", \"zip_count_4w\", \"customer_age\", \"foreign_request\", \"device_os_1\", \"name_email_similarity\", \"income\", \"phone_mobile_valid\", \"keep_alive_session\", \"income.1\", \"name_email_similarity.1\", \"days_since_request\", \"intended_balcon_amount\", \"date_of_birth_distinct_emails_4w\", \"housing_status.1\", \"current_address_months_count\", \"customer_age.1\", \"velocity_6h\", \"velocity_24h\", \"velocity_4w\", \"bank_branch_count_8w\", \"credit_risk_score.1\", \"bank_months_count\", \"proposed_credit_limit.1\", \"session_length_in_minutes\", \"zip_count_4w.1\", \"device_os_4\", \"device_os_5\", \"Quarter\"], \"features\": {\"0\": {\"effect\": -0.3569002894103158, \"value\": 0.0}, \"1\": {\"effect\": -0.1988898159553177, \"value\": 1.0}, \"2\": {\"effect\": -0.02411027750982173, \"value\": 0.0}, \"3\": {\"effect\": -0.015888204296201566, \"value\": 0.4593798568033352}, \"4\": {\"effect\": 0.037351571969304595, \"value\": 1.0}, \"5\": {\"effect\": 0.00017560385930356752, \"value\": 1.0}, \"6\": {\"effect\": -0.019148722231639777, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.0904946169598367, \"value\": 1.0}, \"8\": {\"effect\": -0.051742556780058506, \"value\": 0.0}, \"10\": {\"effect\": -0.2079419908617526, \"value\": 0.0}, \"11\": {\"effect\": 0.20207389022131814, \"value\": 3.0}, \"12\": {\"effect\": 0.06175710024160503, \"value\": -0.4075021073002325}, \"13\": {\"effect\": 0.05983846584536524, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.013948270307616537, \"value\": 0.0}, \"15\": {\"effect\": -0.6514728000118465, \"value\": 1.0}, \"16\": {\"effect\": 0.1595123134211457, \"value\": 0.6856554268961795}, \"17\": {\"effect\": -0.3668528338095677, \"value\": 0.9}, \"18\": {\"effect\": 0.010207842795258255, \"value\": 1.0}, \"19\": {\"effect\": 0.29862232093018776, \"value\": 1.0}, \"20\": {\"effect\": -0.059864916973400614, \"value\": 0.9}, \"21\": {\"effect\": 0.008421583785010832, \"value\": 0.6856554268961795}, \"22\": {\"effect\": -0.12668167663911156, \"value\": 0.0016699051740797}, \"23\": {\"effect\": -0.21990471097542108, \"value\": -1.2430695783155217}, \"24\": {\"effect\": 0.11038413436813432, \"value\": 16.0}, \"25\": {\"effect\": 0.018086960560872625, \"value\": 3.0}, \"26\": {\"effect\": 0.9245844282781993, \"value\": -0.9002484837181745}, \"27\": {\"effect\": -0.00010887642988905681, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.006819795358134701, \"value\": -0.1354705137441912}, \"29\": {\"effect\": -0.1310632721945033, \"value\": 0.9399965621820896}, \"30\": {\"effect\": -0.02090669768074955, \"value\": 1.2427886833583188}, \"31\": {\"effect\": 0.06786691405192981, \"value\": 2.6165632666334875}, \"32\": {\"effect\": 0.019265859499524973, \"value\": 0.4593798568033352}, \"33\": {\"effect\": -0.01156588538471751, \"value\": 1.6638537467837806}, \"34\": {\"effect\": 0.006095512149154542, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09696566577550766, \"value\": 1.1419672816197566}, \"36\": {\"effect\": -0.004419913149653025, \"value\": -0.4075021073002325}, \"37\": {\"effect\": 0.010703201929908252, \"value\": 0.0}, \"38\": {\"effect\": 0.004467692430012495, \"value\": 0.0}, \"39\": {\"effect\": 0.004472011158814293, \"value\": 1.0}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('iD79QZS4WM71H6EC4212I')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceVisualizer at 0x2c11ea4bf10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], X_test.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2d8ab",
   "metadata": {},
   "source": [
    "El gráfico anterior nos proporciona una descomposición visual de cómo cada característica específica contribuye a la predicción del modelo para la primera instancia del dataframe. Observamos la dirección y magnitud de la contribución de cada característica para entender mejor cómo el modelo está tomando decisiones para esa observación en particular. \n",
    "\n",
    "En rojo podemos destacar que:\n",
    "- Housing_status: Tiene un impacto positivo en la predicción. Un valor de 3 en esta característica aumenta la predicción del modelo.\n",
    "- keep_alive_session: Su valor de 1 contribuye positivamente a la predicción.\n",
    "- Current_address_months_count: Su valor de -0.9002 tiene un impacto negativo en la predicción. A medida que este valor aumenta, la predicción tiende a disminuir.\n",
    "\n",
    "En el centro  de nuestro gráfico, el valor en negrita, 2.46, representa la predicción base del modelo antes de considerar las características específicas. La suma de las contribuciones de todas las características más este valor debería dar la predicción final del modelo para esta instancia.\n",
    "\n",
    "Por otro lado, a partir de los datos reflejados en azul concluimos que:\n",
    "- device_os_1: Un valor de 1 contribuye positivamente a la predicción.\n",
    "- income: Su valor de 0.9 tiene un impacto positivo en la predicción.\n",
    "- phone_home_valid: Un valor de 0 contribuye negativamente a la predicción.\n",
    "- intended_balcom_amount: Su valor de -1.243 tiene un impacto negativo en la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47de87",
   "metadata": {},
   "source": [
    "#### Bloque 2: Visualizar SHAP force plot para una muestra de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d131ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='iDAYXZN6MMII9BVP2IFR5'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceArrayVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 2.911426181818031, \"link\": \"identity\", \"featureNames\": [\"phone_home_valid\", \"email_is_free\", \"device_os_2\", \"credit_risk_score\", \"device_distinct_emails_8w\", \"source_1\", \"proposed_credit_limit\", \"employment_status\", \"device_os_3\", \"source_2\", \"has_other_cards\", \"housing_status\", \"zip_count_4w\", \"customer_age\", \"foreign_request\", \"device_os_1\", \"name_email_similarity\", \"income\", \"phone_mobile_valid\", \"keep_alive_session\", \"income.1\", \"name_email_similarity.1\", \"days_since_request\", \"intended_balcon_amount\", \"date_of_birth_distinct_emails_4w\", \"housing_status.1\", \"current_address_months_count\", \"customer_age.1\", \"velocity_6h\", \"velocity_24h\", \"velocity_4w\", \"bank_branch_count_8w\", \"credit_risk_score.1\", \"bank_months_count\", \"proposed_credit_limit.1\", \"session_length_in_minutes\", \"zip_count_4w.1\", \"device_os_4\", \"device_os_5\", \"Quarter\"], \"explanations\": [{\"outValue\": 2.4614496727842656, \"simIndex\": 55.0, \"features\": {\"0\": {\"effect\": -0.3569002894103158, \"value\": 0.0}, \"1\": {\"effect\": -0.1988898159553177, \"value\": 1.0}, \"2\": {\"effect\": -0.02411027750982173, \"value\": 0.0}, \"3\": {\"effect\": -0.015888204296201566, \"value\": 0.4593798568033352}, \"4\": {\"effect\": 0.037351571969304595, \"value\": 1.0}, \"5\": {\"effect\": 0.00017560385930356752, \"value\": 1.0}, \"6\": {\"effect\": -0.019148722231639777, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.0904946169598367, \"value\": 1.0}, \"8\": {\"effect\": -0.051742556780058506, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2079419908617526, \"value\": 0.0}, \"11\": {\"effect\": 0.20207389022131814, \"value\": 3.0}, \"12\": {\"effect\": 0.06175710024160503, \"value\": -0.4075021073002325}, \"13\": {\"effect\": 0.05983846584536524, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.013948270307616537, \"value\": 0.0}, \"15\": {\"effect\": -0.6514728000118465, \"value\": 1.0}, \"16\": {\"effect\": 0.1595123134211457, \"value\": 0.6856554268961795}, \"17\": {\"effect\": -0.3668528338095677, \"value\": 0.9}, \"18\": {\"effect\": 0.010207842795258255, \"value\": 1.0}, \"19\": {\"effect\": 0.29862232093018776, \"value\": 1.0}, \"20\": {\"effect\": -0.059864916973400614, \"value\": 0.9}, \"21\": {\"effect\": 0.008421583785010832, \"value\": 0.6856554268961795}, \"22\": {\"effect\": -0.12668167663911156, \"value\": 0.0016699051740797}, \"23\": {\"effect\": -0.21990471097542108, \"value\": -1.2430695783155217}, \"24\": {\"effect\": 0.11038413436813432, \"value\": 16.0}, \"25\": {\"effect\": 0.018086960560872625, \"value\": 3.0}, \"26\": {\"effect\": 0.9245844282781993, \"value\": -0.9002484837181745}, \"27\": {\"effect\": -0.00010887642988905681, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.006819795358134701, \"value\": -0.1354705137441912}, \"29\": {\"effect\": -0.1310632721945033, \"value\": 0.9399965621820896}, \"30\": {\"effect\": -0.02090669768074955, \"value\": 1.2427886833583188}, \"31\": {\"effect\": 0.06786691405192981, \"value\": 2.6165632666334875}, \"32\": {\"effect\": 0.019265859499524973, \"value\": 0.4593798568033352}, \"33\": {\"effect\": -0.01156588538471751, \"value\": 1.6638537467837806}, \"34\": {\"effect\": 0.006095512149154542, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09696566577550766, \"value\": 1.1419672816197566}, \"36\": {\"effect\": -0.004419913149653025, \"value\": -0.4075021073002325}, \"37\": {\"effect\": 0.010703201929908252, \"value\": 0.0}, \"38\": {\"effect\": 0.004467692430012495, \"value\": 0.0}, \"39\": {\"effect\": 0.004472011158814293, \"value\": 1.0}}}, {\"outValue\": 5.703705968065007, \"simIndex\": 98.0, \"features\": {\"0\": {\"effect\": 0.46822228019576884, \"value\": 1.0}, \"1\": {\"effect\": 0.2855638139053565, \"value\": 0.0}, \"2\": {\"effect\": 0.006916706938778356, \"value\": 0.0}, \"3\": {\"effect\": 0.14562152197423212, \"value\": -0.4734321676686074}, \"4\": {\"effect\": 0.03988208307188845, \"value\": 1.0}, \"5\": {\"effect\": 0.0010612660715510352, \"value\": 1.0}, \"6\": {\"effect\": 0.0643324698443437, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.18961657667864076, \"value\": 2.0}, \"8\": {\"effect\": -0.06000488651304961, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8658954244420642, \"value\": 1.0}, \"11\": {\"effect\": 0.4394729352671675, \"value\": 5.0}, \"12\": {\"effect\": -0.10098475422560868, \"value\": 1.110340909809809}, \"13\": {\"effect\": 0.039078197832656696, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.009744012347136488, \"value\": 0.0}, \"15\": {\"effect\": -0.6158550803682298, \"value\": 1.0}, \"16\": {\"effect\": 0.20630212855587018, \"value\": 0.5864158853783172}, \"17\": {\"effect\": -0.04801045002398836, \"value\": 0.8}, \"18\": {\"effect\": 0.03026907511194035, \"value\": 1.0}, \"19\": {\"effect\": -0.24090515107204427, \"value\": 0.0}, \"20\": {\"effect\": -0.01648919007514802, \"value\": 0.8}, \"21\": {\"effect\": 0.03443748795687635, \"value\": 0.5864158853783172}, \"22\": {\"effect\": 0.10254596756697844, \"value\": 0.0203682750751534}, \"23\": {\"effect\": 0.20577112495149677, \"value\": 32.65823955805774}, \"24\": {\"effect\": 0.015550747522630155, \"value\": 9.0}, \"25\": {\"effect\": 0.048858431704291085, \"value\": 5.0}, \"26\": {\"effect\": -0.5226126613408222, \"value\": -0.1763202628756286}, \"27\": {\"effect\": -0.0011424912668940785, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.029621795407470695, \"value\": -0.4741080800747136}, \"29\": {\"effect\": 0.086998325855337, \"value\": -1.2107590942183302}, \"30\": {\"effect\": 0.24816347524589297, \"value\": -0.6056502353071074}, \"31\": {\"effect\": 0.35388095733220715, \"value\": 3.034295023085665}, \"32\": {\"effect\": 0.03773489125045291, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.23548674082219534, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.000448731682551446, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.10014723773552445, \"value\": 0.9733763053573278}, \"36\": {\"effect\": -0.03639519445956819, \"value\": 1.110340909809809}, \"37\": {\"effect\": 0.01235303111515044, \"value\": 0.0}, \"38\": {\"effect\": 0.0020259578873056978, \"value\": 0.0}, \"39\": {\"effect\": 0.12867624931857305, \"value\": 2.0}}}, {\"outValue\": 2.608532056692479, \"simIndex\": 57.0, \"features\": {\"0\": {\"effect\": -0.29558070949012344, \"value\": 0.0}, \"1\": {\"effect\": -0.24565589374238458, \"value\": 1.0}, \"2\": {\"effect\": -0.040079419441306226, \"value\": 0.0}, \"3\": {\"effect\": 0.0973044819735732, \"value\": -1.0187684281291278}, \"4\": {\"effect\": 0.03335933408843274, \"value\": 1.0}, \"5\": {\"effect\": 0.0005170334164689629, \"value\": 1.0}, \"6\": {\"effect\": 0.052873351180062825, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.16241239506025865, \"value\": 1.0}, \"8\": {\"effect\": -0.05756798587091812, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.19191222491108204, \"value\": 0.0}, \"11\": {\"effect\": 0.2228759778485922, \"value\": 3.0}, \"12\": {\"effect\": -0.026376963750249994, \"value\": -0.0633515935911406}, \"13\": {\"effect\": 0.1755176598496369, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.006850666581896223, \"value\": 0.0}, \"15\": {\"effect\": -0.7867844138169144, \"value\": 1.0}, \"16\": {\"effect\": 0.18733492947271596, \"value\": 0.6939282538872338}, \"17\": {\"effect\": -0.4885751595485921, \"value\": 0.9}, \"18\": {\"effect\": -0.10805308205669101, \"value\": 0.0}, \"19\": {\"effect\": 0.2695286456145467, \"value\": 1.0}, \"20\": {\"effect\": -0.05884141492141856, \"value\": 0.9}, \"21\": {\"effect\": 0.02047277450482665, \"value\": 0.6939282538872338}, \"22\": {\"effect\": -0.0040067106628910954, \"value\": 0.0160169916138557}, \"23\": {\"effect\": -0.093052058789714, \"value\": -0.7146321080917919}, \"24\": {\"effect\": 0.06995302552546694, \"value\": 12.0}, \"25\": {\"effect\": 0.02688650242624238, \"value\": 3.0}, \"26\": {\"effect\": 0.9928728218469038, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.020617930512192312, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.012630346389729168, \"value\": -0.6238535729053909}, \"29\": {\"effect\": 0.06237133370496652, \"value\": -1.018649548123965}, \"30\": {\"effect\": 0.10463648852815609, \"value\": 0.0033769572989511}, \"31\": {\"effect\": -0.26302126074165366, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.022329689643742403, \"value\": -1.0187684281291278}, \"33\": {\"effect\": -0.09643489577666653, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.009219371990927627, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.024601045088280923, \"value\": -0.7568770886196635}, \"36\": {\"effect\": -0.001652296805140532, \"value\": -0.0633515935911406}, \"37\": {\"effect\": 0.019321646777389453, \"value\": 0.0}, \"38\": {\"effect\": 0.0018652719341989807, \"value\": 0.0}, \"39\": {\"effect\": 0.1831724313615045, \"value\": 2.0}}}, {\"outValue\": 3.113947424933395, \"simIndex\": 4.0, \"features\": {\"0\": {\"effect\": 0.5783771474044775, \"value\": 1.0}, \"1\": {\"effect\": 0.24686402696293325, \"value\": 0.0}, \"2\": {\"effect\": -0.015285642784452729, \"value\": 0.0}, \"3\": {\"effect\": 0.022948419670802373, \"value\": -0.5882398014497696}, \"4\": {\"effect\": 0.029045774791932585, \"value\": 1.0}, \"5\": {\"effect\": 0.0005319471057835613, \"value\": 1.0}, \"6\": {\"effect\": 0.022376331247919923, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.0971721525633602, \"value\": 1.0}, \"8\": {\"effect\": 0.17235007601423252, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22763842553825497, \"value\": 0.0}, \"11\": {\"effect\": -0.8710748104572912, \"value\": 1.0}, \"12\": {\"effect\": -0.13231207640365558, \"value\": 0.0778893686825329}, \"13\": {\"effect\": -0.138746517116908, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.009310868309053259, \"value\": 0.0}, \"15\": {\"effect\": 0.4107677152921964, \"value\": 0.0}, \"16\": {\"effect\": -0.6448889648254753, \"value\": 0.0495588250970678}, \"17\": {\"effect\": -0.04844884632611848, \"value\": 0.8}, \"18\": {\"effect\": -0.12856641753512743, \"value\": 0.0}, \"19\": {\"effect\": 0.16732237487949422, \"value\": 1.0}, \"20\": {\"effect\": -0.025231017684688908, \"value\": 0.8}, \"21\": {\"effect\": -0.09085286080235777, \"value\": 0.0495588250970678}, \"22\": {\"effect\": 0.14002651034990263, \"value\": 0.0250427132599829}, \"23\": {\"effect\": 0.46936292514848926, \"value\": 37.515167939581296}, \"24\": {\"effect\": 0.07558851505779464, \"value\": 6.0}, \"25\": {\"effect\": -0.06461145405777415, \"value\": 1.0}, \"26\": {\"effect\": -0.340125548910676, \"value\": -0.4591047241422481}, \"27\": {\"effect\": 0.001803734680172897, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.07316206273960367, \"value\": 0.9762451094717016}, \"29\": {\"effect\": -0.11371933311194289, \"value\": 0.5782812646074298}, \"30\": {\"effect\": 0.17930610523927965, \"value\": 0.2413228424050724}, \"31\": {\"effect\": 0.3524765005098725, \"value\": 1.0130825140019502}, \"32\": {\"effect\": 0.01572219381573776, \"value\": -0.5882398014497696}, \"33\": {\"effect\": 0.14462723428195917, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0020101571223106445, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.020772013497564495, \"value\": -0.7203189735514977}, \"36\": {\"effect\": -0.0018538804029525052, \"value\": 0.0778893686825329}, \"37\": {\"effect\": 0.01640449624769183, \"value\": 0.0}, \"38\": {\"effect\": 0.004553328652627295, \"value\": 0.0}, \"39\": {\"effect\": 0.17520688508890464, \"value\": 2.0}}}, {\"outValue\": 5.947318264164883, \"simIndex\": 20.0, \"features\": {\"0\": {\"effect\": 0.4578691126739264, \"value\": 1.0}, \"1\": {\"effect\": -0.2626810431223334, \"value\": 1.0}, \"2\": {\"effect\": -0.010467571801508448, \"value\": 0.0}, \"3\": {\"effect\": 0.1947391920288836, \"value\": -0.1577111747704115}, \"4\": {\"effect\": 0.02888664505243443, \"value\": 1.0}, \"5\": {\"effect\": 0.00021886539731179528, \"value\": 1.0}, \"6\": {\"effect\": -0.005079080852951946, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.1481389304410472, \"value\": 2.0}, \"8\": {\"effect\": 0.22647844464866942, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.16563799177292549, \"value\": 0.0}, \"11\": {\"effect\": 0.48963585008163324, \"value\": 5.0}, \"12\": {\"effect\": 0.12439766122654451, \"value\": -0.5348179042793186}, \"13\": {\"effect\": 0.19276966451306699, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.007408816084957584, \"value\": 0.0}, \"15\": {\"effect\": 0.22763743855090254, \"value\": 0.0}, \"16\": {\"effect\": 0.048354767041735726, \"value\": 0.8337016071237345}, \"17\": {\"effect\": 0.17991335073001027, \"value\": 0.5}, \"18\": {\"effect\": -0.004336296682168269, \"value\": 1.0}, \"19\": {\"effect\": -0.30533801901843866, \"value\": 0.0}, \"20\": {\"effect\": 0.008441383158219736, \"value\": 0.5}, \"21\": {\"effect\": 0.010408280747308887, \"value\": 0.8337016071237345}, \"22\": {\"effect\": 0.13944793970520164, \"value\": 0.0236147601720055}, \"23\": {\"effect\": 0.6624133633607264, \"value\": 51.64520390800454}, \"24\": {\"effect\": 0.04517885040667872, \"value\": 19.0}, \"25\": {\"effect\": 0.045357637958096504, \"value\": 5.0}, \"26\": {\"effect\": 0.09025086186980279, \"value\": 0.7512127700788831}, \"27\": {\"effect\": 0.010211342445233178, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.1274293847043503, \"value\": -0.9997823221419488}, \"29\": {\"effect\": 0.14862875487927243, \"value\": -0.3609033256730699}, \"30\": {\"effect\": 0.1533826924314971, \"value\": 0.3498048243624359}, \"31\": {\"effect\": 0.4118308854643298, \"value\": 1.1022856494943425}, \"32\": {\"effect\": 0.016043225333281244, \"value\": -0.1577111747704115}, \"33\": {\"effect\": -0.00849048683644721, \"value\": -0.4819151924735424}, \"34\": {\"effect\": -0.010349537710619828, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.31564068556527564, \"value\": 3.8462631806596153}, \"36\": {\"effect\": 0.04665764119340305, \"value\": -0.5348179042793186}, \"37\": {\"effect\": 0.031527186419605405, \"value\": 0.0}, \"38\": {\"effect\": 0.00289757969690759, \"value\": 0.0}, \"39\": {\"effect\": 0.10221581687318257, \"value\": 2.0}}}, {\"outValue\": 3.779712114676723, \"simIndex\": 58.0, \"features\": {\"0\": {\"effect\": -0.3554157466893065, \"value\": 0.0}, \"1\": {\"effect\": 0.34677430362599154, \"value\": 0.0}, \"2\": {\"effect\": -0.00819235763485229, \"value\": 0.0}, \"3\": {\"effect\": 0.0411675345427105, \"value\": -0.7461002978988677}, \"4\": {\"effect\": 0.03743746808332275, \"value\": 1.0}, \"5\": {\"effect\": 0.00048473797094305534, \"value\": 1.0}, \"6\": {\"effect\": 0.02249741888828405, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09249229931613732, \"value\": 1.0}, \"8\": {\"effect\": -0.06486722228556996, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2438321580308083, \"value\": 0.0}, \"11\": {\"effect\": 0.2883919314937858, \"value\": 2.0}, \"12\": {\"effect\": -0.07044860446315478, \"value\": 1.212790340191417}, \"13\": {\"effect\": 0.03240770514932268, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.008802712043069046, \"value\": 0.0}, \"15\": {\"effect\": -0.6373437341620927, \"value\": 1.0}, \"16\": {\"effect\": 0.3389675938861787, \"value\": 0.8944699595268933}, \"17\": {\"effect\": 0.13771628651618623, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.013914635003061372, \"value\": 1.0}, \"19\": {\"effect\": 0.252512144831977, \"value\": 1.0}, \"20\": {\"effect\": -0.10331786246515923, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.021569659786717692, \"value\": 0.8944699595268933}, \"22\": {\"effect\": 0.15044563793455404, \"value\": 0.0215584555359531}, \"23\": {\"effect\": -0.07432238253799932, \"value\": -0.8974181827757686}, \"24\": {\"effect\": 0.05288217390724249, \"value\": 11.0}, \"25\": {\"effect\": 0.029238196978815773, \"value\": 2.0}, \"26\": {\"effect\": 0.6996822487868144, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.002474705369185588, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.49446014903170493, \"value\": 3.198778042768652}, \"29\": {\"effect\": 0.08758544447213182, \"value\": -0.9531411725843202}, \"30\": {\"effect\": -0.0031475666110483626, \"value\": 0.8254933384439148}, \"31\": {\"effect\": 0.3023434445959845, \"value\": 1.1675562364399952}, \"32\": {\"effect\": 0.02535376174821192, \"value\": -0.7461002978988677}, \"33\": {\"effect\": 0.0325390714180398, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0016757139941914827, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.011392891220799554, \"value\": -0.1312981025230191}, \"36\": {\"effect\": 0.008815472171792222, \"value\": 1.212790340191417}, \"37\": {\"effect\": 0.013445686614226331, \"value\": 0.0}, \"38\": {\"effect\": 0.0017453029424814362, \"value\": 0.0}, \"39\": {\"effect\": 0.05386213211050404, \"value\": 1.0}}}, {\"outValue\": 3.353270997874611, \"simIndex\": 24.0, \"features\": {\"0\": {\"effect\": 0.3970831306247617, \"value\": 1.0}, \"1\": {\"effect\": 0.3142606363546589, \"value\": 0.0}, \"2\": {\"effect\": -0.010270046110554888, \"value\": 0.0}, \"3\": {\"effect\": 0.04516239621744698, \"value\": -0.9900665196838372}, \"4\": {\"effect\": -0.7482616986316475, \"value\": 2.0}, \"5\": {\"effect\": -0.0005950861340563149, \"value\": 1.0}, \"6\": {\"effect\": 0.04792412464175767, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.7108801155963552, \"value\": 6.0}, \"8\": {\"effect\": 0.2924380510258146, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.19963453516936008, \"value\": 0.0}, \"11\": {\"effect\": 0.26794761768296943, \"value\": 2.0}, \"12\": {\"effect\": -0.11121607782848475, \"value\": -0.0374905723297637}, \"13\": {\"effect\": 0.11080717260338671, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.008924197793875266, \"value\": 0.0}, \"15\": {\"effect\": 0.2663487467440568, \"value\": 0.0}, \"16\": {\"effect\": -0.5481329050988826, \"value\": 0.0466435703155568}, \"17\": {\"effect\": 0.3117845463530669, \"value\": 0.1}, \"18\": {\"effect\": -0.17568744967799377, \"value\": 0.0}, \"19\": {\"effect\": -0.23705348574081295, \"value\": 0.0}, \"20\": {\"effect\": 0.04100655584661889, \"value\": 0.1}, \"21\": {\"effect\": -0.09963081824706202, \"value\": 0.0466435703155568}, \"22\": {\"effect\": -0.06623862968040513, \"value\": 0.0064613662379056}, \"23\": {\"effect\": -0.025828854127365637, \"value\": -1.0220130928386315}, \"24\": {\"effect\": 0.04610515347306151, \"value\": 5.0}, \"25\": {\"effect\": 0.03659653709285316, \"value\": 2.0}, \"26\": {\"effect\": -0.4671470174404106, \"value\": 0.4910510657135932}, \"27\": {\"effect\": 0.006444526243774727, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.03549054256174309, \"value\": -0.8714890438564032}, \"29\": {\"effect\": 0.025520544614849764, \"value\": -0.1047944390672158}, \"30\": {\"effect\": 0.17459188953447186, \"value\": -0.0639249168726184}, \"31\": {\"effect\": 0.09432641167267385, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.013271715618581115, \"value\": -0.9900665196838372}, \"33\": {\"effect\": -0.12259862773867103, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.0016066624514099966, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10436188016224725, \"value\": -0.1702690453675851}, \"36\": {\"effect\": 0.02365212971770576, \"value\": -0.0374905723297637}, \"37\": {\"effect\": 0.019220385040085153, \"value\": 0.0}, \"38\": {\"effect\": 0.003839870408009946, \"value\": 0.0}, \"39\": {\"effect\": 0.13424935305403193, \"value\": 2.0}}}, {\"outValue\": 4.59893040580737, \"simIndex\": 84.0, \"features\": {\"0\": {\"effect\": -0.35301906060697463, \"value\": 0.0}, \"1\": {\"effect\": -0.2745726802033832, \"value\": 1.0}, \"2\": {\"effect\": -0.021788751117015302, \"value\": 0.0}, \"3\": {\"effect\": -0.11901085179515669, \"value\": -0.4447302592233169}, \"4\": {\"effect\": 0.030741685532406325, \"value\": 1.0}, \"5\": {\"effect\": 0.00029197905591735586, \"value\": 1.0}, \"6\": {\"effect\": 0.06208724874571886, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.08888760060103548, \"value\": 1.0}, \"8\": {\"effect\": 0.19035848720670792, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8582385236629319, \"value\": 1.0}, \"11\": {\"effect\": 0.16655923447346793, \"value\": 3.0}, \"12\": {\"effect\": -0.09280248547337924, \"value\": 0.0221887075041828}, \"13\": {\"effect\": 0.03738673623884427, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01767622411617976, \"value\": 0.0}, \"15\": {\"effect\": 0.27263485509796653, \"value\": 0.0}, \"16\": {\"effect\": -0.47248208469183284, \"value\": 0.0977001258376673}, \"17\": {\"effect\": 0.04305065918087268, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.004606369421827716, \"value\": 1.0}, \"19\": {\"effect\": 0.29496840378059047, \"value\": 1.0}, \"20\": {\"effect\": 0.00133480287659698, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.03407022831153154, \"value\": 0.0977001258376673}, \"22\": {\"effect\": -0.05697755838276648, \"value\": 0.0047335908760908}, \"23\": {\"effect\": 0.35842766403298676, \"value\": 31.617091705598607}, \"24\": {\"effect\": 0.12102065152998537, \"value\": 14.0}, \"25\": {\"effect\": 0.026840635222723355, \"value\": 3.0}, \"26\": {\"effect\": 0.40254754396486636, \"value\": -0.6740209147048789}, \"27\": {\"effect\": -0.0026222044320818173, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.002291471095900143, \"value\": 0.4201378625824888}, \"29\": {\"effect\": -0.0031344939235672877, \"value\": 0.4099242472828535}, \"30\": {\"effect\": -0.2192372560574126, \"value\": 1.655008450708043}, \"31\": {\"effect\": 0.18721773116802576, \"value\": -0.3902351053295849}, \"32\": {\"effect\": 0.03467773823543194, \"value\": -0.4447302592233169}, \"33\": {\"effect\": 0.13216802981175965, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0039397404834149215, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.0995610439201338, \"value\": -0.0392684501024257}, \"36\": {\"effect\": -0.005226991626457171, \"value\": 0.0221887075041828}, \"37\": {\"effect\": 0.020427677356824228, \"value\": 0.0}, \"38\": {\"effect\": 0.001954801716360138, \"value\": 0.0}, \"39\": {\"effect\": 0.060326533283492134, \"value\": 1.0}}}, {\"outValue\": 1.9414373655395343, \"simIndex\": 100.0, \"features\": {\"0\": {\"effect\": -0.3714294682239465, \"value\": 0.0}, \"1\": {\"effect\": -0.2193507026168375, \"value\": 1.0}, \"2\": {\"effect\": -0.017249034885560538, \"value\": 0.0}, \"3\": {\"effect\": -0.6565816904605577, \"value\": 1.980581004403734}, \"4\": {\"effect\": 0.03577144167854451, \"value\": 1.0}, \"5\": {\"effect\": 0.0001311260294739474, \"value\": 1.0}, \"6\": {\"effect\": 0.12602614186755765, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.06468150211561628, \"value\": 1.0}, \"8\": {\"effect\": -0.07065914116343763, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.826125446483033, \"value\": 1.0}, \"11\": {\"effect\": 0.4205043465286746, \"value\": 5.0}, \"12\": {\"effect\": 0.07649520928275498, \"value\": -0.4264005459143156}, \"13\": {\"effect\": -0.25707191243103816, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.017487260146043175, \"value\": 0.0}, \"15\": {\"effect\": -0.9457284178118903, \"value\": 1.0}, \"16\": {\"effect\": -0.6663238630341309, \"value\": 0.0753160294910908}, \"17\": {\"effect\": 0.0005023082265248985, \"value\": 0.8}, \"18\": {\"effect\": 0.009437453769053713, \"value\": 1.0}, \"19\": {\"effect\": -0.2936264851148805, \"value\": 0.0}, \"20\": {\"effect\": -0.01018181123402358, \"value\": 0.8}, \"21\": {\"effect\": -0.025160831581934783, \"value\": 0.0753160294910908}, \"22\": {\"effect\": 0.2892615907222986, \"value\": 0.0327785659676142}, \"23\": {\"effect\": 0.6327293014277537, \"value\": 50.041832936682816}, \"24\": {\"effect\": 0.13516056999312812, \"value\": 21.0}, \"25\": {\"effect\": 0.04185797407616443, \"value\": 5.0}, \"26\": {\"effect\": -0.4517659040603893, \"value\": -0.4477933456915833}, \"27\": {\"effect\": -0.0013471535026404239, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.02733239394999752, \"value\": -1.4660513343453423}, \"29\": {\"effect\": -0.12906759715875854, \"value\": 0.6994235142830543}, \"30\": {\"effect\": -0.0049576644209448585, \"value\": -0.663736109927928}, \"31\": {\"effect\": 0.45181805861984775, \"value\": 0.8107436944704265}, \"32\": {\"effect\": -0.1378410950804541, \"value\": 1.980581004403734}, \"33\": {\"effect\": 0.1642246017029719, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.023114900264870154, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.040389788048513016, \"value\": -0.2406363475387151}, \"36\": {\"effect\": 0.008397893705214645, \"value\": -0.4264005459143156}, \"37\": {\"effect\": 0.01217003719396941, \"value\": 0.0}, \"38\": {\"effect\": 0.004471033976227906, \"value\": 0.0}, \"39\": {\"effect\": 0.06429136882592253, \"value\": 2.0}}}, {\"outValue\": 4.909020405403323, \"simIndex\": 94.0, \"features\": {\"0\": {\"effect\": -0.2956180919749153, \"value\": 0.0}, \"1\": {\"effect\": -0.27269157050634546, \"value\": 1.0}, \"2\": {\"effect\": 0.026215097004202388, \"value\": 1.0}, \"3\": {\"effect\": 0.1890044353583976, \"value\": -0.0572544952118945}, \"4\": {\"effect\": 0.03188969366851111, \"value\": 1.0}, \"5\": {\"effect\": 8.615596457958857e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.07308277561383751, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.10541147758696791, \"value\": 1.0}, \"8\": {\"effect\": -0.04502654140482914, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7371213692236356, \"value\": 1.0}, \"11\": {\"effect\": 0.43243788023405305, \"value\": 5.0}, \"12\": {\"effect\": 0.11952909299609303, \"value\": -0.6860054131919833}, \"13\": {\"effect\": 0.03154162330103315, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01114693364878058, \"value\": 0.0}, \"15\": {\"effect\": 0.2803560797520208, \"value\": 0.0}, \"16\": {\"effect\": 0.22122010884991292, \"value\": 0.6562182655974945}, \"17\": {\"effect\": 0.10200095755179713, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.013438721164203218, \"value\": 1.0}, \"19\": {\"effect\": 0.25690272544229475, \"value\": 1.0}, \"20\": {\"effect\": 0.005545055863850472, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.02714189364259418, \"value\": 0.6562182655974945}, \"22\": {\"effect\": 0.10312324335481163, \"value\": 0.0255387773784521}, \"23\": {\"effect\": 0.3190940770967512, \"value\": 17.875403274061945}, \"24\": {\"effect\": 0.0686899829020194, \"value\": 12.0}, \"25\": {\"effect\": 0.038041733774953436, \"value\": 5.0}, \"26\": {\"effect\": -0.6247018710650302, \"value\": 0.2761348751509624}, \"27\": {\"effect\": -0.004788396064987229, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.00042378163490200264, \"value\": -0.966972289947756}, \"29\": {\"effect\": 0.03711148799031918, \"value\": -0.3271617660539367}, \"30\": {\"effect\": 0.11552634436293593, \"value\": -0.5193945352402696}, \"31\": {\"effect\": -0.3713287342410265, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.007364162881051041, \"value\": -0.0572544952118945}, \"33\": {\"effect\": 0.1556078042549139, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.021717921472685003, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.17185475856171115, \"value\": 0.5186412913484967}, \"36\": {\"effect\": 0.018402539485369164, \"value\": -0.6860054131919833}, \"37\": {\"effect\": 0.026091514732625918, \"value\": 0.0}, \"38\": {\"effect\": 0.0017698875657033205, \"value\": 0.0}, \"39\": {\"effect\": 0.07368106707884445, \"value\": 2.0}}}, {\"outValue\": 3.8521987868837746, \"simIndex\": 16.0, \"features\": {\"0\": {\"effect\": 0.6080945174106658, \"value\": 1.0}, \"1\": {\"effect\": 0.4591785402804419, \"value\": 0.0}, \"2\": {\"effect\": 0.029073787932723832, \"value\": 1.0}, \"3\": {\"effect\": -0.011034130015326805, \"value\": -0.6312926641177055}, \"4\": {\"effect\": 0.04615996804875517, \"value\": 1.0}, \"5\": {\"effect\": 0.0006632944816681978, \"value\": 1.0}, \"6\": {\"effect\": 0.11424998060795101, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.1089257097814147, \"value\": 1.0}, \"8\": {\"effect\": -0.08865451128419026, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.18771918526163878, \"value\": 0.0}, \"11\": {\"effect\": -0.9713080210372245, \"value\": 1.0}, \"12\": {\"effect\": -0.08191724559086691, \"value\": 2.1895412201403426}, \"13\": {\"effect\": 0.05936734136269879, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01117729233051644, \"value\": 0.0}, \"15\": {\"effect\": 0.3201554543347496, \"value\": 0.0}, \"16\": {\"effect\": -0.503235646772579, \"value\": 0.09662365265163}, \"17\": {\"effect\": 0.3690559251655021, \"value\": 0.1}, \"18\": {\"effect\": -0.20487500457267468, \"value\": 0.0}, \"19\": {\"effect\": -0.28548323260951636, \"value\": 0.0}, \"20\": {\"effect\": 0.04796305327134131, \"value\": 0.1}, \"21\": {\"effect\": -0.046763779164859354, \"value\": 0.09662365265163}, \"22\": {\"effect\": 0.27004736126124373, \"value\": 0.032733260813103}, \"23\": {\"effect\": -0.19732528933949633, \"value\": -1.548627685484825}, \"24\": {\"effect\": 0.050527693579985086, \"value\": 8.0}, \"25\": {\"effect\": -0.06815912722363789, \"value\": 1.0}, \"26\": {\"effect\": 1.1741359684812795, \"value\": -0.979428132872828}, \"27\": {\"effect\": -0.00010819329495283252, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.07081105534391088, \"value\": 1.1928588302132612}, \"29\": {\"effect\": -0.03688859750662661, \"value\": 1.632914435864}, \"30\": {\"effect\": 0.1352542075447332, \"value\": -0.1375671741547335}, \"31\": {\"effect\": 0.13058165099193558, \"value\": -0.3858837328665414}, \"32\": {\"effect\": 0.0013341338535555502, \"value\": -0.6312926641177055}, \"33\": {\"effect\": 0.04881731629883624, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.001435262541918635, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10552618513616675, \"value\": -0.3858969490021638}, \"36\": {\"effect\": -0.03810937419703637, \"value\": 2.1895412201403426}, \"37\": {\"effect\": 0.02206051487356569, \"value\": 0.0}, \"38\": {\"effect\": 0.004266287155112998, \"value\": 0.0}, \"39\": {\"effect\": 0.044017341388682456, \"value\": 1.0}}}, {\"outValue\": 6.329146982638209, \"simIndex\": 67.0, \"features\": {\"0\": {\"effect\": 0.4593696350558688, \"value\": 1.0}, \"1\": {\"effect\": 0.4060582565039712, \"value\": 0.0}, \"2\": {\"effect\": -0.021522469788766613, \"value\": 0.0}, \"3\": {\"effect\": 0.04479505276173473, \"value\": -0.8752588859026751}, \"4\": {\"effect\": 0.036366994015680144, \"value\": 1.0}, \"5\": {\"effect\": 0.0004321907147145519, \"value\": 1.0}, \"6\": {\"effect\": 0.08537377023738855, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.650047676968608, \"value\": 4.0}, \"8\": {\"effect\": 0.224786609401153, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2003892790347193, \"value\": 0.0}, \"11\": {\"effect\": 0.24663942564397748, \"value\": 2.0}, \"12\": {\"effect\": -0.05473762371111903, \"value\": 1.4594646968383964}, \"13\": {\"effect\": 0.0862595998882034, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.007730640251041261, \"value\": 0.0}, \"15\": {\"effect\": 0.2486759325503847, \"value\": 0.0}, \"16\": {\"effect\": 0.13736858190405943, \"value\": 0.4241876554038889}, \"17\": {\"effect\": -0.014043298468894965, \"value\": 0.8}, \"18\": {\"effect\": 0.027687225251185468, \"value\": 1.0}, \"19\": {\"effect\": -0.2717879206690235, \"value\": 0.0}, \"20\": {\"effect\": -0.028333028006599568, \"value\": 0.8}, \"21\": {\"effect\": -0.004408927643754789, \"value\": 0.4241876554038889}, \"22\": {\"effect\": -0.14853465901073815, \"value\": 14.24818593223887}, \"23\": {\"effect\": -0.15001936280191072, \"value\": -1.003362630172552}, \"24\": {\"effect\": 0.05735779172476042, \"value\": 7.0}, \"25\": {\"effect\": 0.042977964526303744, \"value\": 2.0}, \"26\": {\"effect\": 1.1413883657701116, \"value\": -0.8776257268168449}, \"27\": {\"effect\": 0.0014648779780977175, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.004283432315522908, \"value\": 0.6133349864800512}, \"29\": {\"effect\": -0.07966457824414265, \"value\": 0.2550155008997839}, \"30\": {\"effect\": 0.18689434687071843, \"value\": 0.333162279347529}, \"31\": {\"effect\": -0.006404035808457936, \"value\": -0.3358429495415409}, \"32\": {\"effect\": 0.005818556917828417, \"value\": -0.8752588859026751}, \"33\": {\"effect\": -0.06575384656181867, \"value\": 1.4987945976101402}, \"34\": {\"effect\": 0.001574572786238911, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.06954741549990999, \"value\": -0.0347996479249416}, \"36\": {\"effect\": -0.004858173975821151, \"value\": 1.4594646968383964}, \"37\": {\"effect\": 0.022265386513331396, \"value\": 0.0}, \"38\": {\"effect\": 0.003958591080374198, \"value\": 0.0}, \"39\": {\"effect\": 0.2690551114147758, \"value\": 2.0}}}, {\"outValue\": 2.1417022457743133, \"simIndex\": 11.0, \"features\": {\"0\": {\"effect\": 0.4949682399556418, \"value\": 1.0}, \"1\": {\"effect\": 0.2606938123583836, \"value\": 0.0}, \"2\": {\"effect\": -0.021240551150192553, \"value\": 0.0}, \"3\": {\"effect\": -0.18577486660827472, \"value\": 1.6218071488376022}, \"4\": {\"effect\": 0.04136448568009052, \"value\": 1.0}, \"5\": {\"effect\": 0.0011427382477743153, \"value\": 1.0}, \"6\": {\"effect\": -0.016906045089484522, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.10930597984430879, \"value\": 1.0}, \"8\": {\"effect\": -0.06326350597794962, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22198295985450792, \"value\": 0.0}, \"11\": {\"effect\": -1.0346193840736322, \"value\": 1.0}, \"12\": {\"effect\": 0.10032069400710708, \"value\": -0.4065074526363335}, \"13\": {\"effect\": -0.25629919646243493, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.014535419326343528, \"value\": 0.0}, \"15\": {\"effect\": -0.7959253584807572, \"value\": 1.0}, \"16\": {\"effect\": -0.2359819030784659, \"value\": 0.226885714655147}, \"17\": {\"effect\": 0.17373548815311077, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.034855921251078927, \"value\": 1.0}, \"19\": {\"effect\": 0.27121964950585226, \"value\": 1.0}, \"20\": {\"effect\": -0.010238193625097194, \"value\": 0.6000000000000001}, \"21\": {\"effect\": -0.025258843135779717, \"value\": 0.226885714655147}, \"22\": {\"effect\": -0.014019751576633828, \"value\": 0.0181711151442754}, \"23\": {\"effect\": 0.8726856190022757, \"value\": 106.59364547578468}, \"24\": {\"effect\": 0.12674254623222084, \"value\": 7.0}, \"25\": {\"effect\": -0.09999610841258363, \"value\": 1.0}, \"26\": {\"effect\": -0.24733051253614632, \"value\": 3.251027407675799}, \"27\": {\"effect\": 0.0002992642487302736, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.017132095587231277, \"value\": 0.4805915247567988}, \"29\": {\"effect\": -0.05197580767122772, \"value\": -1.0229133503833792}, \"30\": {\"effect\": -0.24532348657193784, \"value\": -0.8313214238423839}, \"31\": {\"effect\": 0.2455020560528576, \"value\": -0.3597754980882803}, \"32\": {\"effect\": -0.02900064456673127, \"value\": 1.6218071488376022}, \"33\": {\"effect\": 0.17882612051104754, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.0072652383104227615, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.030071350851813772, \"value\": -0.5382733385047538}, \"36\": {\"effect\": 0.034079913385010534, \"value\": -0.4065074526363335}, \"37\": {\"effect\": 0.02596042612005334, \"value\": 0.0}, \"38\": {\"effect\": 0.0018517401441393005, \"value\": 0.0}, \"39\": {\"effect\": 0.07040371324017769, \"value\": 2.0}}}, {\"outValue\": 2.321715651839576, \"simIndex\": 81.0, \"features\": {\"0\": {\"effect\": -0.3356331833594423, \"value\": 0.0}, \"1\": {\"effect\": 0.37742165538655054, \"value\": 0.0}, \"2\": {\"effect\": 0.03220907957374171, \"value\": 1.0}, \"3\": {\"effect\": -0.30626976108165227, \"value\": 1.8514224163999269}, \"4\": {\"effect\": 0.035740443386480296, \"value\": 1.0}, \"5\": {\"effect\": 0.001720479963151811, \"value\": 1.0}, \"6\": {\"effect\": -0.20714853772449987, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.06673258756673549, \"value\": 1.0}, \"8\": {\"effect\": -0.0470415139234878, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8119638906211758, \"value\": 1.0}, \"11\": {\"effect\": -0.88055372450062, \"value\": 1.0}, \"12\": {\"effect\": 0.08594377971402532, \"value\": -0.9903697403451108}, \"13\": {\"effect\": 0.07154679455740669, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.012417589854475148, \"value\": 0.0}, \"15\": {\"effect\": 0.2261821080406767, \"value\": 0.0}, \"16\": {\"effect\": 0.21444361887494137, \"value\": 0.5357375374369842}, \"17\": {\"effect\": 0.3349866387350217, \"value\": 0.1}, \"18\": {\"effect\": 0.016191642953004806, \"value\": 1.0}, \"19\": {\"effect\": -0.3924105199225847, \"value\": 0.0}, \"20\": {\"effect\": 0.06432705072656052, \"value\": 0.1}, \"21\": {\"effect\": 0.04890457949990197, \"value\": 0.5357375374369842}, \"22\": {\"effect\": 0.18155352309582215, \"value\": 0.0288517107391928}, \"23\": {\"effect\": -0.1415832883998682, \"value\": -0.850976542009417}, \"24\": {\"effect\": -0.2357931415314772, \"value\": 3.0}, \"25\": {\"effect\": -0.11707942761592675, \"value\": 1.0}, \"26\": {\"effect\": -0.06742123259859369, \"value\": 1.011374474444173}, \"27\": {\"effect\": 0.01193291016783963, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.06857521743493265, \"value\": -1.513448160154229}, \"29\": {\"effect\": -0.031288558432960974, \"value\": -1.6093036180458482}, \"30\": {\"effect\": -0.2773114398269449, \"value\": -1.961134205438511}, \"31\": {\"effect\": 0.1524210021511704, \"value\": -0.3880594190980632}, \"32\": {\"effect\": -0.07692665701482714, \"value\": 1.8514224163999269}, \"33\": {\"effect\": -0.060735041792878836, \"value\": 1.4987945976101402}, \"34\": {\"effect\": -0.003318753788081238, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.022764047496001444, \"value\": -0.6336701527957489}, \"36\": {\"effect\": 0.04263338195094781, \"value\": -0.9903697403451108}, \"37\": {\"effect\": 0.026530147483471937, \"value\": 0.0}, \"38\": {\"effect\": 0.0037525763766841436, \"value\": 0.0}, \"39\": {\"effect\": -0.1410972239498556, \"value\": 3.0}}}, {\"outValue\": 1.7084356514126686, \"simIndex\": 49.0, \"features\": {\"0\": {\"effect\": -0.4227188853997665, \"value\": 0.0}, \"1\": {\"effect\": 0.254700742373679, \"value\": 0.0}, \"2\": {\"effect\": -0.033813873172458375, \"value\": 0.0}, \"3\": {\"effect\": 0.012629489099895646, \"value\": 0.2441155434636561}, \"4\": {\"effect\": 0.03243321881399169, \"value\": 1.0}, \"5\": {\"effect\": 0.00021080911659909242, \"value\": 1.0}, \"6\": {\"effect\": 0.05779340890870922, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.12138646964100343, \"value\": 1.0}, \"8\": {\"effect\": -0.07840127287822266, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.25190943482920936, \"value\": 0.0}, \"11\": {\"effect\": 0.24333415751733706, \"value\": 2.0}, \"12\": {\"effect\": -0.0896685577618559, \"value\": 0.1256327925496902}, \"13\": {\"effect\": 0.0331099165475107, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.01183468745028396, \"value\": 0.0}, \"15\": {\"effect\": -0.5891716226537121, \"value\": 1.0}, \"16\": {\"effect\": 0.44088138932546506, \"value\": 0.9185349779850132}, \"17\": {\"effect\": -0.39277365663919256, \"value\": 0.9}, \"18\": {\"effect\": 0.015021935976862908, \"value\": 1.0}, \"19\": {\"effect\": -0.2900280860002585, \"value\": 0.0}, \"20\": {\"effect\": -0.08721762501697096, \"value\": 0.9}, \"21\": {\"effect\": 0.03680114812372155, \"value\": 0.9185349779850132}, \"22\": {\"effect\": -0.06637370659219134, \"value\": 0.0071965453278727}, \"23\": {\"effect\": -0.08401170251753431, \"value\": -0.7479774985091603}, \"24\": {\"effect\": 0.09465118904047051, \"value\": 13.0}, \"25\": {\"effect\": 0.059293288304237926, \"value\": 2.0}, \"26\": {\"effect\": -0.5192684471278202, \"value\": 0.4231827950096046}, \"27\": {\"effect\": -0.0010879088224464944, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.07534998566848385, \"value\": 1.1917189228102172}, \"29\": {\"effect\": -0.07521876290771316, \"value\": 0.698942492453125}, \"30\": {\"effect\": 0.16741010823389807, \"value\": -0.3704593170774373}, \"31\": {\"effect\": 0.11557943588179757, \"value\": -0.3684782430143673}, \"32\": {\"effect\": 0.011387305734374064, \"value\": 0.2441155434636561}, \"33\": {\"effect\": 0.08908413039609286, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.022803159848287683, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.15267169954108725, \"value\": 0.0273455769498943}, \"36\": {\"effect\": -0.016744341834899604, \"value\": 0.1256327925496902}, \"37\": {\"effect\": 0.01226116425766645, \"value\": 0.0}, \"38\": {\"effect\": 0.0014664386298617101, \"value\": 0.0}, \"39\": {\"effect\": 0.1267949859365469, \"value\": 2.0}}}, {\"outValue\": 1.6977523311059182, \"simIndex\": 79.0, \"features\": {\"0\": {\"effect\": -0.3452981552970338, \"value\": 0.0}, \"1\": {\"effect\": -0.272202586023251, \"value\": 1.0}, \"2\": {\"effect\": -0.0376402928576557, \"value\": 0.0}, \"3\": {\"effect\": 0.019727344857265013, \"value\": 0.2728174519089467}, \"4\": {\"effect\": 0.028327450453036907, \"value\": 1.0}, \"5\": {\"effect\": 0.0012532670049818003, \"value\": 1.0}, \"6\": {\"effect\": 0.033489327929760726, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10698119224669285, \"value\": 1.0}, \"8\": {\"effect\": -0.08202468311711673, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 1.061196375663695, \"value\": 1.0}, \"11\": {\"effect\": -0.9812315965828411, \"value\": 1.0}, \"12\": {\"effect\": -0.03350712549324659, \"value\": -0.1200469094333898}, \"13\": {\"effect\": 0.09366659554759374, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.014811273508511838, \"value\": 0.0}, \"15\": {\"effect\": 0.2003339922189715, \"value\": 0.0}, \"16\": {\"effect\": 0.3507058787975254, \"value\": 0.838423928799047}, \"17\": {\"effect\": -0.40635389169510383, \"value\": 0.9}, \"18\": {\"effect\": 0.015875890700312072, \"value\": 1.0}, \"19\": {\"effect\": -0.4329167061436324, \"value\": 0.0}, \"20\": {\"effect\": -0.037865928878550635, \"value\": 0.9}, \"21\": {\"effect\": -0.02387416657653889, \"value\": 0.838423928799047}, \"22\": {\"effect\": -0.1360184904260321, \"value\": 0.0005579096528686}, \"23\": {\"effect\": 0.5710409572162124, \"value\": 100.25945723635468}, \"24\": {\"effect\": 0.02581368894937579, \"value\": 14.0}, \"25\": {\"effect\": -0.10156842109946486, \"value\": 1.0}, \"26\": {\"effect\": 0.07618898356083546, \"value\": -0.5495957517475664}, \"27\": {\"effect\": -0.006061195024745893, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.0648926177103407, \"value\": -0.2205902376761144}, \"29\": {\"effect\": 0.013165165939007692, \"value\": -1.3061715803875589}, \"30\": {\"effect\": -0.47285679118626933, \"value\": -1.9360158600248092}, \"31\": {\"effect\": 0.1330375052806884, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.006493841090634198, \"value\": 0.2728174519089467}, \"33\": {\"effect\": 0.044538573109063784, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.007720341558244379, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1361927587632047, \"value\": -0.5328448824698934}, \"36\": {\"effect\": 0.023582320604714487, \"value\": -0.1200469094333898}, \"37\": {\"effect\": -0.2851462224066445, \"value\": 1.0}, \"38\": {\"effect\": 0.001234898140062977, \"value\": 0.0}, \"39\": {\"effect\": -0.09004225455365321, \"value\": 3.0}}}, {\"outValue\": 2.844649090925133, \"simIndex\": 97.0, \"features\": {\"0\": {\"effect\": 0.5927566902216812, \"value\": 1.0}, \"1\": {\"effect\": -0.36227990391809434, \"value\": 1.0}, \"2\": {\"effect\": -0.023760637883999073, \"value\": 0.0}, \"3\": {\"effect\": 0.002948499383523697, \"value\": 0.2871684061315919}, \"4\": {\"effect\": 0.040018798031562546, \"value\": 1.0}, \"5\": {\"effect\": 0.000690258267115874, \"value\": 1.0}, \"6\": {\"effect\": -0.018658324887014577, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12320107028697971, \"value\": 1.0}, \"8\": {\"effect\": -0.10835012615999566, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7564507653012719, \"value\": 1.0}, \"11\": {\"effect\": 0.12524307400758006, \"value\": 3.0}, \"12\": {\"effect\": 0.04783580554916008, \"value\": -0.1449132760308676}, \"13\": {\"effect\": 0.04456476616465001, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.014883233920688913, \"value\": 0.0}, \"15\": {\"effect\": -0.532827758147322, \"value\": 1.0}, \"16\": {\"effect\": -0.11139388693615054, \"value\": 0.2823262122138937}, \"17\": {\"effect\": 0.06119390813356937, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.03836793656059355, \"value\": 1.0}, \"19\": {\"effect\": -0.33204055070451927, \"value\": 0.0}, \"20\": {\"effect\": -0.021723291173501892, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.003311886201774718, \"value\": 0.2823262122138937}, \"22\": {\"effect\": 0.16152310172757936, \"value\": 0.0226005031915871}, \"23\": {\"effect\": -0.2242393771359923, \"value\": -1.0887017613062415}, \"24\": {\"effect\": -0.19274730296796108, \"value\": 3.0}, \"25\": {\"effect\": 0.03367283343165295, \"value\": 3.0}, \"26\": {\"effect\": -0.21239147813230846, \"value\": 3.1039794878171567}, \"27\": {\"effect\": -0.0061182425243166815, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.05157589136725643, \"value\": 0.3885662486103252}, \"29\": {\"effect\": 0.09281777167387453, \"value\": -0.3762537590346955}, \"30\": {\"effect\": 0.09452640204851487, \"value\": 0.5215624979795103}, \"31\": {\"effect\": 0.14965256314790157, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.01175839071368832, \"value\": 0.2871684061315919}, \"33\": {\"effect\": 0.07508077752474686, \"value\": 0.3433805533946588}, \"34\": {\"effect\": -0.009163587937067697, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.08553026861432429, \"value\": -0.3975161741653795}, \"36\": {\"effect\": 0.014003715636118417, \"value\": -0.1449132760308676}, \"37\": {\"effect\": 0.01757542149870851, \"value\": 0.0}, \"38\": {\"effect\": 0.000925905386478428, \"value\": 0.0}, \"39\": {\"effect\": -0.023954124244980005, \"value\": 1.0}}}, {\"outValue\": 2.090754395993638, \"simIndex\": 54.0, \"features\": {\"0\": {\"effect\": -0.3716123697498262, \"value\": 0.0}, \"1\": {\"effect\": -0.24826783312649525, \"value\": 1.0}, \"2\": {\"effect\": -0.05897319506704781, \"value\": 0.0}, \"3\": {\"effect\": 0.05058833664086161, \"value\": 0.2441155434636561}, \"4\": {\"effect\": 0.03190397631484179, \"value\": 1.0}, \"5\": {\"effect\": 0.0003926038750518303, \"value\": 1.0}, \"6\": {\"effect\": 0.06689719507039199, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.0957245333175477, \"value\": 1.0}, \"8\": {\"effect\": -0.07906898381814553, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2005992501536612, \"value\": 0.0}, \"11\": {\"effect\": 0.29140907160541546, \"value\": 4.0}, \"12\": {\"effect\": 0.08073769475884116, \"value\": -0.5119408470096392}, \"13\": {\"effect\": 0.014541933069491322, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.006685251327457298, \"value\": 0.0}, \"15\": {\"effect\": -0.6875991766198272, \"value\": 1.0}, \"16\": {\"effect\": -0.4416403910882793, \"value\": 0.1466809421263942}, \"17\": {\"effect\": -0.4709106848685151, \"value\": 0.9}, \"18\": {\"effect\": 0.010864696621467279, \"value\": 1.0}, \"19\": {\"effect\": 0.3403224806957075, \"value\": 1.0}, \"20\": {\"effect\": -0.04968614894461028, \"value\": 0.9}, \"21\": {\"effect\": -0.029397312701566963, \"value\": 0.1466809421263942}, \"22\": {\"effect\": 0.12343420531149028, \"value\": 0.0209620875462239}, \"23\": {\"effect\": 0.04319841792818196, \"value\": -0.395195132560878}, \"24\": {\"effect\": -0.3077322955457775, \"value\": 3.0}, \"25\": {\"effect\": 0.029760855485033953, \"value\": 4.0}, \"26\": {\"effect\": 0.8530913927067545, \"value\": -0.7871346992115267}, \"27\": {\"effect\": -0.005533454007746004, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.09032154401963804, \"value\": -1.3397860282730976}, \"29\": {\"effect\": -0.05005934670561505, \"value\": 0.1761448549105544}, \"30\": {\"effect\": 0.09309619276536747, \"value\": -0.5994551903605114}, \"31\": {\"effect\": 0.08513880628758064, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.002421236851212744, \"value\": 0.2441155434636561}, \"33\": {\"effect\": 0.14489765018329687, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.007862432422621897, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.16391329033487784, \"value\": 0.0706742854790419}, \"36\": {\"effect\": -0.0007696759380415088, \"value\": -0.5119408470096392}, \"37\": {\"effect\": 0.011704742133275419, \"value\": 0.0}, \"38\": {\"effect\": 0.0011336447829557957, \"value\": 0.0}, \"39\": {\"effect\": -0.08677169732422883, \"value\": 3.0}}}, {\"outValue\": 0.7293273138966367, \"simIndex\": 5.0, \"features\": {\"0\": {\"effect\": -0.46181991408995954, \"value\": 0.0}, \"1\": {\"effect\": 0.28328473662391523, \"value\": 0.0}, \"2\": {\"effect\": 0.026954656650847696, \"value\": 1.0}, \"3\": {\"effect\": -0.37227145245920495, \"value\": 2.05233577551696}, \"4\": {\"effect\": 0.024056258733840832, \"value\": 1.0}, \"5\": {\"effect\": 0.001279718691921979, \"value\": 1.0}, \"6\": {\"effect\": -0.11483728964126728, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.12650859327795488, \"value\": 1.0}, \"8\": {\"effect\": -0.07527500727735635, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.23672122382866737, \"value\": 0.0}, \"11\": {\"effect\": -0.7778012821910252, \"value\": 1.0}, \"12\": {\"effect\": 0.07526526224524419, \"value\": -0.6183688960468439}, \"13\": {\"effect\": -0.27863547852442155, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.010169188888637276, \"value\": 0.0}, \"15\": {\"effect\": 0.3673380585351784, \"value\": 0.0}, \"16\": {\"effect\": 0.037281997191934375, \"value\": 0.8250636626767969}, \"17\": {\"effect\": -0.0002756609806322239, \"value\": 0.8}, \"18\": {\"effect\": 0.0157513063402274, \"value\": 1.0}, \"19\": {\"effect\": 0.3571743948123914, \"value\": 1.0}, \"20\": {\"effect\": -0.041957760279391916, \"value\": 0.8}, \"21\": {\"effect\": 0.026315677846638512, \"value\": 0.8250636626767969}, \"22\": {\"effect\": -0.07841795133436022, \"value\": 0.0065793600081051}, \"23\": {\"effect\": -0.20254040421741842, \"value\": -1.1343380859187744}, \"24\": {\"effect\": 0.07093853370676301, \"value\": 6.0}, \"25\": {\"effect\": -0.15246026514294084, \"value\": 1.0}, \"26\": {\"effect\": -0.4813279134074163, \"value\": 0.4797396872629285}, \"27\": {\"effect\": 0.0005884015114983005, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.02980329061581256, \"value\": -0.003223211624672}, \"29\": {\"effect\": 0.07885805459263694, \"value\": -1.0014615776700966}, \"30\": {\"effect\": 0.0987235008386141, \"value\": -0.6342878062186565}, \"31\": {\"effect\": 0.14692059751508346, \"value\": 2.7710369890715323}, \"32\": {\"effect\": -0.04380459483628247, \"value\": 2.05233577551696}, \"33\": {\"effect\": -0.15731490047527083, \"value\": 1.16867629926286}, \"34\": {\"effect\": -0.01005689707433104, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.02266948845088573, \"value\": -0.6887251920711804}, \"36\": {\"effect\": 0.016287524238530714, \"value\": -0.6183688960468439}, \"37\": {\"effect\": 0.0165270909542581, \"value\": 0.0}, \"38\": {\"effect\": 0.001352739524033527, \"value\": 0.0}, \"39\": {\"effect\": -0.17266719925898977, \"value\": 3.0}}}, {\"outValue\": 1.9996682718656742, \"simIndex\": 34.0, \"features\": {\"0\": {\"effect\": -0.3702210562075337, \"value\": 0.0}, \"1\": {\"effect\": 0.3224523624718686, \"value\": 0.0}, \"2\": {\"effect\": -0.013516276181604163, \"value\": 0.0}, \"3\": {\"effect\": -0.06086053643258338, \"value\": 1.1482256594903082}, \"4\": {\"effect\": 0.02436186843433169, \"value\": 1.0}, \"5\": {\"effect\": -0.0017916683427739257, \"value\": 1.0}, \"6\": {\"effect\": 0.1158666133323821, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.11052171858832548, \"value\": 1.0}, \"8\": {\"effect\": 0.16114412089738248, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.24025501775904526, \"value\": 0.0}, \"11\": {\"effect\": 0.4250767468644608, \"value\": 5.0}, \"12\": {\"effect\": 0.05233639568777427, \"value\": -0.882947036644007}, \"13\": {\"effect\": 0.22439926658997397, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.009321902262232257, \"value\": 0.0}, \"15\": {\"effect\": 0.29290714502095244, \"value\": 0.0}, \"16\": {\"effect\": -0.29225836376508885, \"value\": 0.1902649533763414}, \"17\": {\"effect\": -0.558240133140133, \"value\": 0.9}, \"18\": {\"effect\": 0.008751378038046757, \"value\": 1.0}, \"19\": {\"effect\": -0.31936250845339226, \"value\": 0.0}, \"20\": {\"effect\": -0.07666259684807183, \"value\": 0.9}, \"21\": {\"effect\": -0.027174553517956532, \"value\": 0.1902649533763414}, \"22\": {\"effect\": -0.03547828216582397, \"value\": 0.0029140384928089}, \"23\": {\"effect\": -0.15138083229998292, \"value\": -0.7949532263696695}, \"24\": {\"effect\": 0.041690668109610265, \"value\": 5.0}, \"25\": {\"effect\": 0.02690140167715269, \"value\": 5.0}, \"26\": {\"effect\": -0.6575740828000471, \"value\": 0.2874462536016272}, \"27\": {\"effect\": 0.006268772318277004, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.009932291523057555, \"value\": -1.5283029049562116}, \"29\": {\"effect\": -0.02964867639859702, \"value\": 0.179948098862764}, \"30\": {\"effect\": 0.09811822488473651, \"value\": -0.6065805450041664}, \"31\": {\"effect\": 0.03909626475539762, \"value\": -0.3750053017089326}, \"32\": {\"effect\": -0.012797914475339466, \"value\": 1.1482256594903082}, \"33\": {\"effect\": 0.05277913731841684, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.016324755259315357, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.022671607546379986, \"value\": -0.5905106245828544}, \"36\": {\"effect\": 0.01481099977607776, \"value\": -0.882947036644007}, \"37\": {\"effect\": 0.023194988428410085, \"value\": 0.0}, \"38\": {\"effect\": 0.0014535687800066193, \"value\": 0.0}, \"39\": {\"effect\": 0.10146904254045856, \"value\": 2.0}}}, {\"outValue\": 5.380694651169142, \"simIndex\": 76.0, \"features\": {\"0\": {\"effect\": 0.38086824869227187, \"value\": 1.0}, \"1\": {\"effect\": -0.24562749687666283, \"value\": 1.0}, \"2\": {\"effect\": -0.01745335387020224, \"value\": 0.0}, \"3\": {\"effect\": 0.18897303798969875, \"value\": -0.2581678543289284}, \"4\": {\"effect\": 0.03169962248162407, \"value\": 1.0}, \"5\": {\"effect\": -2.609615861214286e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.052423734060838105, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.1893851345806436, \"value\": 2.0}, \"8\": {\"effect\": 0.18265355202305672, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.749721134370584, \"value\": 1.0}, \"11\": {\"effect\": 0.2601998432709981, \"value\": 2.0}, \"12\": {\"effect\": 0.08142241896637623, \"value\": -0.4632027684785827}, \"13\": {\"effect\": 0.03187931913485138, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.015387494467758054, \"value\": 0.0}, \"15\": {\"effect\": 0.22440658983009404, \"value\": 0.0}, \"16\": {\"effect\": -0.4544678077033147, \"value\": 0.1439571342498778}, \"17\": {\"effect\": -0.44272412870045297, \"value\": 0.9}, \"18\": {\"effect\": 0.03882842495574505, \"value\": 1.0}, \"19\": {\"effect\": 0.22765506958571308, \"value\": 1.0}, \"20\": {\"effect\": -0.0545240298161948, \"value\": 0.9}, \"21\": {\"effect\": -0.043506292213219624, \"value\": 0.1439571342498778}, \"22\": {\"effect\": 0.4372694520276076, \"value\": 0.0524692318456086}, \"23\": {\"effect\": -0.08881971135236826, \"value\": -0.6897968565020084}, \"24\": {\"effect\": 0.005139263521479333, \"value\": 5.0}, \"25\": {\"effect\": 0.02796353797136423, \"value\": 2.0}, \"26\": {\"effect\": 0.5513767817688201, \"value\": -0.7532005638595324}, \"27\": {\"effect\": 0.00015294378148772008, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.10416188486785469, \"value\": 2.2236398248656304}, \"29\": {\"effect\": -0.020486447409086964, \"value\": 1.6627118099018383}, \"30\": {\"effect\": 0.015301548237344566, \"value\": 0.7383397647086981}, \"31\": {\"effect\": 0.015242813884653095, \"value\": -0.3293158908469756}, \"32\": {\"effect\": 0.009232963203971073, \"value\": -0.2581678543289284}, \"33\": {\"effect\": 0.17680465882552085, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0019318089774918667, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.016057094783456013, \"value\": -0.2521809014779365}, \"36\": {\"effect\": 0.013390934803189383, \"value\": -0.4632027684785827}, \"37\": {\"effect\": 0.024796529481274227, \"value\": 0.0}, \"38\": {\"effect\": 0.0014332536965621354, \"value\": 0.0}, \"39\": {\"effect\": -0.01053149105539527, \"value\": 1.0}}}, {\"outValue\": 3.1122227247231984, \"simIndex\": 43.0, \"features\": {\"0\": {\"effect\": -0.3757421201122269, \"value\": 0.0}, \"1\": {\"effect\": 0.3584469273097637, \"value\": 0.0}, \"2\": {\"effect\": -0.005880674223492958, \"value\": 0.0}, \"3\": {\"effect\": -0.051725096900053016, \"value\": 0.7176970328109501}, \"4\": {\"effect\": 0.027474263834580577, \"value\": 1.0}, \"5\": {\"effect\": 9.852923886001047e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.11913740296953543, \"value\": 0.9724943033069674}, \"7\": {\"effect\": -0.1485534577283306, \"value\": 1.0}, \"8\": {\"effect\": 0.23292462601521674, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2548924495212912, \"value\": 0.0}, \"11\": {\"effect\": 0.18613284836468766, \"value\": 3.0}, \"12\": {\"effect\": 0.10711268048478342, \"value\": -0.6969466144948735}, \"13\": {\"effect\": 0.018107659782001996, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.007910742932311659, \"value\": 0.0}, \"15\": {\"effect\": 0.29524673285654873, \"value\": 0.0}, \"16\": {\"effect\": 0.19156212270417, \"value\": 0.5228322324319671}, \"17\": {\"effect\": 0.25409121307734023, \"value\": 0.1}, \"18\": {\"effect\": 0.007090270721574765, \"value\": 1.0}, \"19\": {\"effect\": -0.36318530793565623, \"value\": 0.0}, \"20\": {\"effect\": 0.05908732366684284, \"value\": 0.1}, \"21\": {\"effect\": 0.02496344878203691, \"value\": 0.5228322324319671}, \"22\": {\"effect\": 0.09874512144372001, \"value\": 0.0221784144262212}, \"23\": {\"effect\": 0.12773008989060677, \"value\": -0.3204386728718779}, \"24\": {\"effect\": 0.06737246708655908, \"value\": 23.0}, \"25\": {\"effect\": 0.0361214059085399, \"value\": 3.0}, \"26\": {\"effect\": -0.693472532800032, \"value\": 0.2761348751509624}, \"27\": {\"effect\": -0.0021332702816237504, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.02970982757557912, \"value\": 0.1299793030505146}, \"29\": {\"effect\": 0.05487256688901889, \"value\": -0.9381340664645018}, \"30\": {\"effect\": 0.0316019113881183, \"value\": 0.8083180925364188}, \"31\": {\"effect\": -0.28182067338647976, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.0062916997017352224, \"value\": 0.7176970328109501}, \"33\": {\"effect\": -0.03666961139646723, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.01090202820366434, \"value\": 0.9724943033069674}, \"35\": {\"effect\": -0.018705743013823342, \"value\": -0.2063164831673995}, \"36\": {\"effect\": 0.008473542885764816, \"value\": -0.6969466144948735}, \"37\": {\"effect\": 0.026095364225205007, \"value\": 0.0}, \"38\": {\"effect\": 0.002011702770209054, \"value\": 0.0}, \"39\": {\"effect\": 0.056846358899139596, \"value\": 1.0}}}, {\"outValue\": 3.4777877241258364, \"simIndex\": 72.0, \"features\": {\"0\": {\"effect\": -0.3208969974521612, \"value\": 0.0}, \"1\": {\"effect\": -0.27037628090614313, \"value\": 1.0}, \"2\": {\"effect\": -0.020237409753399726, \"value\": 0.0}, \"3\": {\"effect\": 0.22078036135247736, \"value\": -0.1290092663251209}, \"4\": {\"effect\": 0.030262882808300702, \"value\": 1.0}, \"5\": {\"effect\": 0.000313959207095694, \"value\": 1.0}, \"6\": {\"effect\": 0.0060178691067298735, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.14448595832896538, \"value\": 1.0}, \"8\": {\"effect\": 0.17479091676211597, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.23553236238520625, \"value\": 0.0}, \"11\": {\"effect\": 0.28226954506825874, \"value\": 2.0}, \"12\": {\"effect\": 0.11250458179826835, \"value\": -0.5119408470096392}, \"13\": {\"effect\": 0.05950897492056915, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010626166555464072, \"value\": 0.0}, \"15\": {\"effect\": 0.2941449208571981, \"value\": 0.0}, \"16\": {\"effect\": 0.21854941799546532, \"value\": 0.4058771515049263}, \"17\": {\"effect\": 0.23264274358690176, \"value\": 0.3}, \"18\": {\"effect\": 0.011167892054015579, \"value\": 1.0}, \"19\": {\"effect\": -0.38430035880426, \"value\": 0.0}, \"20\": {\"effect\": 0.04980926074863584, \"value\": 0.3}, \"21\": {\"effect\": -0.013389859787122116, \"value\": 0.4058771515049263}, \"22\": {\"effect\": -0.2497324709027594, \"value\": 0.0001581464728412}, \"23\": {\"effect\": -0.024196345558093434, \"value\": -0.7934247690654197}, \"24\": {\"effect\": 0.05529175316933099, \"value\": 7.0}, \"25\": {\"effect\": 0.06515349727695352, \"value\": 2.0}, \"26\": {\"effect\": 0.10141589556810598, \"value\": -0.5722185086488959}, \"27\": {\"effect\": -0.004560763319231487, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.06276778863906057, \"value\": 1.667822111368752}, \"29\": {\"effect\": -0.04019312554468455, \"value\": 2.363381748575836}, \"30\": {\"effect\": 0.054323838863116154, \"value\": 0.8236336341231767}, \"31\": {\"effect\": -0.011964479113238507, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.006072057562122664, \"value\": -0.1290092663251209}, \"33\": {\"effect\": 0.02054787805778749, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0018217737668512093, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.17320001884299072, \"value\": 0.7661714283677769}, \"36\": {\"effect\": 0.013052666855759745, \"value\": -0.5119408470096392}, \"37\": {\"effect\": 0.023740439902014483, \"value\": 0.0}, \"38\": {\"effect\": 0.0022608484370175833, \"value\": 0.0}, \"39\": {\"effect\": 0.003190004400462861, \"value\": 1.0}}}, {\"outValue\": 0.9054505289536969, \"simIndex\": 12.0, \"features\": {\"0\": {\"effect\": 0.5202585282131006, \"value\": 1.0}, \"1\": {\"effect\": 0.31509437260014417, \"value\": 0.0}, \"2\": {\"effect\": 0.00089576481952393, \"value\": 0.0}, \"3\": {\"effect\": -0.20224158111713209, \"value\": 1.449595698165859}, \"4\": {\"effect\": 0.04207195944812416, \"value\": 1.0}, \"5\": {\"effect\": 0.0007609011671613388, \"value\": 1.0}, \"6\": {\"effect\": 0.014981594557363349, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.1396022979013846, \"value\": 1.0}, \"8\": {\"effect\": -0.07776836326705504, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2563947153314497, \"value\": 0.0}, \"11\": {\"effect\": -1.0311238396208875, \"value\": 1.0}, \"12\": {\"effect\": -0.08153473208987386, \"value\": -0.0454478096409566}, \"13\": {\"effect\": -0.20502104196326296, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.013486332573223403, \"value\": 0.0}, \"15\": {\"effect\": -0.6852202632766967, \"value\": 1.0}, \"16\": {\"effect\": -0.07787985668965329, \"value\": 0.2687254035631397}, \"17\": {\"effect\": 0.33259733833169625, \"value\": 0.1}, \"18\": {\"effect\": -0.19088538488428447, \"value\": 0.0}, \"19\": {\"effect\": 0.2776274141620923, \"value\": 1.0}, \"20\": {\"effect\": 0.05123298462468571, \"value\": 0.1}, \"21\": {\"effect\": -0.02425447476785877, \"value\": 0.2687254035631397}, \"22\": {\"effect\": -0.012081482992578852, \"value\": 0.0101073198582863}, \"23\": {\"effect\": -0.4074120139178621, \"value\": -1.6299725790196913}, \"24\": {\"effect\": -0.009720169765717055, \"value\": 4.0}, \"25\": {\"effect\": -0.08048209244181914, \"value\": 1.0}, \"26\": {\"effect\": -0.08517016572486559, \"value\": 1.1810451512041449}, \"27\": {\"effect\": -0.0005519711820244453, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.03291727433175265, \"value\": -0.6701417196855498}, \"29\": {\"effect\": -0.12115788870240546, \"value\": 1.0450169573587784}, \"30\": {\"effect\": 0.11143658105586102, \"value\": 0.3034857892972058}, \"31\": {\"effect\": -0.1804615935829112, \"value\": -0.3967621640241502}, \"32\": {\"effect\": -0.026529266074059796, \"value\": 1.449595698165859}, \"33\": {\"effect\": 0.03571821906327775, \"value\": -0.6469743416471827}, \"34\": {\"effect\": 0.03315923972193765, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.06309022461840319, \"value\": -0.4595795508444403}, \"36\": {\"effect\": 0.025590768021424883, \"value\": -0.0454478096409566}, \"37\": {\"effect\": 0.018995658892260018, \"value\": 0.0}, \"38\": {\"effect\": 0.0009511597406490766, \"value\": 0.0}, \"39\": {\"effect\": 0.12483167572357347, \"value\": 2.0}}}, {\"outValue\": -0.03285021979308089, \"simIndex\": 8.0, \"features\": {\"0\": {\"effect\": -0.39818156163029483, \"value\": 0.0}, \"1\": {\"effect\": -0.33406686684038317, \"value\": 1.0}, \"2\": {\"effect\": 0.021340807332988328, \"value\": 1.0}, \"3\": {\"effect\": 0.08265927910783508, \"value\": -0.8896098401253204}, \"4\": {\"effect\": 0.027143028261162425, \"value\": 1.0}, \"5\": {\"effect\": 0.00042811846718456676, \"value\": 1.0}, \"6\": {\"effect\": 0.05303257904048196, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.08559382560927174, \"value\": 1.0}, \"8\": {\"effect\": -0.07700312240891288, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22155013995807976, \"value\": 0.0}, \"11\": {\"effect\": -0.9887550444907872, \"value\": 1.0}, \"12\": {\"effect\": -0.17513381869075265, \"value\": 0.9780518395112272}, \"13\": {\"effect\": 0.026736779699720156, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.006870812370629368, \"value\": 0.0}, \"15\": {\"effect\": 0.3456238431754281, \"value\": 0.0}, \"16\": {\"effect\": 0.25612265244882904, \"value\": 0.5456563501802075}, \"17\": {\"effect\": -0.426245943840334, \"value\": 0.9}, \"18\": {\"effect\": 0.018400016177149852, \"value\": 1.0}, \"19\": {\"effect\": -0.42169849748135474, \"value\": 0.0}, \"20\": {\"effect\": -0.0389214954854175, \"value\": 0.9}, \"21\": {\"effect\": 0.03241578537551157, \"value\": 0.5456563501802075}, \"22\": {\"effect\": 0.5592645748092185, \"value\": 0.0404237194438229}, \"23\": {\"effect\": -0.08067968578835255, \"value\": -0.8898183565146907}, \"24\": {\"effect\": 0.19109165335613423, \"value\": 16.0}, \"25\": {\"effect\": -0.1248643612128488, \"value\": 1.0}, \"26\": {\"effect\": -0.19356090881555732, \"value\": 1.373338584865446}, \"27\": {\"effect\": -0.002357475147264495, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.1250197245852582, \"value\": 1.2750214853715454}, \"29\": {\"effect\": -0.07402763869723332, \"value\": 0.9404408087908313}, \"30\": {\"effect\": -0.32820080165593596, \"value\": 2.050810574870477}, \"31\": {\"effect\": -0.2915091844256817, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.006582077027469136, \"value\": -0.8896098401253204}, \"33\": {\"effect\": -0.04576631193193108, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.0023063532908893106, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.05161361050662475, \"value\": -0.2309749956756041}, \"36\": {\"effect\": -0.03879646611317084, \"value\": 0.9780518395112272}, \"37\": {\"effect\": 0.028322574844624342, \"value\": 0.0}, \"38\": {\"effect\": 0.001472011845390202, \"value\": 0.0}, \"39\": {\"effect\": -0.08054286292631063, \"value\": 1.0}}}, {\"outValue\": -1.787027146059859, \"simIndex\": 1.0, \"features\": {\"0\": {\"effect\": -0.24593136378120584, \"value\": 0.0}, \"1\": {\"effect\": 0.37774492006616145, \"value\": 0.0}, \"2\": {\"effect\": -0.02031374188890798, \"value\": 0.0}, \"3\": {\"effect\": -0.5638115443675074, \"value\": 1.9949319586263796}, \"4\": {\"effect\": -0.8959071597571618, \"value\": 2.0}, \"5\": {\"effect\": 0.0017805076198770804, \"value\": 1.0}, \"6\": {\"effect\": -1.0338491403068144, \"value\": 3.04403566911276}, \"7\": {\"effect\": -0.09727888914943307, \"value\": 1.0}, \"8\": {\"effect\": -0.04324582538696738, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22950696691000233, \"value\": 0.0}, \"11\": {\"effect\": -1.1086823687544396, \"value\": 1.0}, \"12\": {\"effect\": -0.13726053774844546, \"value\": 1.102383672498616}, \"13\": {\"effect\": 0.026316242160217183, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010631931311485088, \"value\": 0.0}, \"15\": {\"effect\": 0.2168266141701914, \"value\": 0.0}, \"16\": {\"effect\": 0.1365527509285338, \"value\": 0.6667941987074497}, \"17\": {\"effect\": 0.15171539507965912, \"value\": 0.7000000000000001}, \"18\": {\"effect\": -0.017384462566195944, \"value\": 1.0}, \"19\": {\"effect\": -0.45272588965362015, \"value\": 0.0}, \"20\": {\"effect\": 0.014399375701122747, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.031958417639155766, \"value\": 0.6667941987074497}, \"22\": {\"effect\": 0.08006024911697315, \"value\": 0.0207397599315737}, \"23\": {\"effect\": -0.11585568374010714, \"value\": -0.9169465574063528}, \"24\": {\"effect\": 0.04073039583974299, \"value\": 6.0}, \"25\": {\"effect\": -0.09399387687760138, \"value\": 1.0}, \"26\": {\"effect\": -0.26941835088073157, \"value\": 0.2082666044469737}, \"27\": {\"effect\": 0.009948905738914934, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.14389606902228042, \"value\": 1.8491641908618344}, \"29\": {\"effect\": -0.07878414756966712, \"value\": 0.1068743080232039}, \"30\": {\"effect\": 0.06710604810906633, \"value\": 0.8062524521133926}, \"31\": {\"effect\": 0.16296603912969398, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.06356842028674634, \"value\": 1.9949319586263796}, \"33\": {\"effect\": -0.2422812358092281, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.06430777369254041, \"value\": 3.04403566911276}, \"35\": {\"effect\": -0.10992332013589841, \"value\": -0.2953950887937493}, \"36\": {\"effect\": 0.0012600190675165302, \"value\": 1.102383672498616}, \"37\": {\"effect\": 0.014954032878152015, \"value\": 0.0}, \"38\": {\"effect\": -0.3517529840761878, \"value\": 1.0}, \"39\": {\"effect\": 0.048482441882776, \"value\": 1.0}}}, {\"outValue\": 4.58437034606355, \"simIndex\": 91.0, \"features\": {\"0\": {\"effect\": -0.3349093437515166, \"value\": 0.0}, \"1\": {\"effect\": -0.3148167722468352, \"value\": 1.0}, \"2\": {\"effect\": -0.010614331793564169, \"value\": 0.0}, \"3\": {\"effect\": 0.2386322749989022, \"value\": -0.1290092663251209}, \"4\": {\"effect\": 0.03415904164257187, \"value\": 1.0}, \"5\": {\"effect\": 0.0011377135943533468, \"value\": 1.0}, \"6\": {\"effect\": 0.0221572301018328, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11783110970280573, \"value\": 1.0}, \"8\": {\"effect\": 0.24173762095646897, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8807501344265215, \"value\": 1.0}, \"11\": {\"effect\": 0.18942809486087242, \"value\": 2.0}, \"12\": {\"effect\": 0.1082987202532927, \"value\": -0.438336401881105}, \"13\": {\"effect\": 0.03046935766155099, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010361794667002476, \"value\": 0.0}, \"15\": {\"effect\": 0.24577008179266766, \"value\": 0.0}, \"16\": {\"effect\": 0.09998699664105884, \"value\": 0.8118733016389821}, \"17\": {\"effect\": 0.25613815300285114, \"value\": 0.1}, \"18\": {\"effect\": 0.007176949062480301, \"value\": 1.0}, \"19\": {\"effect\": -0.23467150771955855, \"value\": 0.0}, \"20\": {\"effect\": 0.03556325239758989, \"value\": 0.1}, \"21\": {\"effect\": 0.015564499931789247, \"value\": 0.8118733016389821}, \"22\": {\"effect\": -0.0027602430911038665, \"value\": 0.0085113139429613}, \"23\": {\"effect\": 0.43219508809150736, \"value\": 98.9574134707346}, \"24\": {\"effect\": 0.029315805137455332, \"value\": 8.0}, \"25\": {\"effect\": 0.0459943128167595, \"value\": 2.0}, \"26\": {\"effect\": -0.5931777525044822, \"value\": -0.2102543982276229}, \"27\": {\"effect\": -0.005079262686285247, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.003649779123224275, \"value\": -0.4857764207646231}, \"29\": {\"effect\": 0.003828083753755668, \"value\": -0.0991431450267918}, \"30\": {\"effect\": 0.13953443689319298, \"value\": 0.5434141846860041}, \"31\": {\"effect\": 0.20360143458390745, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.011386546868225034, \"value\": -0.1290092663251209}, \"33\": {\"effect\": -0.06894967003314816, \"value\": -0.7295039162340028}, \"34\": {\"effect\": 0.0012255730672514216, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.082430105128783, \"value\": -0.4647487834025468}, \"36\": {\"effect\": 0.0214362719993117, \"value\": -0.438336401881105}, \"37\": {\"effect\": 0.02281445287861522, \"value\": 0.0}, \"38\": {\"effect\": 0.0028296033844167285, \"value\": 0.0}, \"39\": {\"effect\": 0.11034051656062169, \"value\": 2.0}}}, {\"outValue\": 1.498914675431021, \"simIndex\": 51.0, \"features\": {\"0\": {\"effect\": -0.3829534014359412, \"value\": 0.0}, \"1\": {\"effect\": -0.230965473465667, \"value\": 1.0}, \"2\": {\"effect\": -0.021741984448838486, \"value\": 0.0}, \"3\": {\"effect\": 0.19456165960848582, \"value\": -1.6932632765934557}, \"4\": {\"effect\": 0.0397436713794366, \"value\": 1.0}, \"5\": {\"effect\": 0.0002501352347105876, \"value\": 1.0}, \"6\": {\"effect\": 0.03926748114494694, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12090911332731602, \"value\": 1.0}, \"8\": {\"effect\": -0.12298620322434499, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21571472536421643, \"value\": 0.0}, \"11\": {\"effect\": 0.5798731441252535, \"value\": 5.0}, \"12\": {\"effect\": -0.14618507965160477, \"value\": 1.5171546673445446}, \"13\": {\"effect\": 0.22544902485013343, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.008219056813558626, \"value\": 0.0}, \"15\": {\"effect\": -0.7569931403325728, \"value\": 1.0}, \"16\": {\"effect\": 0.24889583577391694, \"value\": 0.5185259653237886}, \"17\": {\"effect\": 0.09010444189707668, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.013319907344836237, \"value\": 1.0}, \"19\": {\"effect\": -0.30739227095308924, \"value\": 0.0}, \"20\": {\"effect\": 0.007247859560114349, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.035460934432718985, \"value\": 0.5185259653237886}, \"22\": {\"effect\": 0.02286313663177746, \"value\": 0.009142919838652}, \"23\": {\"effect\": 0.2634178403633174, \"value\": 51.40918652308189}, \"24\": {\"effect\": 0.06154689206727385, \"value\": 5.0}, \"25\": {\"effect\": 0.02067631561572561, \"value\": 5.0}, \"26\": {\"effect\": -0.49136583085887686, \"value\": -0.2328771551289525}, \"27\": {\"effect\": 0.023015524866459754, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.0034659922070119594, \"value\": -0.6580259107613199}, \"29\": {\"effect\": -0.07779110691484159, \"value\": 1.5259510402799736}, \"30\": {\"effect\": 0.10256366301467021, \"value\": 0.7520707177520078}, \"31\": {\"effect\": -0.4879093142880233, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.027861386253170386, \"value\": -1.6932632765934557}, \"33\": {\"effect\": -0.152304215584171, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0024565507825360018, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.14458671906317688, \"value\": 0.2016459983773806}, \"36\": {\"effect\": -0.027069843185992582, \"value\": 1.5171546673445446}, \"37\": {\"effect\": 0.01819382829075908, \"value\": 0.0}, \"38\": {\"effect\": 0.001942994969779262, \"value\": 0.0}, \"39\": {\"effect\": -0.03828181522833634, \"value\": 1.0}}}, {\"outValue\": 3.744428824379186, \"simIndex\": 29.0, \"features\": {\"0\": {\"effect\": 0.49111132668317226, \"value\": 1.0}, \"1\": {\"effect\": 0.29118079380556205, \"value\": 0.0}, \"2\": {\"effect\": 0.03893961341674017, \"value\": 1.0}, \"3\": {\"effect\": 0.10550745651478817, \"value\": 0.0001493216786865}, \"4\": {\"effect\": 0.02734012588750208, \"value\": 1.0}, \"5\": {\"effect\": 0.0006536990141590035, \"value\": 1.0}, \"6\": {\"effect\": -0.021720441151557232, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09737455777103733, \"value\": 1.0}, \"8\": {\"effect\": -0.038453510932320745, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2121176191430642, \"value\": 0.0}, \"11\": {\"effect\": 0.2031461635493722, \"value\": 3.0}, \"12\": {\"effect\": 0.11117612911691735, \"value\": -1.085856588079425}, \"13\": {\"effect\": 0.0441192945190233, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.00873137154496035, \"value\": 0.0}, \"15\": {\"effect\": 0.2686562469869866, \"value\": 0.0}, \"16\": {\"effect\": -0.148073988716483, \"value\": 0.2457179970395381}, \"17\": {\"effect\": -0.4001051444691879, \"value\": 0.9}, \"18\": {\"effect\": -0.19332531848083198, \"value\": 0.0}, \"19\": {\"effect\": 0.2874370197123007, \"value\": 1.0}, \"20\": {\"effect\": -0.05189569794556261, \"value\": 0.9}, \"21\": {\"effect\": -0.029104006603415746, \"value\": 0.2457179970395381}, \"22\": {\"effect\": 0.2541281090516979, \"value\": 0.0252950701814086}, \"23\": {\"effect\": -0.24175246356234842, \"value\": -1.3617048675647152}, \"24\": {\"effect\": 0.05107177250136879, \"value\": 7.0}, \"25\": {\"effect\": 0.014051303513158362, \"value\": 3.0}, \"26\": {\"effect\": -0.39050601016337977, \"value\": -0.4591047241422481}, \"27\": {\"effect\": -0.0008653737674054053, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.04528865928124424, \"value\": -0.1969288228443723}, \"29\": {\"effect\": 0.02586990869479909, \"value\": -0.998325770249054}, \"30\": {\"effect\": -0.20566633053532904, \"value\": -1.482682347048874}, \"31\": {\"effect\": 0.15760641140648413, \"value\": -0.3945864777926284}, \"32\": {\"effect\": 0.007820808086526257, \"value\": 0.0001493216786865}, \"33\": {\"effect\": 0.14334534528230813, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.002228119677458115, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.2619751787712468, \"value\": 0.3498625449969868}, \"36\": {\"effect\": -0.06381781579877974, \"value\": -1.085856588079425}, \"37\": {\"effect\": 0.028850179538568582, \"value\": 0.0}, \"38\": {\"effect\": 0.0008645936292309519, \"value\": 0.0}, \"39\": {\"effect\": 0.05668129141628234, \"value\": 2.0}}}, {\"outValue\": 3.9514707138152794, \"simIndex\": 36.0, \"features\": {\"0\": {\"effect\": -0.33748116395145045, \"value\": 0.0}, \"1\": {\"effect\": 0.3656189046746761, \"value\": 0.0}, \"2\": {\"effect\": 0.0372320536603787, \"value\": 1.0}, \"3\": {\"effect\": 0.03624210049663263, \"value\": -0.6456436183403508}, \"4\": {\"effect\": 0.034137382918684345, \"value\": 1.0}, \"5\": {\"effect\": -0.0002212833170391402, \"value\": 1.0}, \"6\": {\"effect\": 0.03164803627324444, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.3252630452243843, \"value\": 2.0}, \"8\": {\"effect\": -0.03353169071393581, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.20174574973700382, \"value\": 0.0}, \"11\": {\"effect\": 0.2694503641519403, \"value\": 2.0}, \"12\": {\"effect\": -0.09654426217977571, \"value\": 1.689229924199091}, \"13\": {\"effect\": 0.05523239885278831, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.009909139525025553, \"value\": 0.0}, \"15\": {\"effect\": 0.2923685095554946, \"value\": 0.0}, \"16\": {\"effect\": -0.1638572090587922, \"value\": 0.2367375134743228}, \"17\": {\"effect\": 0.24622318258702808, \"value\": 0.1}, \"18\": {\"effect\": 0.012696683928990727, \"value\": 1.0}, \"19\": {\"effect\": 0.27547730246853164, \"value\": 1.0}, \"20\": {\"effect\": 0.03013249880761616, \"value\": 0.1}, \"21\": {\"effect\": -0.008605440682548466, \"value\": 0.2367375134743228}, \"22\": {\"effect\": 0.2007311058103376, \"value\": 0.0238485145273115}, \"23\": {\"effect\": -0.2419674324512963, \"value\": -1.2228462797250872}, \"24\": {\"effect\": -0.07726016555343977, \"value\": 4.0}, \"25\": {\"effect\": 0.03634164854297023, \"value\": 2.0}, \"26\": {\"effect\": -0.3630884517050746, \"value\": -0.4930388594942424}, \"27\": {\"effect\": -0.00024711274515937346, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.004337081533545026, \"value\": -0.2071059758824562}, \"29\": {\"effect\": -0.0987603844282505, \"value\": 0.8991030004259764}, \"30\": {\"effect\": 0.13299277058563932, \"value\": 0.0087181634713361}, \"31\": {\"effect\": 0.07651894280626848, \"value\": -0.035598249591538}, \"32\": {\"effect\": 0.007384284950467198, \"value\": -0.6456436183403508}, \"33\": {\"effect\": 0.07931605157827998, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.0011243019526584355, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.059194874978612824, \"value\": -0.5760364994583359}, \"36\": {\"effect\": -0.028548521543436806, \"value\": 1.689229924199091}, \"37\": {\"effect\": 0.02296683119653244, \"value\": 0.0}, \"38\": {\"effect\": 0.003404399914167532, \"value\": 0.0}, \"39\": {\"effect\": 0.1643492530467822, \"value\": 2.0}}}, {\"outValue\": 2.6595061533696263, \"simIndex\": 7.0, \"features\": {\"0\": {\"effect\": -0.4548503568860817, \"value\": 0.0}, \"1\": {\"effect\": 0.26633818329877984, \"value\": 0.0}, \"2\": {\"effect\": -0.013902962671162606, \"value\": 0.0}, \"3\": {\"effect\": 0.06617799032451414, \"value\": -0.7030474352309318}, \"4\": {\"effect\": 0.015427528274834245, \"value\": 1.0}, \"5\": {\"effect\": 0.0008731526564420323, \"value\": 1.0}, \"6\": {\"effect\": 0.055675883243710735, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.7758256498515553, \"value\": 4.0}, \"8\": {\"effect\": 0.17630046533120378, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21359298312729866, \"value\": 0.0}, \"11\": {\"effect\": -1.0796272508409472, \"value\": 1.0}, \"12\": {\"effect\": 0.05017074735667641, \"value\": -0.5954918387771643}, \"13\": {\"effect\": 0.0590426552596116, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.007462044855400885, \"value\": 0.0}, \"15\": {\"effect\": 0.2832866359999665, \"value\": 0.0}, \"16\": {\"effect\": -0.23655287244862125, \"value\": 0.2198051685074796}, \"17\": {\"effect\": 0.2651725497147158, \"value\": 0.3}, \"18\": {\"effect\": 0.010293556655910096, \"value\": 1.0}, \"19\": {\"effect\": -0.24351691175355764, \"value\": 0.0}, \"20\": {\"effect\": 0.029967436620243582, \"value\": 0.3}, \"21\": {\"effect\": -0.0074180292214302, \"value\": 0.2198051685074796}, \"22\": {\"effect\": 0.2581189831950646, \"value\": 0.038785277333971}, \"23\": {\"effect\": -0.2058181396264913, \"value\": -1.1389610770169014}, \"24\": {\"effect\": 0.04989897252526768, \"value\": 7.0}, \"25\": {\"effect\": -0.11360552715333168, \"value\": 1.0}, \"26\": {\"effect\": -0.6070945643528419, \"value\": 0.1743324690949794}, \"27\": {\"effect\": 0.021603298990325606, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.03491658482114567, \"value\": -0.6722742045783877}, \"29\": {\"effect\": -0.018941854871304988, \"value\": -0.2725369192404879}, \"30\": {\"effect\": 0.1379369710414826, \"value\": -0.6087069762390762}, \"31\": {\"effect\": 0.1918393366769176, \"value\": 3.508594621557409}, \"32\": {\"effect\": 0.01159316866041719, \"value\": -0.7030474352309318}, \"33\": {\"effect\": 0.04779235460413975, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.0010115984538932882, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.11185940490340103, \"value\": -0.6930771914744531}, \"36\": {\"effect\": 0.015618691264826587, \"value\": -0.5954918387771643}, \"37\": {\"effect\": 0.018160070351984667, \"value\": 0.0}, \"38\": {\"effect\": 0.0032111674839336, \"value\": 0.0}, \"39\": {\"effect\": -0.022573657911700174, \"value\": 3.0}}}, {\"outValue\": 5.677340481889114, \"simIndex\": 85.0, \"features\": {\"0\": {\"effect\": -0.2418717843752105, \"value\": 0.0}, \"1\": {\"effect\": 0.3927658090927922, \"value\": 0.0}, \"2\": {\"effect\": -0.020452886071736415, \"value\": 0.0}, \"3\": {\"effect\": 0.17505955612715318, \"value\": -0.1290092663251209}, \"4\": {\"effect\": 0.03640185994003275, \"value\": 1.0}, \"5\": {\"effect\": 0.00032028312794768135, \"value\": 1.0}, \"6\": {\"effect\": 0.06870656389412219, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12135055176883895, \"value\": 1.0}, \"8\": {\"effect\": 0.1751598428036786, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.85125621657694, \"value\": 1.0}, \"11\": {\"effect\": 0.21878341238946844, \"value\": 3.0}, \"12\": {\"effect\": 0.041108439148043414, \"value\": -0.2672557996904581}, \"13\": {\"effect\": 0.04997341348093128, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.012158162755743341, \"value\": 0.0}, \"15\": {\"effect\": 0.28020475610811996, \"value\": 0.0}, \"16\": {\"effect\": -0.23618936766043935, \"value\": 0.207584200764263}, \"17\": {\"effect\": 0.12401317474843886, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.016179064261691512, \"value\": 1.0}, \"19\": {\"effect\": 0.2743744748053973, \"value\": 1.0}, \"20\": {\"effect\": -4.810422596963112e-05, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.02203469482260756, \"value\": 0.207584200764263}, \"22\": {\"effect\": -0.011249382131098431, \"value\": 0.015605598808693}, \"23\": {\"effect\": 0.3819471245351496, \"value\": 10.961761672491374}, \"24\": {\"effect\": 0.04310477761757534, \"value\": 6.0}, \"25\": {\"effect\": 0.0309622816562504, \"value\": 3.0}, \"26\": {\"effect\": 0.04897633135233953, \"value\": -0.5495957517475664}, \"27\": {\"effect\": -0.00022192929002849536, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0322480126764108, \"value\": 0.6341739535559496}, \"29\": {\"effect\": -0.05576150095516201, \"value\": 0.3539359763818452}, \"30\": {\"effect\": 0.17618998678622524, \"value\": -0.4703895986064898}, \"31\": {\"effect\": -0.14904087222806656, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.006433678406499615, \"value\": -0.1290092663251209}, \"33\": {\"effect\": 0.11180890199902031, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0019730623874850525, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.010796119582810336, \"value\": -0.2156481959082472}, \"36\": {\"effect\": 0.009589916501014581, \"value\": -0.2672557996904581}, \"37\": {\"effect\": 0.019828323239353456, \"value\": 0.0}, \"38\": {\"effect\": 0.0018472826087173161, \"value\": 0.0}, \"39\": {\"effect\": 0.09646057034371155, \"value\": 2.0}}}, {\"outValue\": 3.2042859961704204, \"simIndex\": 2.0, \"features\": {\"0\": {\"effect\": 0.4656333863648692, \"value\": 1.0}, \"1\": {\"effect\": 0.38558271961916213, \"value\": 0.0}, \"2\": {\"effect\": -0.21625729163738228, \"value\": 1.0}, \"3\": {\"effect\": -0.023258962114490214, \"value\": 0.3015193603542372}, \"4\": {\"effect\": 0.03781605710607073, \"value\": 1.0}, \"5\": {\"effect\": 0.00035921070777045086, \"value\": 1.0}, \"6\": {\"effect\": 0.03599525898837635, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.18437534882846845, \"value\": 2.0}, \"8\": {\"effect\": -0.0814172307562758, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.6262918950782181, \"value\": 1.0}, \"11\": {\"effect\": -0.8860086602056096, \"value\": 1.0}, \"12\": {\"effect\": 0.05616720840034127, \"value\": -0.3756731580554611}, \"13\": {\"effect\": 0.13271530441832605, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.009117349034303834, \"value\": 0.0}, \"15\": {\"effect\": 0.26756575809787386, \"value\": 0.0}, \"16\": {\"effect\": 0.23895392127623255, \"value\": 0.9960355006330058}, \"17\": {\"effect\": 0.10662398225410326, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.03539616306571265, \"value\": 1.0}, \"19\": {\"effect\": -0.35694697850010515, \"value\": 0.0}, \"20\": {\"effect\": -0.0006417740009344101, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.01583846694319935, \"value\": 0.9960355006330058}, \"22\": {\"effect\": -0.004389449425790666, \"value\": 0.0063754197168118}, \"23\": {\"effect\": -0.013576995066703033, \"value\": -0.5625651631618891}, \"24\": {\"effect\": -0.25933996629694506, \"value\": 31.0}, \"25\": {\"effect\": -0.1367116614233369, \"value\": 1.0}, \"26\": {\"effect\": -0.5740610172306578, \"value\": 0.5136738226149228}, \"27\": {\"effect\": -0.000837054034925587, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.10261871418115294, \"value\": 1.2685570047491672}, \"29\": {\"effect\": -0.015761812456267548, \"value\": -0.0697467373509096}, \"30\": {\"effect\": 0.05462139674966976, \"value\": -0.020013983730829}, \"31\": {\"effect\": 0.050321401710366996, \"value\": -0.3140860872263233}, \"32\": {\"effect\": -0.004070503464358819, \"value\": 0.3015193603542372}, \"33\": {\"effect\": 0.09766789748575364, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0005975731820919034, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.02138761303421174, \"value\": -0.2361290772280217}, \"36\": {\"effect\": 0.013293916904802743, \"value\": -0.3756731580554611}, \"37\": {\"effect\": 0.01729665910677008, \"value\": 0.0}, \"38\": {\"effect\": 0.002007238480552459, \"value\": 0.0}, \"39\": {\"effect\": 0.11313215831007808, \"value\": 2.0}}}, {\"outValue\": 3.137607307697348, \"simIndex\": 35.0, \"features\": {\"0\": {\"effect\": -0.2888704868407239, \"value\": 0.0}, \"1\": {\"effect\": 0.37282340753283827, \"value\": 0.0}, \"2\": {\"effect\": -0.012392535605661283, \"value\": 0.0}, \"3\": {\"effect\": 0.05056964825013313, \"value\": -0.4734321676686074}, \"4\": {\"effect\": 0.03336787707805708, \"value\": 1.0}, \"5\": {\"effect\": 0.002005666482480887, \"value\": 1.0}, \"6\": {\"effect\": 0.02582153205976324, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.17315894197224962, \"value\": 1.0}, \"8\": {\"effect\": 0.22846723601462365, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.24624340933799924, \"value\": 0.0}, \"11\": {\"effect\": 0.2418188727349222, \"value\": 3.0}, \"12\": {\"effect\": -0.06403386189252329, \"value\": 1.5579355085644082}, \"13\": {\"effect\": 0.04312333396108698, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.009418686073743817, \"value\": 0.0}, \"15\": {\"effect\": 0.3159133236230687, \"value\": 0.0}, \"16\": {\"effect\": -0.16945557037912592, \"value\": 0.2358480576693369}, \"17\": {\"effect\": -0.05953244802502428, \"value\": 0.8}, \"18\": {\"effect\": 0.02494478682168161, \"value\": 1.0}, \"19\": {\"effect\": 0.2703019166893704, \"value\": 1.0}, \"20\": {\"effect\": -0.015619632264804189, \"value\": 0.8}, \"21\": {\"effect\": -0.011796709699385828, \"value\": 0.2358480576693369}, \"22\": {\"effect\": -0.043987868478102335, \"value\": 0.0105795406477229}, \"23\": {\"effect\": -0.24335213444636888, \"value\": -1.5599453563318753}, \"24\": {\"effect\": 0.10794540166376937, \"value\": 13.0}, \"25\": {\"effect\": 0.03220292735807389, \"value\": 3.0}, \"26\": {\"effect\": -0.06653490407750172, \"value\": -0.5722185086488959}, \"27\": {\"effect\": 0.0017280020105973975, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.05306385617807284, \"value\": 1.0976247146913525}, \"29\": {\"effect\": 0.07514683548629612, \"value\": -0.2746072325378001}, \"30\": {\"effect\": -0.28744631982707963, \"value\": 1.994694663559877}, \"31\": {\"effect\": -0.21514014196002343, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.032252659658852885, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.12902162368379966, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.001944823963974677, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09987071261377493, \"value\": -0.7232988069805538}, \"36\": {\"effect\": -0.005664052287319872, \"value\": 1.5579355085644082}, \"37\": {\"effect\": 0.044951147530294014, \"value\": 0.0}, \"38\": {\"effect\": 0.0010419032670672518, \"value\": 0.0}, \"39\": {\"effect\": 0.037791674593013434, \"value\": 1.0}}}, {\"outValue\": 3.451094499736027, \"simIndex\": 96.0, \"features\": {\"0\": {\"effect\": 0.4052160665668186, \"value\": 1.0}, \"1\": {\"effect\": -0.2988781647584407, \"value\": 1.0}, \"2\": {\"effect\": 0.018431456402137347, \"value\": 1.0}, \"3\": {\"effect\": 0.18089422492156793, \"value\": -0.3729754881100905}, \"4\": {\"effect\": 0.039588780257145705, \"value\": 1.0}, \"5\": {\"effect\": 0.0009228419247207273, \"value\": 1.0}, \"6\": {\"effect\": 0.04187074565203118, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2601252721214879, \"value\": 2.0}, \"8\": {\"effect\": -0.04320412337506419, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7887701952960138, \"value\": 1.0}, \"11\": {\"effect\": 0.17630104876639768, \"value\": 3.0}, \"12\": {\"effect\": 0.07628835084795821, \"value\": -0.3925822873417459}, \"13\": {\"effect\": 0.061698700480670526, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.011685154361426168, \"value\": 0.0}, \"15\": {\"effect\": 0.17898161978469204, \"value\": 0.0}, \"16\": {\"effect\": -0.2693408312436513, \"value\": 0.2814096278091333}, \"17\": {\"effect\": -0.4411833275170662, \"value\": 0.9}, \"18\": {\"effect\": -0.15669917504580916, \"value\": 0.0}, \"19\": {\"effect\": 0.25148577012892237, \"value\": 1.0}, \"20\": {\"effect\": -0.040520381537849655, \"value\": 0.9}, \"21\": {\"effect\": -0.02685750946483518, \"value\": 0.2814096278091333}, \"22\": {\"effect\": 0.027376942740874217, \"value\": 0.0184864614604537}, \"23\": {\"effect\": -0.14890400954561825, \"value\": -0.9979067238215336}, \"24\": {\"effect\": 0.08042460157232242, \"value\": 7.0}, \"25\": {\"effect\": 0.019906016115682053, \"value\": 3.0}, \"26\": {\"effect\": -0.6172340528502492, \"value\": 0.095152819940326}, \"27\": {\"effect\": -0.0037070575387536907, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0042050487901171925, \"value\": -1.573032859936922}, \"29\": {\"effect\": -0.06695521056119304, \"value\": 0.3982780924728248}, \"30\": {\"effect\": -0.15170024196816417, \"value\": -0.7036709555824625}, \"31\": {\"effect\": 0.06992415992092557, \"value\": -0.361951184319802}, \"32\": {\"effect\": 0.01617352852742493, \"value\": -0.3729754881100905}, \"33\": {\"effect\": 0.06226957890831836, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.007377538384963018, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.06285758045929543, \"value\": -0.5341016278719797}, \"36\": {\"effect\": 0.016996800085207542, \"value\": -0.3925822873417459}, \"37\": {\"effect\": 0.03495835102718805, \"value\": 0.0}, \"38\": {\"effect\": 0.0011058195621599766, \"value\": 0.0}, \"39\": {\"effect\": 0.0431414682170476, \"value\": 2.0}}}, {\"outValue\": 5.100323757163147, \"simIndex\": 63.0, \"features\": {\"0\": {\"effect\": -0.27604655134589057, \"value\": 0.0}, \"1\": {\"effect\": 0.38361282485686105, \"value\": 0.0}, \"2\": {\"effect\": -0.029750489964840345, \"value\": 0.0}, \"3\": {\"effect\": 0.06813113794242708, \"value\": -1.1048741534649995}, \"4\": {\"effect\": 0.031131503097677156, \"value\": 1.0}, \"5\": {\"effect\": 0.0003939578385208073, \"value\": 1.0}, \"6\": {\"effect\": 0.04080937248038588, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11653131004301424, \"value\": 1.0}, \"8\": {\"effect\": 0.20582300181106306, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.192594591906587, \"value\": 0.0}, \"11\": {\"effect\": 0.31072877459007625, \"value\": 2.0}, \"12\": {\"effect\": -0.2683295519357796, \"value\": 0.6150028871880522}, \"13\": {\"effect\": 0.1988114351773802, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.006614383710897022, \"value\": 0.0}, \"15\": {\"effect\": 0.2931860875612099, \"value\": 0.0}, \"16\": {\"effect\": 0.18830400023833824, \"value\": 0.7496201246436558}, \"17\": {\"effect\": 0.15867754856517632, \"value\": 0.3}, \"18\": {\"effect\": -0.04732531429699951, \"value\": 0.0}, \"19\": {\"effect\": 0.2500194626441798, \"value\": 1.0}, \"20\": {\"effect\": 0.07160255895546083, \"value\": 0.3}, \"21\": {\"effect\": 0.029386464157365524, \"value\": 0.7496201246436558}, \"22\": {\"effect\": -0.1683597139237528, \"value\": 7.486059015267934}, \"23\": {\"effect\": -0.04325915320195018, \"value\": -0.904860461188404}, \"24\": {\"effect\": 0.10499344061448435, \"value\": 13.0}, \"25\": {\"effect\": 0.031109105314845814, \"value\": 2.0}, \"26\": {\"effect\": 1.033184413310035, \"value\": -0.8663143483661802}, \"27\": {\"effect\": 0.005232904097862089, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.07456818213362018, \"value\": -0.9236426063415026}, \"29\": {\"effect\": 0.025067778585806107, \"value\": 0.0033490954805646}, \"30\": {\"effect\": 0.08559978617342019, \"value\": 0.7500986386270642}, \"31\": {\"effect\": -0.2333006027152417, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.015398866833250063, \"value\": -1.1048741534649995}, \"33\": {\"effect\": -0.007916818449709819, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0019032357637596155, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.21224147185043188, \"value\": 0.2637175924365599}, \"36\": {\"effect\": -0.07155108559581506, \"value\": 0.6150028871880522}, \"37\": {\"effect\": 0.025167986391124022, \"value\": 0.0}, \"38\": {\"effect\": 0.0007553921186042639, \"value\": 0.0}, \"39\": {\"effect\": -0.05945595382232536, \"value\": 1.0}}}, {\"outValue\": 3.1273546970357247, \"simIndex\": 22.0, \"features\": {\"0\": {\"effect\": 0.6183839287059378, \"value\": 1.0}, \"1\": {\"effect\": 0.3448706630836929, \"value\": 0.0}, \"2\": {\"effect\": 0.03345025956829421, \"value\": 1.0}, \"3\": {\"effect\": 0.13163895827186128, \"value\": -0.4447302592233169}, \"4\": {\"effect\": 0.03960810483481034, \"value\": 1.0}, \"5\": {\"effect\": 0.0010150450073484175, \"value\": 1.0}, \"6\": {\"effect\": 0.04850806011329166, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12067238428454673, \"value\": 1.0}, \"8\": {\"effect\": -0.08952486253745782, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.20163654229298916, \"value\": 0.0}, \"11\": {\"effect\": 0.4688248672320711, \"value\": 5.0}, \"12\": {\"effect\": 0.06543984387039178, \"value\": -0.2901328569601376}, \"13\": {\"effect\": 0.1388377616803141, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.01865360818696895, \"value\": 0.0}, \"15\": {\"effect\": 0.25202813871883295, \"value\": 0.0}, \"16\": {\"effect\": -0.4355152457959152, \"value\": 0.153754379736744}, \"17\": {\"effect\": 0.10174095291875253, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.06895719058957168, \"value\": 1.0}, \"19\": {\"effect\": -0.3315934426554007, \"value\": 0.0}, \"20\": {\"effect\": -0.0002012321627300375, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.040711295925804115, \"value\": 0.153754379736744}, \"22\": {\"effect\": 0.061139988454822, \"value\": 0.0076284236411141}, \"23\": {\"effect\": -0.1959051278686942, \"value\": -1.1552254298079605}, \"24\": {\"effect\": 0.021837909427050183, \"value\": 10.0}, \"25\": {\"effect\": 0.012291707357852157, \"value\": 5.0}, \"26\": {\"effect\": -0.10089445711696465, \"value\": 0.7512127700788831}, \"27\": {\"effect\": 0.008385844630744635, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.023135871782808334, \"value\": 0.3802047432886652}, \"29\": {\"effect\": -0.06298131424593735, \"value\": 0.1563581062758069}, \"30\": {\"effect\": 0.12719292850322605, \"value\": 0.3827972232978841}, \"31\": {\"effect\": -0.04614714869689163, \"value\": -0.3641268705513238}, \"32\": {\"effect\": 0.011039989036728103, \"value\": -0.4447302592233169}, \"33\": {\"effect\": -0.6205841231661745, \"value\": 1.5813241721969604}, \"34\": {\"effect\": -0.00944431846928356, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.11038988142449921, \"value\": -0.4958037814224769}, \"36\": {\"effect\": 0.02728096540788559, \"value\": -0.2901328569601376}, \"37\": {\"effect\": 0.02623217997609724, \"value\": 0.0}, \"38\": {\"effect\": 0.0011609634273629633, \"value\": 0.0}, \"39\": {\"effect\": -0.023254095360117723, \"value\": 1.0}}}, {\"outValue\": 1.330656945340025, \"simIndex\": 33.0, \"features\": {\"0\": {\"effect\": -0.3797397442809352, \"value\": 0.0}, \"1\": {\"effect\": 0.33119175075961593, \"value\": 0.0}, \"2\": {\"effect\": 0.035234773254974636, \"value\": 1.0}, \"3\": {\"effect\": 0.05225056821665134, \"value\": -0.6312926641177055}, \"4\": {\"effect\": 0.027965951194420646, \"value\": 1.0}, \"5\": {\"effect\": -0.00017682492764153703, \"value\": 1.0}, \"6\": {\"effect\": 0.04973385291046335, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.1241834730168758, \"value\": 1.0}, \"8\": {\"effect\": -0.05277873287112619, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2543260338531019, \"value\": 0.0}, \"11\": {\"effect\": 0.2704522204321349, \"value\": 2.0}, \"12\": {\"effect\": 0.07869457628639037, \"value\": -0.3945715966695441}, \"13\": {\"effect\": 0.04943308265087798, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01102529801497871, \"value\": 0.0}, \"15\": {\"effect\": 0.27366988413185633, \"value\": 0.0}, \"16\": {\"effect\": -0.5145516745954325, \"value\": 0.0657063291874649}, \"17\": {\"effect\": -0.5655702399931892, \"value\": 0.9}, \"18\": {\"effect\": 0.01245916868892871, \"value\": 1.0}, \"19\": {\"effect\": -0.3042083393032719, \"value\": 0.0}, \"20\": {\"effect\": -0.06874010059341831, \"value\": 0.9}, \"21\": {\"effect\": -0.03954096135459839, \"value\": 0.0657063291874649}, \"22\": {\"effect\": 0.0177588855841514, \"value\": 0.0150663426552952}, \"23\": {\"effect\": -0.15678824146961254, \"value\": -0.8998996930614878}, \"24\": {\"effect\": 0.07748909819972968, \"value\": 15.0}, \"25\": {\"effect\": 0.03953391356306888, \"value\": 2.0}, \"26\": {\"effect\": -0.5853078724884109, \"value\": -0.312056804283606}, \"27\": {\"effect\": 0.0005198147691622539, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.05791756965166149, \"value\": -0.8247228699094711}, \"29\": {\"effect\": -0.03122876552532068, \"value\": 1.6416079520855889}, \"30\": {\"effect\": 0.13803429472026577, \"value\": 0.0979961663942158}, \"31\": {\"effect\": 0.036626310388458656, \"value\": -0.3837080466350197}, \"32\": {\"effect\": 0.004802420623043695, \"value\": -0.6312926641177055}, \"33\": {\"effect\": -0.11542984627385443, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.0074052615296908795, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10791376845205806, \"value\": -0.4334828104224658}, \"36\": {\"effect\": 0.021072882857084505, \"value\": -0.3945715966695441}, \"37\": {\"effect\": 0.024318227956940188, \"value\": 0.0}, \"38\": {\"effect\": 0.0033825972518272923, \"value\": 0.0}, \"39\": {\"effect\": 0.0987429788844638, \"value\": 2.0}}}, {\"outValue\": 3.1050462525149847, \"simIndex\": 37.0, \"features\": {\"0\": {\"effect\": -0.35733030110787534, \"value\": 0.0}, \"1\": {\"effect\": 0.38479600388817253, \"value\": 0.0}, \"2\": {\"effect\": 0.023830271413213745, \"value\": 1.0}, \"3\": {\"effect\": 0.17294071660468247, \"value\": -0.2438169001062831}, \"4\": {\"effect\": 0.03407499876165951, \"value\": 1.0}, \"5\": {\"effect\": 0.001811591719152533, \"value\": 1.0}, \"6\": {\"effect\": -0.006772991647883652, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.26124736803763304, \"value\": 2.0}, \"8\": {\"effect\": -0.0678693950386527, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.20416649240935633, \"value\": 0.0}, \"11\": {\"effect\": 0.5343899746264847, \"value\": 5.0}, \"12\": {\"effect\": -0.1753246516404371, \"value\": 2.782355399824212}, \"13\": {\"effect\": 0.07781617986150267, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.007925763886217263, \"value\": 0.0}, \"15\": {\"effect\": 0.25840402249984734, \"value\": 0.0}, \"16\": {\"effect\": -0.3249531946722099, \"value\": 0.2000865281438929}, \"17\": {\"effect\": 0.1331772931562072, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.021216580298543494, \"value\": 1.0}, \"19\": {\"effect\": 0.31354837252102563, \"value\": 1.0}, \"20\": {\"effect\": 0.013134034213742098, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.007780511410849807, \"value\": 0.2000865281438929}, \"22\": {\"effect\": 0.006186595935197224, \"value\": 0.008723130333755}, \"23\": {\"effect\": -0.04949793298034561, \"value\": -0.8403255387099654}, \"24\": {\"effect\": 0.0905142025144276, \"value\": 14.0}, \"25\": {\"effect\": 0.03455462087492994, \"value\": 5.0}, \"26\": {\"effect\": -0.6722628842841281, \"value\": 0.2422007397989681}, \"27\": {\"effect\": 0.0009238712785687608, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.03025537895167153, \"value\": -0.4242432627811128}, \"29\": {\"effect\": -0.07406675274575987, \"value\": 0.2150558160978708}, \"30\": {\"effect\": -0.18955768049461028, \"value\": 1.6846213834143553}, \"31\": {\"effect\": -0.1138400022280212, \"value\": 3.417215799833495}, \"32\": {\"effect\": 0.013233937630615193, \"value\": -0.2438169001062831}, \"33\": {\"effect\": 0.08434157859520953, \"value\": -0.5644447670603625}, \"34\": {\"effect\": -1.551128426248861e-05, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.11373110599914986, \"value\": -0.4762974766720713}, \"36\": {\"effect\": -0.027063274661731525, \"value\": 2.782355399824212}, \"37\": {\"effect\": 0.027706721176823036, \"value\": 0.0}, \"38\": {\"effect\": 0.003108458238968229, \"value\": 0.0}, \"39\": {\"effect\": 0.04871421661773199, \"value\": 1.0}}}, {\"outValue\": 4.742433344422593, \"simIndex\": 28.0, \"features\": {\"0\": {\"effect\": 0.44161896243458704, \"value\": 1.0}, \"1\": {\"effect\": 0.31250796022183847, \"value\": 0.0}, \"2\": {\"effect\": 0.0326320748447743, \"value\": 1.0}, \"3\": {\"effect\": 0.49042789871745235, \"value\": -2.0950899948275232}, \"4\": {\"effect\": 0.04199033965727228, \"value\": 1.0}, \"5\": {\"effect\": -0.00033378889203939836, \"value\": 1.0}, \"6\": {\"effect\": 0.035895908413560065, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10055375282197151, \"value\": 1.0}, \"8\": {\"effect\": -0.07117493483791523, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.231800008479754, \"value\": 0.0}, \"11\": {\"effect\": 0.15130769944682568, \"value\": 3.0}, \"12\": {\"effect\": -0.2537151114730567, \"value\": 0.3195904520100166}, \"13\": {\"effect\": 0.12128639437301386, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.010462945421971985, \"value\": 0.0}, \"15\": {\"effect\": 0.28257479299979643, \"value\": 0.0}, \"16\": {\"effect\": 0.3470985217002309, \"value\": 0.9003346540356256}, \"17\": {\"effect\": 0.18745485730139252, \"value\": 0.2}, \"18\": {\"effect\": 0.04084540857620113, \"value\": 1.0}, \"19\": {\"effect\": 0.2887430297374908, \"value\": 1.0}, \"20\": {\"effect\": 0.06324744164458633, \"value\": 0.2}, \"21\": {\"effect\": 0.02882383230255615, \"value\": 0.9003346540356256}, \"22\": {\"effect\": -0.18172331504530478, \"value\": 15.970416979977465}, \"23\": {\"effect\": 0.12905334997166676, \"value\": 32.60600133487275}, \"24\": {\"effect\": 0.008133863897712637, \"value\": 7.0}, \"25\": {\"effect\": 0.026504899231504314, \"value\": 3.0}, \"26\": {\"effect\": -0.6765359653407204, \"value\": -0.2441885335796173}, \"27\": {\"effect\": 0.0027659622812681865, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.019770987230459246, \"value\": -0.5889210887132186}, \"29\": {\"effect\": 0.10874010196498722, \"value\": 1.7809694988143827}, \"30\": {\"effect\": 0.1181272662008833, \"value\": 0.7711248280880857}, \"31\": {\"effect\": -0.13206863797671564, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.06523374356433886, \"value\": -2.0950899948275232}, \"33\": {\"effect\": 0.20226691194144272, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.0008396515815429955, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.008045099493302378, \"value\": -0.225396153699623}, \"36\": {\"effect\": -0.05196041099602769, \"value\": 0.3195904520100166}, \"37\": {\"effect\": 0.02480965224095103, \"value\": 0.0}, \"38\": {\"effect\": 0.001980364299568056, \"value\": 0.0}, \"39\": {\"effect\": -0.046226634238506266, \"value\": 1.0}}}, {\"outValue\": 3.930299041924105, \"simIndex\": 70.0, \"features\": {\"0\": {\"effect\": -0.26917980252562335, \"value\": 0.0}, \"1\": {\"effect\": -0.2781133996732204, \"value\": 1.0}, \"2\": {\"effect\": -0.024631351436572232, \"value\": 0.0}, \"3\": {\"effect\": 0.06820514091424545, \"value\": -0.9900665196838372}, \"4\": {\"effect\": 0.03497484047153725, \"value\": 1.0}, \"5\": {\"effect\": 0.00038042157290622917, \"value\": 1.0}, \"6\": {\"effect\": 0.02543771933193422, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.13625359249150656, \"value\": 1.0}, \"8\": {\"effect\": 0.13366586561545568, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2181142761774832, \"value\": 0.0}, \"11\": {\"effect\": 0.26637973186833014, \"value\": 2.0}, \"12\": {\"effect\": -0.23466519930444507, \"value\": 0.767185050764616}, \"13\": {\"effect\": 0.031850978307862036, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.008511650136331497, \"value\": 0.0}, \"15\": {\"effect\": 0.2860835136298505, \"value\": 0.0}, \"16\": {\"effect\": 0.21174255490623795, \"value\": 0.7474859016020629}, \"17\": {\"effect\": 0.2187309799100652, \"value\": 0.1}, \"18\": {\"effect\": 0.016528331391255886, \"value\": 1.0}, \"19\": {\"effect\": 0.3358238828916323, \"value\": 1.0}, \"20\": {\"effect\": 0.056097322860910306, \"value\": 0.1}, \"21\": {\"effect\": 0.029875901717385935, \"value\": 0.7474859016020629}, \"22\": {\"effect\": 0.10232675050662242, \"value\": 0.0224154686109596}, \"23\": {\"effect\": 0.04065228466911637, \"value\": -0.5909010049000778}, \"24\": {\"effect\": 0.10507111898173425, \"value\": 21.0}, \"25\": {\"effect\": 0.04488732375044695, \"value\": 2.0}, \"26\": {\"effect\": 0.0709319895073868, \"value\": -0.5609071301982311}, \"27\": {\"effect\": -0.006222823706839592, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.03461723431198303, \"value\": 0.2208159082669271}, \"29\": {\"effect\": 0.0532684402326602, \"value\": -0.3680086799100812}, \"30\": {\"effect\": 0.0330249173269318, \"value\": 0.9635836267353636}, \"31\": {\"effect\": -0.238795904192347, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.015363003899004891, \"value\": -0.9900665196838372}, \"33\": {\"effect\": -0.000807956899978117, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.003641467330400193, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.15480516087828214, \"value\": 0.3594479959811}, \"36\": {\"effect\": -0.04433187457259935, \"value\": 0.767185050764616}, \"37\": {\"effect\": 0.025118371596101925, \"value\": 0.0}, \"38\": {\"effect\": 0.001849622264350563, \"value\": 0.0}, \"39\": {\"effect\": 0.060142520305727, \"value\": 1.0}}}, {\"outValue\": 1.9044114760917015, \"simIndex\": 6.0, \"features\": {\"0\": {\"effect\": -0.4005070742146086, \"value\": 0.0}, \"1\": {\"effect\": 0.42147045899491375, \"value\": 0.0}, \"2\": {\"effect\": 0.012461812973748312, \"value\": 0.0}, \"3\": {\"effect\": -0.03836715765009012, \"value\": 1.0621199341544367}, \"4\": {\"effect\": 0.03497977881460713, \"value\": 1.0}, \"5\": {\"effect\": 0.001929458569018782, \"value\": 1.0}, \"6\": {\"effect\": -0.046449630383647154, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.14884458777067128, \"value\": 1.0}, \"8\": {\"effect\": 0.23105128499816405, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.19796936950518332, \"value\": 0.0}, \"11\": {\"effect\": -0.9835566405722368, \"value\": 1.0}, \"12\": {\"effect\": -0.18021353741993992, \"value\": 1.4435502222160106}, \"13\": {\"effect\": 0.03056234916235697, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.006369142431276122, \"value\": 0.0}, \"15\": {\"effect\": 0.3668882318636123, \"value\": 0.0}, \"16\": {\"effect\": -0.3008539072718277, \"value\": 0.1849774831565682}, \"17\": {\"effect\": 0.13992638191402362, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.012810633286388382, \"value\": 1.0}, \"19\": {\"effect\": 0.28174130784988066, \"value\": 1.0}, \"20\": {\"effect\": -0.009217610482960464, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.06327409435929598, \"value\": 0.1849774831565682}, \"22\": {\"effect\": -0.04906877899732291, \"value\": 0.0073156162514227}, \"23\": {\"effect\": 0.4291929923869599, \"value\": 37.240431915681626}, \"24\": {\"effect\": 0.043939711718222516, \"value\": 8.0}, \"25\": {\"effect\": -0.13106687367393613, \"value\": 1.0}, \"26\": {\"effect\": -0.6319105902974405, \"value\": -0.1197633706223047}, \"27\": {\"effect\": 0.005807936183846734, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.037312387520834246, \"value\": 1.1644849611143349}, \"29\": {\"effect\": 0.018700755265957634, \"value\": -0.1706537305201994}, \"30\": {\"effect\": 0.1719249253979529, \"value\": 0.0778038021963255}, \"31\": {\"effect\": -0.17630199190627374, \"value\": -0.3967621640241502}, \"32\": {\"effect\": -0.020946655618307105, \"value\": 1.0621199341544367}, \"33\": {\"effect\": 0.13836371165112202, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.002534874560588754, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.0821944858072411, \"value\": -0.4620596339246541}, \"36\": {\"effect\": -0.01465334971679117, \"value\": 1.4435502222160106}, \"37\": {\"effect\": 0.02248589694629406, \"value\": 0.0}, \"38\": {\"effect\": 0.0018457391370826498, \"value\": 0.0}, \"39\": {\"effect\": 0.13577638245743875, \"value\": 2.0}}}, {\"outValue\": 5.40261244092758, \"simIndex\": 64.0, \"features\": {\"0\": {\"effect\": 0.6203571124095024, \"value\": 1.0}, \"1\": {\"effect\": 0.35780344092510274, \"value\": 0.0}, \"2\": {\"effect\": -0.05713426390552236, \"value\": 0.0}, \"3\": {\"effect\": -0.10842384028535536, \"value\": 0.6746441701430143}, \"4\": {\"effect\": 0.03491113102491372, \"value\": 1.0}, \"5\": {\"effect\": 0.0020044385460170726, \"value\": 1.0}, \"6\": {\"effect\": 0.0009074838245779128, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.08619420417745963, \"value\": 1.0}, \"8\": {\"effect\": -0.07979435308337622, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.24531367438097715, \"value\": 0.0}, \"11\": {\"effect\": 0.13328192266708513, \"value\": 3.0}, \"12\": {\"effect\": -0.24684633767489994, \"value\": 0.5324465500844261}, \"13\": {\"effect\": 0.07006342037008507, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.012759238799447473, \"value\": 0.0}, \"15\": {\"effect\": 0.2505931636160596, \"value\": 0.0}, \"16\": {\"effect\": 0.2322622203743923, \"value\": 0.7758329122947942}, \"17\": {\"effect\": 0.11096059189714798, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.01959677104451675, \"value\": 1.0}, \"19\": {\"effect\": 0.24396458710936678, \"value\": 1.0}, \"20\": {\"effect\": 0.07075879274876078, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.044867892221096765, \"value\": 0.7758329122947942}, \"22\": {\"effect\": -0.05718307560767414, \"value\": 0.0059931653573817}, \"23\": {\"effect\": -0.16909093760029043, \"value\": -1.1883961829346164}, \"24\": {\"effect\": 0.02938410220327946, \"value\": 9.0}, \"25\": {\"effect\": 0.019042852274699745, \"value\": 3.0}, \"26\": {\"effect\": 1.1886112807799802, \"value\": -0.8550029699155153}, \"27\": {\"effect\": -0.0014669932757322274, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.022032104543075047, \"value\": -1.3814688789712135}, \"29\": {\"effect\": 0.11712441360284472, \"value\": -1.7032334136973943}, \"30\": {\"effect\": 0.21978963658824108, \"value\": -0.545987455207056}, \"31\": {\"effect\": 0.3326771020413144, \"value\": 0.1101727279204198}, \"32\": {\"effect\": -0.0008287228718929855, \"value\": 0.6746441701430143}, \"33\": {\"effect\": -0.006545228474755937, \"value\": 0.7560284263287593}, \"34\": {\"effect\": 0.0015853694934941038, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.0933091481904459, \"value\": -0.4123844900121388}, \"36\": {\"effect\": -0.08716341855480776, \"value\": 0.5324465500844261}, \"37\": {\"effect\": -0.2746090494176471, \"value\": 1.0}, \"38\": {\"effect\": 0.0020098397585876864, \"value\": 0.0}, \"39\": {\"effect\": -0.08819519316705239, \"value\": 3.0}}}, {\"outValue\": 2.926658546818506, \"simIndex\": 59.0, \"features\": {\"0\": {\"effect\": -0.3874515649205477, \"value\": 0.0}, \"1\": {\"effect\": 0.32212810335937536, \"value\": 0.0}, \"2\": {\"effect\": -0.07706654852721163, \"value\": 0.0}, \"3\": {\"effect\": -0.30809799194525045, \"value\": 1.7509657368414098}, \"4\": {\"effect\": 0.04055892110727391, \"value\": 1.0}, \"5\": {\"effect\": 0.00024257157672846942, \"value\": 1.0}, \"6\": {\"effect\": -0.1300298874280742, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.11867988744253091, \"value\": 1.0}, \"8\": {\"effect\": -0.08335345971793597, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2066758659721532, \"value\": 0.0}, \"11\": {\"effect\": 0.2118639661551915, \"value\": 3.0}, \"12\": {\"effect\": -0.22767256659458895, \"value\": 0.5085748381508475}, \"13\": {\"effect\": 0.03960390566762206, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.012154419156916845, \"value\": 0.0}, \"15\": {\"effect\": -0.7209064124857418, \"value\": 1.0}, \"16\": {\"effect\": 0.14182961297934105, \"value\": 0.8091895944048574}, \"17\": {\"effect\": 0.137140744730073, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.006473208740796245, \"value\": 1.0}, \"19\": {\"effect\": 0.32946965402621436, \"value\": 1.0}, \"20\": {\"effect\": 0.018551961149784045, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.006285083119427486, \"value\": 0.8091895944048574}, \"22\": {\"effect\": 0.003825792802234016, \"value\": 0.0098560308140484}, \"23\": {\"effect\": 0.35433454265099706, \"value\": 16.647705640888883}, \"24\": {\"effect\": 0.12881144810171555, \"value\": 14.0}, \"25\": {\"effect\": 0.02732282357688337, \"value\": 3.0}, \"26\": {\"effect\": 0.939809366730591, \"value\": -0.8889371052675097}, \"27\": {\"effect\": 0.0005204007882006801, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.1061969089455193, \"value\": -1.2263366888104512}, \"29\": {\"effect\": 0.12826026159230497, \"value\": -0.5451231089986989}, \"30\": {\"effect\": -0.1953976278699016, \"value\": 1.6260333041095136}, \"31\": {\"effect\": -0.27462888209289815, \"value\": -0.3989378502556719}, \"32\": {\"effect\": -0.037971103738495764, \"value\": 1.7509657368414098}, \"33\": {\"effect\": -0.04400601957750867, \"value\": 1.4162650230233202}, \"34\": {\"effect\": -0.009753854928329522, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.15012747418709024, \"value\": 1.112042033548979}, \"36\": {\"effect\": -0.01782894638967266, \"value\": 0.5085748381508475}, \"37\": {\"effect\": 0.018630850942359493, \"value\": 0.0}, \"38\": {\"effect\": 0.0018440723652504434, \"value\": 0.0}, \"39\": {\"effect\": -0.04626912569068106, \"value\": 1.0}}}, {\"outValue\": 0.9872448813555419, \"simIndex\": 15.0, \"features\": {\"0\": {\"effect\": -0.3374999633218294, \"value\": 0.0}, \"1\": {\"effect\": 0.2374626205463376, \"value\": 0.0}, \"2\": {\"effect\": -0.021729830727289394, \"value\": 0.0}, \"3\": {\"effect\": 0.19962024752539434, \"value\": -1.7793690019293271}, \"4\": {\"effect\": 0.03697448366062662, \"value\": 1.0}, \"5\": {\"effect\": -0.00040228754716160794, \"value\": 1.0}, \"6\": {\"effect\": 0.05887343001499257, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.023312917866397963, \"value\": 3.0}, \"8\": {\"effect\": -0.1494251094667811, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21870395280612817, \"value\": 0.0}, \"11\": {\"effect\": -0.892752229221089, \"value\": 1.0}, \"12\": {\"effect\": -0.21258189506818115, \"value\": 0.4190559183999275}, \"13\": {\"effect\": -0.3476403990199937, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.01069742597540165, \"value\": 0.0}, \"15\": {\"effect\": -0.5450808322093584, \"value\": 1.0}, \"16\": {\"effect\": 0.34763714920709105, \"value\": 0.8983855429393464}, \"17\": {\"effect\": 0.25088596897564064, \"value\": 0.2}, \"18\": {\"effect\": 0.013156090244735151, \"value\": 1.0}, \"19\": {\"effect\": -0.30071090477873264, \"value\": 0.0}, \"20\": {\"effect\": 0.05320003480442971, \"value\": 0.2}, \"21\": {\"effect\": 0.023913707375910913, \"value\": 0.8983855429393464}, \"22\": {\"effect\": 0.03201975023412438, \"value\": 0.0175660327593277}, \"23\": {\"effect\": 0.10200849445930191, \"value\": -0.222553037035036}, \"24\": {\"effect\": 0.015078578108664104, \"value\": 5.0}, \"25\": {\"effect\": -0.09298524794626345, \"value\": 1.0}, \"26\": {\"effect\": -0.256308897585697, \"value\": 2.052021291905332}, \"27\": {\"effect\": -0.0023952769103600903, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.07480030797468334, \"value\": 1.3964007932086813}, \"29\": {\"effect\": -0.15053886801010563, \"value\": 0.5225976370886384}, \"30\": {\"effect\": 0.20164784725064436, \"value\": 0.1665270681986227}, \"31\": {\"effect\": 0.15759242364912823, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.04004157955130561, \"value\": -1.7793690019293271}, \"33\": {\"effect\": -0.3339924114310744, \"value\": 1.5813241721969604}, \"34\": {\"effect\": 0.00022141927262698424, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.09094599314331481, \"value\": -0.426484719368509}, \"36\": {\"effect\": -0.0780725328512073, \"value\": 0.4190559183999275}, \"37\": {\"effect\": 0.017577281591208516, \"value\": 0.0}, \"38\": {\"effect\": 0.0030145942756913966, \"value\": 0.0}, \"39\": {\"effect\": 0.20784897901774102, \"value\": 2.0}}}, {\"outValue\": 5.635750959409489, \"simIndex\": 65.0, \"features\": {\"0\": {\"effect\": 0.4843553646827043, \"value\": 1.0}, \"1\": {\"effect\": 0.3459024148483692, \"value\": 0.0}, \"2\": {\"effect\": 0.11558593723912847, \"value\": 1.0}, \"3\": {\"effect\": -0.05077662678158712, \"value\": 0.818153712369467}, \"4\": {\"effect\": 0.041597731539118, \"value\": 1.0}, \"5\": {\"effect\": 0.0018388899446187877, \"value\": 1.0}, \"6\": {\"effect\": 0.011318947863145239, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.11091771574838928, \"value\": 1.0}, \"8\": {\"effect\": -0.05665449990489516, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.18378114004431795, \"value\": 0.0}, \"11\": {\"effect\": 0.2013931353736947, \"value\": 3.0}, \"12\": {\"effect\": -0.1364750528553395, \"value\": 0.966115983544438}, \"13\": {\"effect\": 0.06849195262233715, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01158737245585787, \"value\": 0.0}, \"15\": {\"effect\": 0.25093105677331773, \"value\": 0.0}, \"16\": {\"effect\": -0.5506901029707586, \"value\": 0.1004355908199503}, \"17\": {\"effect\": 0.15051958780955899, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.02888154337923528, \"value\": 1.0}, \"19\": {\"effect\": 0.2633205277260299, \"value\": 1.0}, \"20\": {\"effect\": 0.028201828595775257, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.040415888606953075, \"value\": 0.1004355908199503}, \"22\": {\"effect\": -0.06643054183011972, \"value\": 0.0036131955023819}, \"23\": {\"effect\": 0.39382242907132176, \"value\": 17.09337799604331}, \"24\": {\"effect\": 0.030161681768350115, \"value\": 11.0}, \"25\": {\"effect\": 0.020082642048379156, \"value\": 3.0}, \"26\": {\"effect\": 1.098884443286302, \"value\": -0.922871240619504}, \"27\": {\"effect\": 0.0005779071139713727, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.01719055612794628, \"value\": 0.2975378264378087}, \"29\": {\"effect\": 0.00046419588458625324, \"value\": 1.3761103899159726}, \"30\": {\"effect\": 0.16914537619253162, \"value\": -0.5256213593132205}, \"31\": {\"effect\": 0.0788634431027359, \"value\": -0.3793566741719761}, \"32\": {\"effect\": -0.003033172184495093, \"value\": 0.818153712369467}, \"33\": {\"effect\": -0.018494267255570577, \"value\": 1.4162650230233202}, \"34\": {\"effect\": 0.021879469237183723, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.016419285377931407, \"value\": -0.6518048492033595}, \"36\": {\"effect\": -0.029165331562969327, \"value\": 0.966115983544438}, \"37\": {\"effect\": 0.02836731492306199, \"value\": 0.0}, \"38\": {\"effect\": 0.003999861649817937, \"value\": 0.0}, \"39\": {\"effect\": 0.1202127914557055, \"value\": 2.0}}}, {\"outValue\": -0.6925407262871408, \"simIndex\": 9.0, \"features\": {\"0\": {\"effect\": -0.3587228342676744, \"value\": 0.0}, \"1\": {\"effect\": -0.294495586468864, \"value\": 1.0}, \"2\": {\"effect\": -0.0031857816916078677, \"value\": 1.0}, \"3\": {\"effect\": -0.09653706005528767, \"value\": 0.7751008497015311}, \"4\": {\"effect\": 0.022331906334714047, \"value\": 1.0}, \"5\": {\"effect\": -0.0008993821695614549, \"value\": 1.0}, \"6\": {\"effect\": -0.07721496243733914, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11806852183701677, \"value\": 1.0}, \"8\": {\"effect\": -0.05267706064182383, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22244408704088453, \"value\": 0.0}, \"11\": {\"effect\": -1.0905878837491507, \"value\": 1.0}, \"12\": {\"effect\": 0.0792138147466617, \"value\": -0.9058240939136866}, \"13\": {\"effect\": 0.01656202869713238, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.013405058398398024, \"value\": 0.0}, \"15\": {\"effect\": 0.31009916588052167, \"value\": 0.0}, \"16\": {\"effect\": -0.6554188624472174, \"value\": 0.0580318121139235}, \"17\": {\"effect\": -0.3833134323891671, \"value\": 0.9}, \"18\": {\"effect\": 0.014115573507910852, \"value\": 1.0}, \"19\": {\"effect\": 0.39821402668384653, \"value\": 1.0}, \"20\": {\"effect\": -0.0396609271978731, \"value\": 0.9}, \"21\": {\"effect\": -0.08389358989642706, \"value\": 0.0580318121139235}, \"22\": {\"effect\": 0.21994088525918576, \"value\": 0.0256887108419516}, \"23\": {\"effect\": -0.264578163350086, \"value\": -0.6841366987478685}, \"24\": {\"effect\": 0.0446887923977305, \"value\": 9.0}, \"25\": {\"effect\": -0.11851898722479315, \"value\": 1.0}, \"26\": {\"effect\": -0.2888092759091516, \"value\": -0.4817274810435776}, \"27\": {\"effect\": -0.004558507302687339, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.07251154812907357, \"value\": -1.6456119373601756}, \"29\": {\"effect\": 0.048904119459500184, \"value\": -1.188332786192459}, \"30\": {\"effect\": -0.3305408879888612, \"value\": -1.9297427683647976}, \"31\": {\"effect\": 0.01984970925055005, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.003214218173912602, \"value\": 0.7751008497015311}, \"33\": {\"effect\": -0.355772253012941, \"value\": 1.6638537467837806}, \"34\": {\"effect\": 0.0027884858685074025, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.15544301216742534, \"value\": 0.5545011574157146}, \"36\": {\"effect\": 0.014486681108525194, \"value\": -0.9058240939136866}, \"37\": {\"effect\": 0.02116749773361089, \"value\": 0.0}, \"38\": {\"effect\": 0.003049833670561824, \"value\": 0.0}, \"39\": {\"effect\": -0.07260368588855273, \"value\": 3.0}}}, {\"outValue\": 5.895037912563142, \"simIndex\": 62.0, \"features\": {\"0\": {\"effect\": -0.29146170996474025, \"value\": 0.0}, \"1\": {\"effect\": 0.35579170470728283, \"value\": 0.0}, \"2\": {\"effect\": -0.028271621596755104, \"value\": 0.0}, \"3\": {\"effect\": 0.13570762074958653, \"value\": 0.0862550470145581}, \"4\": {\"effect\": 0.032204053419556955, \"value\": 1.0}, \"5\": {\"effect\": 0.0010545949061659696, \"value\": 1.0}, \"6\": {\"effect\": 0.0676662385239386, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.33841147109145875, \"value\": 2.0}, \"8\": {\"effect\": 0.2718424631859985, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2059507261068436, \"value\": 0.0}, \"11\": {\"effect\": 0.22666693601476717, \"value\": 2.0}, \"12\": {\"effect\": -0.31955537746151774, \"value\": 0.7283935188725507}, \"13\": {\"effect\": 0.07522071726381983, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.013094366383470623, \"value\": 0.0}, \"15\": {\"effect\": 0.2578596680309686, \"value\": 0.0}, \"16\": {\"effect\": 0.19445751799600056, \"value\": 0.9978064083231728}, \"17\": {\"effect\": 0.08436623106158156, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.004754302522008419, \"value\": 1.0}, \"19\": {\"effect\": 0.22488288761467323, \"value\": 1.0}, \"20\": {\"effect\": -0.016909181803462004, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.014729873405419648, \"value\": 0.9978064083231728}, \"22\": {\"effect\": -0.06709795280554665, \"value\": 0.0026222115350568}, \"23\": {\"effect\": 0.382883046469303, \"value\": 41.04136460147297}, \"24\": {\"effect\": 0.04047871255011695, \"value\": 7.0}, \"25\": {\"effect\": 0.029770025288284194, \"value\": 2.0}, \"26\": {\"effect\": 1.1171841821984578, \"value\": -0.8550029699155153}, \"27\": {\"effect\": -0.002445850864227378, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.04782396171522696, \"value\": -1.2998521078775005}, \"29\": {\"effect\": 0.0006104165724638111, \"value\": 0.0735837846735578}, \"30\": {\"effect\": 0.13102622869267488, \"value\": 0.3392739080961101}, \"31\": {\"effect\": 0.11594764731930286, \"value\": -0.3837080466350197}, \"32\": {\"effect\": 0.01310588287240633, \"value\": 0.0862550470145581}, \"33\": {\"effect\": 0.04247264984012726, \"value\": 0.0132622550473782}, \"34\": {\"effect\": 0.0016541783751260236, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.07404137297804633, \"value\": -0.3660742007757301}, \"36\": {\"effect\": -0.08720650654644474, \"value\": 0.7283935188725507}, \"37\": {\"effect\": 0.015130329388677151, \"value\": 0.0}, \"38\": {\"effect\": 0.0021032749918294697, \"value\": 0.0}, \"39\": {\"effect\": -0.06670122884754623, \"value\": 1.0}}}, {\"outValue\": 3.6356564249269283, \"simIndex\": 3.0, \"features\": {\"0\": {\"effect\": 0.47931304422578946, \"value\": 1.0}, \"1\": {\"effect\": 0.43412247271281146, \"value\": 0.0}, \"2\": {\"effect\": -0.017200487366853402, \"value\": 1.0}, \"3\": {\"effect\": 0.10136604911459275, \"value\": -0.9183117485706108}, \"4\": {\"effect\": 0.04866665066931092, \"value\": 1.0}, \"5\": {\"effect\": 0.0005804966057394333, \"value\": 1.0}, \"6\": {\"effect\": 0.033947307935578486, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.06836618159907384, \"value\": 1.0}, \"8\": {\"effect\": -0.09376112230673414, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.1857549434734747, \"value\": 0.0}, \"11\": {\"effect\": -0.8372629513561245, \"value\": 1.0}, \"12\": {\"effect\": -0.07088230606198496, \"value\": 0.0470550741016605}, \"13\": {\"effect\": 0.14078912342929764, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.010039963980350182, \"value\": 0.0}, \"15\": {\"effect\": 0.38059994101381145, \"value\": 0.0}, \"16\": {\"effect\": 0.14725300609969807, \"value\": 0.4253356789021363}, \"17\": {\"effect\": 0.3075251008536501, \"value\": 0.1}, \"18\": {\"effect\": -0.20237314754966795, \"value\": 0.0}, \"19\": {\"effect\": 0.2886982177753776, \"value\": 1.0}, \"20\": {\"effect\": 0.0628101919815647, \"value\": 0.1}, \"21\": {\"effect\": 0.05862408479653383, \"value\": 0.4253356789021363}, \"22\": {\"effect\": -0.1823615793028138, \"value\": 0.6132841709628309}, \"23\": {\"effect\": 0.30114091881680916, \"value\": 24.75391057560111}, \"24\": {\"effect\": 0.02892325175400973, \"value\": 5.0}, \"25\": {\"effect\": -0.09333473456443259, \"value\": 1.0}, \"26\": {\"effect\": -0.2962374700222153, \"value\": 1.7805482090893778}, \"27\": {\"effect\": 0.0039563407096796155, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.0017856116615856017, \"value\": -0.5168199751686737}, \"29\": {\"effect\": 0.08867681109378255, \"value\": -0.2686789856404498}, \"30\": {\"effect\": -0.11664564122039309, \"value\": -0.7088153913000559}, \"31\": {\"effect\": -0.04629878434311599, \"value\": 4.146070687393284}, \"32\": {\"effect\": 0.007772841914470206, \"value\": -0.9183117485706108}, \"33\": {\"effect\": -0.12083832859463628, \"value\": 0.6734988517419392}, \"34\": {\"effect\": 0.0005660921974694445, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.1951043362188626, \"value\": 0.4432750460218564}, \"36\": {\"effect\": -0.04882034837249633, \"value\": 0.0470550741016605}, \"37\": {\"effect\": 0.024474171483104656, \"value\": 0.0}, \"38\": {\"effect\": 0.0013917710091648871, \"value\": 0.0}, \"39\": {\"effect\": -0.0401883054869594, \"value\": 3.0}}}, {\"outValue\": 2.405494413077857, \"simIndex\": 39.0, \"features\": {\"0\": {\"effect\": -0.3362914882387126, \"value\": 0.0}, \"1\": {\"effect\": -0.26254420063673894, \"value\": 1.0}, \"2\": {\"effect\": 0.037253624285729876, \"value\": 1.0}, \"3\": {\"effect\": 0.42670058518294485, \"value\": -2.066388086382233}, \"4\": {\"effect\": 0.035007394316895195, \"value\": 1.0}, \"5\": {\"effect\": 0.0005375542781398962, \"value\": 1.0}, \"6\": {\"effect\": 0.03296210403468658, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.1455713374462806, \"value\": 1.0}, \"8\": {\"effect\": -0.06803615346148564, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2020412370670394, \"value\": 0.0}, \"11\": {\"effect\": 0.23492418872948545, \"value\": 3.0}, \"12\": {\"effect\": -0.20538579475385968, \"value\": 0.3573873292381828}, \"13\": {\"effect\": 0.19441401936891173, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.010742790880268138, \"value\": 0.0}, \"15\": {\"effect\": 0.311507199843346, \"value\": 0.0}, \"16\": {\"effect\": -0.573622564596751, \"value\": 0.086475841080249}, \"17\": {\"effect\": 0.26070149174734863, \"value\": 0.1}, \"18\": {\"effect\": 0.018369119605479888, \"value\": 1.0}, \"19\": {\"effect\": 0.27678944964026986, \"value\": 1.0}, \"20\": {\"effect\": 0.057584103794255354, \"value\": 0.1}, \"21\": {\"effect\": -0.04371076655606593, \"value\": 0.086475841080249}, \"22\": {\"effect\": -0.09880457671166312, \"value\": 0.004611918760104}, \"23\": {\"effect\": 0.004744746728427808, \"value\": -0.6361151194328155}, \"24\": {\"effect\": 0.08406516122145229, \"value\": 13.0}, \"25\": {\"effect\": 0.03254884294471995, \"value\": 3.0}, \"26\": {\"effect\": -0.721970027581485, \"value\": -0.2554999120302821}, \"27\": {\"effect\": 0.023610515134724553, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.08419928127491513, \"value\": 0.0595226669955877}, \"29\": {\"effect\": 0.04846200615672336, \"value\": 1.882509580019311}, \"30\": {\"effect\": 0.038074421435962374, \"value\": 0.8579907722245983}, \"31\": {\"effect\": -0.1969603237144602, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.020037002485319862, \"value\": -2.066388086382233}, \"33\": {\"effect\": -0.001056807968463507, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0029353059251148203, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.03355078896936189, \"value\": -0.6416296879206786}, \"36\": {\"effect\": -0.03218221277119928, \"value\": 0.3573873292381828}, \"37\": {\"effect\": 0.03769397872199704, \"value\": 0.0}, \"38\": {\"effect\": 0.005050025656240292, \"value\": 0.0}, \"39\": {\"effect\": 0.0697800204013099, \"value\": 1.0}}}, {\"outValue\": 0.6026117668164286, \"simIndex\": 13.0, \"features\": {\"0\": {\"effect\": 0.559212715869768, \"value\": 1.0}, \"1\": {\"effect\": 0.34465542314347736, \"value\": 0.0}, \"2\": {\"effect\": -0.02776653255444738, \"value\": 0.0}, \"3\": {\"effect\": 0.2335053022883281, \"value\": -0.3586245338874453}, \"4\": {\"effect\": 0.03312995062256134, \"value\": 1.0}, \"5\": {\"effect\": 6.981565444794733e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.059859333167757156, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10937049522057755, \"value\": 1.0}, \"8\": {\"effect\": -0.05576179083351671, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2650234397533471, \"value\": 0.0}, \"11\": {\"effect\": -1.0792958789180125, \"value\": 1.0}, \"12\": {\"effect\": 0.06000552880114143, \"value\": -0.7228076357562504}, \"13\": {\"effect\": 0.05110812274353727, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.012043949172479418, \"value\": 0.0}, \"15\": {\"effect\": -0.6917147033255262, \"value\": 1.0}, \"16\": {\"effect\": -0.06852541002292425, \"value\": 0.2858771665427634}, \"17\": {\"effect\": -0.40137796123027863, \"value\": 0.9}, \"18\": {\"effect\": 0.03521401224515986, \"value\": 1.0}, \"19\": {\"effect\": 0.25690048156830814, \"value\": 1.0}, \"20\": {\"effect\": -0.05023526232024102, \"value\": 0.9}, \"21\": {\"effect\": -0.029874650200944385, \"value\": 0.2858771665427634}, \"22\": {\"effect\": -0.12020961228312337, \"value\": 0.0015814639754678}, \"23\": {\"effect\": -0.21329091843027725, \"value\": -1.369304660207218}, \"24\": {\"effect\": 0.09155928925081847, \"value\": 10.0}, \"25\": {\"effect\": -0.04104912999175719, \"value\": 1.0}, \"26\": {\"effect\": -0.5753674648119951, \"value\": 0.3553145243056159}, \"27\": {\"effect\": -0.000548831051302938, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.07681180437511764, \"value\": 0.0642044196844573}, \"29\": {\"effect\": 0.06403260284407292, \"value\": -0.2874986471982434}, \"30\": {\"effect\": -0.2030334346663605, \"value\": -0.7846240594637387}, \"31\": {\"effect\": -0.37872309829049844, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.010405577335197085, \"value\": -0.3586245338874453}, \"33\": {\"effect\": -0.02120019703030957, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.007470362420305474, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.03367517389426151, \"value\": -0.1070363011432582}, \"36\": {\"effect\": 0.012845412296830347, \"value\": -0.7228076357562504}, \"37\": {\"effect\": 0.024052177062425066, \"value\": 0.0}, \"38\": {\"effect\": 0.0008478741141055023, \"value\": 0.0}, \"39\": {\"effect\": 0.056149487063737895, \"value\": 2.0}}}, {\"outValue\": 2.7472242300914274, \"simIndex\": 82.0, \"features\": {\"0\": {\"effect\": -0.34459293649087996, \"value\": 0.0}, \"1\": {\"effect\": 0.1977318384760987, \"value\": 0.0}, \"2\": {\"effect\": 0.07356577714605556, \"value\": 1.0}, \"3\": {\"effect\": 0.0761658918925936, \"value\": 0.7033460785883049}, \"4\": {\"effect\": 0.02488336323160688, \"value\": 1.0}, \"5\": {\"effect\": 0.0011234029857909568, \"value\": 1.0}, \"6\": {\"effect\": -0.27219661566411285, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.11014680093620625, \"value\": 1.0}, \"8\": {\"effect\": -0.05176384189845507, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8035550569500927, \"value\": 1.0}, \"11\": {\"effect\": 0.1729255558092778, \"value\": 3.0}, \"12\": {\"effect\": -0.17084226041214695, \"value\": 0.7532598854700284}, \"13\": {\"effect\": 0.048166351016467726, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.016398035894558256, \"value\": 0.0}, \"15\": {\"effect\": 0.2508580491710628, \"value\": 0.0}, \"16\": {\"effect\": -0.6268185429987614, \"value\": 0.0682841515287472}, \"17\": {\"effect\": -0.4060540735857815, \"value\": 0.9}, \"18\": {\"effect\": 0.013150841655607896, \"value\": 1.0}, \"19\": {\"effect\": 0.347882867682758, \"value\": 1.0}, \"20\": {\"effect\": -0.054531831389982674, \"value\": 0.9}, \"21\": {\"effect\": -0.04245440093746523, \"value\": 0.0682841515287472}, \"22\": {\"effect\": -0.13573855306673252, \"value\": 0.0029238684599572}, \"23\": {\"effect\": -0.25762048870535675, \"value\": -1.4365463598359742}, \"24\": {\"effect\": 0.1666262454073796, \"value\": 20.0}, \"25\": {\"effect\": 0.04203440606076334, \"value\": 3.0}, \"26\": {\"effect\": 0.19718940316671937, \"value\": -0.6061526440008902}, \"27\": {\"effect\": 0.0008297160998876419, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.023762187831921903, \"value\": 0.1820769797603826}, \"29\": {\"effect\": -0.06981987248559174, \"value\": 1.5935666949123877}, \"30\": {\"effect\": 0.073792734853913, \"value\": 1.5758910609737786}, \"31\": {\"effect\": 0.07591699493366137, \"value\": -0.3880594190980632}, \"32\": {\"effect\": -0.004561272805897374, \"value\": 0.7033460785883049}, \"33\": {\"effect\": -0.41366654079005183, \"value\": 1.5813241721969604}, \"34\": {\"effect\": -0.02641838268690808, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.23873300271698916, \"value\": -0.8907587198250733}, \"36\": {\"effect\": -0.08941378070200157, \"value\": 0.7532598854700284}, \"37\": {\"effect\": 0.020142612912269084, \"value\": 0.0}, \"38\": {\"effect\": 0.0015065267681973115, \"value\": 0.0}, \"39\": {\"effect\": 0.04549738116605524, \"value\": 1.0}}}, {\"outValue\": 1.996456200862304, \"simIndex\": 38.0, \"features\": {\"0\": {\"effect\": -0.3083308945979575, \"value\": 0.0}, \"1\": {\"effect\": 0.36625236914585585, \"value\": 0.0}, \"2\": {\"effect\": -0.037672140720453294, \"value\": 0.0}, \"3\": {\"effect\": 0.12402183468629896, \"value\": -0.1146583121024756}, \"4\": {\"effect\": 0.031352081705778696, \"value\": 1.0}, \"5\": {\"effect\": 0.0008570342978565298, \"value\": 1.0}, \"6\": {\"effect\": 0.013162611773607199, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.15269177066449222, \"value\": 1.0}, \"8\": {\"effect\": -0.07432945781516223, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22823074313407835, \"value\": 0.0}, \"11\": {\"effect\": 0.27888508394215383, \"value\": 2.0}, \"12\": {\"effect\": 0.09693988428336932, \"value\": -0.4373417472172058}, \"13\": {\"effect\": 0.19489216653411587, \"value\": -1.969856016832232}, \"14\": {\"effect\": 0.010212730127349119, \"value\": 0.0}, \"15\": {\"effect\": 0.21486955935643637, \"value\": 0.0}, \"16\": {\"effect\": -0.24086009856300716, \"value\": 0.2547231408100571}, \"17\": {\"effect\": 0.14787586939583675, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.018036045547481405, \"value\": 1.0}, \"19\": {\"effect\": 0.2607859631835965, \"value\": 1.0}, \"20\": {\"effect\": 0.0003412978678433094, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.02098451759184754, \"value\": 0.2547231408100571}, \"22\": {\"effect\": -0.036434352293972135, \"value\": 0.0031779749194716}, \"23\": {\"effect\": -0.15719917582464615, \"value\": -1.034772067635902}, \"24\": {\"effect\": 0.02276969860752615, \"value\": 5.0}, \"25\": {\"effect\": 0.011761917721690284, \"value\": 2.0}, \"26\": {\"effect\": -0.635337532788567, \"value\": 0.400560038108275}, \"27\": {\"effect\": 0.08109448202875084, \"value\": -1.969856016832232}, \"28\": {\"effect\": -0.01680570090761007, \"value\": -0.9552196274062306}, \"29\": {\"effect\": 0.10325328914378169, \"value\": -0.8677863892053393}, \"30\": {\"effect\": 0.06296942703707242, \"value\": -0.6401243059290145}, \"31\": {\"effect\": -0.3158500567402738, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.012593385506368796, \"value\": -0.1146583121024756}, \"33\": {\"effect\": -0.07641291795581863, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0015218141668254335, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.08636528078826002, \"value\": -0.3477761303190556}, \"36\": {\"effect\": 0.00954546716474072, \"value\": -0.4373417472172058}, \"37\": {\"effect\": -0.6476968109338919, \"value\": 1.0}, \"38\": {\"effect\": 0.001196615681683168, \"value\": 0.0}, \"39\": {\"effect\": 0.05504084145829157, \"value\": 2.0}}}, {\"outValue\": 1.4534519603265035, \"simIndex\": 48.0, \"features\": {\"0\": {\"effect\": -0.4220949454371138, \"value\": 0.0}, \"1\": {\"effect\": 0.26432528054902377, \"value\": 0.0}, \"2\": {\"effect\": -0.04446019391228756, \"value\": 0.0}, \"3\": {\"effect\": 0.03159849869048867, \"value\": 0.1293079096824939}, \"4\": {\"effect\": 0.031919744156739496, \"value\": 1.0}, \"5\": {\"effect\": 0.0006953725340915198, \"value\": 1.0}, \"6\": {\"effect\": 0.039104876574450144, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.11723283208912254, \"value\": 1.0}, \"8\": {\"effect\": -0.07394233539276847, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.23677875669011933, \"value\": 0.0}, \"11\": {\"effect\": 0.22775219093767396, \"value\": 2.0}, \"12\": {\"effect\": -0.03155803586494358, \"value\": -1.220134967705805}, \"13\": {\"effect\": 0.033606787329559344, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.014356306952410594, \"value\": 0.0}, \"15\": {\"effect\": -0.7104062084990961, \"value\": 1.0}, \"16\": {\"effect\": 0.21526437090786518, \"value\": 0.4682919094684842}, \"17\": {\"effect\": -0.15038687480184867, \"value\": 0.8}, \"18\": {\"effect\": 0.020610060970247708, \"value\": 1.0}, \"19\": {\"effect\": -0.28376089501744234, \"value\": 0.0}, \"20\": {\"effect\": -0.022922931742329226, \"value\": 0.8}, \"21\": {\"effect\": 0.014753562031330953, \"value\": 0.4682919094684842}, \"22\": {\"effect\": 0.14038609149772663, \"value\": 0.0221891999049787}, \"23\": {\"effect\": -0.2438976787023132, \"value\": -1.3908733741674504}, \"24\": {\"effect\": 0.07766982559459976, \"value\": 6.0}, \"25\": {\"effect\": 0.037615292200369965, \"value\": 2.0}, \"26\": {\"effect\": -0.7057321919218328, \"value\": -0.4025478318889242}, \"27\": {\"effect\": -0.0008186925147407586, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.0043398899398268504, \"value\": 1.130705286989996}, \"29\": {\"effect\": -0.05307001823409707, \"value\": 0.4650961230471678}, \"30\": {\"effect\": 0.06925368073181078, \"value\": -0.1441408041756536}, \"31\": {\"effect\": 0.19463086079643374, \"value\": 3.019065219465013}, \"32\": {\"effect\": -0.004396054252177583, \"value\": 0.1293079096824939}, \"33\": {\"effect\": -0.0572112732965013, \"value\": -0.7295039162340028}, \"34\": {\"effect\": 0.0011103183596382316, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.13032286019809047, \"value\": 0.0294570923193311}, \"36\": {\"effect\": -0.01332660718122503, \"value\": -1.220134967705805}, \"37\": {\"effect\": 0.0143741505366093, \"value\": 0.0}, \"38\": {\"effect\": 0.0013600136273275048, \"value\": 0.0}, \"39\": {\"effect\": 0.1576520488217712, \"value\": 2.0}}}, {\"outValue\": 2.919294860846868, \"simIndex\": 87.0, \"features\": {\"0\": {\"effect\": -0.37053509165547344, \"value\": 0.0}, \"1\": {\"effect\": 0.3393113210423902, \"value\": 0.0}, \"2\": {\"effect\": 0.03616785686681176, \"value\": 1.0}, \"3\": {\"effect\": 0.21295415007753743, \"value\": -0.2151149916609925}, \"4\": {\"effect\": 0.03273968180101177, \"value\": 1.0}, \"5\": {\"effect\": 0.0009687669573679315, \"value\": 1.0}, \"6\": {\"effect\": 0.05326957023453843, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11968416198053494, \"value\": 1.0}, \"8\": {\"effect\": -0.06290948429453913, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9433744049774058, \"value\": 1.0}, \"11\": {\"effect\": 0.1380292118498781, \"value\": 3.0}, \"12\": {\"effect\": -0.07719727264520264, \"value\": 0.0003063048984023}, \"13\": {\"effect\": 0.17834413747603814, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.004511784477787253, \"value\": 0.0}, \"15\": {\"effect\": 0.24862479358590678, \"value\": 0.0}, \"16\": {\"effect\": 0.16682407414178543, \"value\": 0.5202790851955159}, \"17\": {\"effect\": -0.5347245135911366, \"value\": 0.9}, \"18\": {\"effect\": 0.026485928378031744, \"value\": 1.0}, \"19\": {\"effect\": -0.33139725196141223, \"value\": 0.0}, \"20\": {\"effect\": -0.08599834684754451, \"value\": 0.9}, \"21\": {\"effect\": 0.025286771045182656, \"value\": 0.5202790851955159}, \"22\": {\"effect\": -0.09536139573925943, \"value\": 0.0037675516528476}, \"23\": {\"effect\": -0.20281704868663825, \"value\": -1.3473288028918673}, \"24\": {\"effect\": 0.0964539418007446, \"value\": 12.0}, \"25\": {\"effect\": 0.03276819592553964, \"value\": 3.0}, \"26\": {\"effect\": -0.5544811413565053, \"value\": -0.3007454258329412}, \"27\": {\"effect\": 0.007824539641140884, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.08009384580786218, \"value\": 0.9029643667102012}, \"29\": {\"effect\": -0.10274192572812894, \"value\": 0.7993148927671195}, \"30\": {\"effect\": 0.07893965031810213, \"value\": 0.6846077998782062}, \"31\": {\"effect\": 0.08755887491363888, \"value\": -0.3815323604034979}, \"32\": {\"effect\": 0.008380976551034224, \"value\": -0.2151149916609925}, \"33\": {\"effect\": 0.042887797103852786, \"value\": -0.6469743416471827}, \"34\": {\"effect\": 0.006293533418387492, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.16533667098069946, \"value\": -0.4253031873757872}, \"36\": {\"effect\": -0.0020621565843772353, \"value\": 0.0003063048984023}, \"37\": {\"effect\": 0.02570963980789777, \"value\": 0.0}, \"38\": {\"effect\": 0.001204443226468389, \"value\": 0.0}, \"39\": {\"effect\": -0.0017050587303289902, \"value\": 1.0}}}, {\"outValue\": 2.45751450910308, \"simIndex\": 41.0, \"features\": {\"0\": {\"effect\": -0.39861037207193606, \"value\": 0.0}, \"1\": {\"effect\": -0.30608434915524746, \"value\": 1.0}, \"2\": {\"effect\": -0.01454135554846162, \"value\": 0.0}, \"3\": {\"effect\": -0.06656992010396276, \"value\": 1.1195237510450178}, \"4\": {\"effect\": 0.03787701202095409, \"value\": 1.0}, \"5\": {\"effect\": 0.0009757636508775896, \"value\": 1.0}, \"6\": {\"effect\": 0.07819261812781728, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.1353296759056665, \"value\": 1.0}, \"8\": {\"effect\": 0.19450246964294596, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21766816340635436, \"value\": 0.0}, \"11\": {\"effect\": 0.23788392189399094, \"value\": 4.0}, \"12\": {\"effect\": 0.07113965257268193, \"value\": -0.6183688960468439}, \"13\": {\"effect\": 0.21631897853352006, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.00720401249536315, \"value\": 0.0}, \"15\": {\"effect\": 0.27944976812614836, \"value\": 0.0}, \"16\": {\"effect\": -0.15184569732826533, \"value\": 0.2878631675268583}, \"17\": {\"effect\": 0.25518030178786477, \"value\": 0.2}, \"18\": {\"effect\": 0.01072800838705203, \"value\": 1.0}, \"19\": {\"effect\": -0.2939057188427768, \"value\": 0.0}, \"20\": {\"effect\": 0.053932419966104206, \"value\": 0.2}, \"21\": {\"effect\": -0.01152529863011026, \"value\": 0.2878631675268583}, \"22\": {\"effect\": -0.02291096995729378, \"value\": 0.0070738291820691}, \"23\": {\"effect\": -0.1725723593688299, \"value\": -1.0138865755698867}, \"24\": {\"effect\": 0.022002844172010493, \"value\": 10.0}, \"25\": {\"effect\": 0.024751609664157962, \"value\": 4.0}, \"26\": {\"effect\": -0.5892940903959792, \"value\": -0.4251705887902537}, \"27\": {\"effect\": 0.009561805411834313, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.005423577622628513, \"value\": -0.481280687218376}, \"29\": {\"effect\": 0.059888434894069975, \"value\": -0.6027763687150239}, \"30\": {\"effect\": -0.14896683286358228, \"value\": -0.7543192372890553}, \"31\": {\"effect\": 0.23806186175899183, \"value\": 2.618738952865009}, \"32\": {\"effect\": -0.01586484105693345, \"value\": 1.1195237510450178}, \"33\": {\"effect\": 0.22801626648689088, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.0019881330297184243, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.09879251416098427, \"value\": -0.3895225012713656}, \"36\": {\"effect\": 0.01726684014853345, \"value\": -0.6183688960468439}, \"37\": {\"effect\": 0.025534085748848297, \"value\": 0.0}, \"38\": {\"effect\": 0.0029576775029223432, \"value\": 0.0}, \"39\": {\"effect\": 0.11173242243550623, \"value\": 2.0}}}, {\"outValue\": 5.054834232892747, \"simIndex\": 77.0, \"features\": {\"0\": {\"effect\": 0.38075004859574213, \"value\": 1.0}, \"1\": {\"effect\": -0.29639978832312946, \"value\": 1.0}, \"2\": {\"effect\": -0.03552882351719963, \"value\": 0.0}, \"3\": {\"effect\": 0.022897911762194377, \"value\": 0.2441155434636561}, \"4\": {\"effect\": 0.03714732112260129, \"value\": 1.0}, \"5\": {\"effect\": -8.648083572371125e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.03852700359800815, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11248044675738947, \"value\": 3.0}, \"8\": {\"effect\": 0.20633325904452712, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7965786237318484, \"value\": 1.0}, \"11\": {\"effect\": 0.30749080910124904, \"value\": 2.0}, \"12\": {\"effect\": 0.026806546429889482, \"value\": -1.1415572492577757}, \"13\": {\"effect\": -0.22941481350593662, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.010031082707868937, \"value\": 0.0}, \"15\": {\"effect\": 0.3464009573844153, \"value\": 0.0}, \"16\": {\"effect\": 0.17312342051296156, \"value\": 0.3970790402300558}, \"17\": {\"effect\": 0.07164514252334034, \"value\": 0.6000000000000001}, \"18\": {\"effect\": -0.0028398992753998, \"value\": 1.0}, \"19\": {\"effect\": -0.2957341407626233, \"value\": 0.0}, \"20\": {\"effect\": -0.0023121524407243147, \"value\": 0.6000000000000001}, \"21\": {\"effect\": -0.011739922705376724, \"value\": 0.3970790402300558}, \"22\": {\"effect\": 0.002279651829104992, \"value\": 0.0068165976963421}, \"23\": {\"effect\": 0.061270020726437675, \"value\": -0.4360904704802789}, \"24\": {\"effect\": -0.5260542929295798, \"value\": 1.0}, \"25\": {\"effect\": 0.046407259319299496, \"value\": 2.0}, \"26\": {\"effect\": 0.8649696538966368, \"value\": -0.922871240619504}, \"27\": {\"effect\": -0.006667456720803926, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.02498154304746844, \"value\": -0.3133717397101241}, \"29\": {\"effect\": 0.14233660652227628, \"value\": -0.4987102257707593}, \"30\": {\"effect\": 0.1174170804103813, \"value\": 0.2367731141577185}, \"31\": {\"effect\": -0.2204517082808236, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.0062364581872831806, \"value\": 0.2441155434636561}, \"33\": {\"effect\": -0.04569183316220247, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0021560186708875486, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.11383310060959823, \"value\": 1.0362114155571316}, \"36\": {\"effect\": -0.0010518772551147237, \"value\": -1.1415572492577757}, \"37\": {\"effect\": 0.026543604394502995, \"value\": 0.0}, \"38\": {\"effect\": 0.0020696118461429876, \"value\": 0.0}, \"39\": {\"effect\": 0.10162895157207816, \"value\": 2.0}}}, {\"outValue\": 0.47116414151072616, \"simIndex\": 17.0, \"features\": {\"0\": {\"effect\": -0.4336240036938219, \"value\": 0.0}, \"1\": {\"effect\": -0.2090696286638602, \"value\": 1.0}, \"2\": {\"effect\": -0.010822533032948656, \"value\": 0.0}, \"3\": {\"effect\": 0.005762450735803101, \"value\": 0.2441155434636561}, \"4\": {\"effect\": 0.02983996766583764, \"value\": 1.0}, \"5\": {\"effect\": -0.0017429827486322349, \"value\": 1.0}, \"6\": {\"effect\": -0.011048324509207572, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2118148855599737, \"value\": 2.0}, \"8\": {\"effect\": 0.13246307815717742, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.24195165507881178, \"value\": 0.0}, \"11\": {\"effect\": 0.07608078737614087, \"value\": 3.0}, \"12\": {\"effect\": 0.0252817134552032, \"value\": -0.9416316618140544}, \"13\": {\"effect\": -1.083906273822973, \"value\": 3.850966116330231}, \"14\": {\"effect\": 0.005059606600635798, \"value\": 0.0}, \"15\": {\"effect\": 0.31252319485920677, \"value\": 0.0}, \"16\": {\"effect\": 0.14479074010186244, \"value\": 0.7338505531627748}, \"17\": {\"effect\": 0.2393342775079292, \"value\": 0.4}, \"18\": {\"effect\": 0.003657362215474656, \"value\": 1.0}, \"19\": {\"effect\": -0.2856665287034356, \"value\": 0.0}, \"20\": {\"effect\": 0.012566784294081548, \"value\": 0.4}, \"21\": {\"effect\": 0.00750411742678702, \"value\": 0.7338505531627748}, \"22\": {\"effect\": -0.03590399231962785, \"value\": 0.0073237439710313}, \"23\": {\"effect\": -0.31830593075578767, \"value\": -1.2965578965167923}, \"24\": {\"effect\": -0.47014411016316154, \"value\": 2.0}, \"25\": {\"effect\": 0.035426717202430305, \"value\": 3.0}, \"26\": {\"effect\": -0.6869812350428557, \"value\": -0.3686136965369299}, \"27\": {\"effect\": -0.07151863119340181, \"value\": 3.850966116330231}, \"28\": {\"effect\": -0.04731406236950623, \"value\": 0.613683061706632}, \"29\": {\"effect\": 0.02177634324695802, \"value\": -0.1651569129420882}, \"30\": {\"effect\": -0.14049170397868144, \"value\": -0.7571279439777315}, \"31\": {\"effect\": 0.2819962613113364, \"value\": 2.4599138579639206}, \"32\": {\"effect\": 0.013322446285259417, \"value\": 0.2441155434636561}, \"33\": {\"effect\": -0.02164431972962728, \"value\": -0.4819151924735424}, \"34\": {\"effect\": -0.00032148034448962375, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10025550136107242, \"value\": -0.5490612672173829}, \"36\": {\"effect\": 0.010944032963664837, \"value\": -0.9416316618140544}, \"37\": {\"effect\": 0.02894288327664829, \"value\": 0.0}, \"38\": {\"effect\": 0.003342334342793673, \"value\": 0.0}, \"39\": {\"effect\": 0.12802087261939368, \"value\": 2.0}}}, {\"outValue\": 4.287352233570967, \"simIndex\": 60.0, \"features\": {\"0\": {\"effect\": 0.5867049988385281, \"value\": 1.0}, \"1\": {\"effect\": 0.30447303317878355, \"value\": 0.0}, \"2\": {\"effect\": -0.03180111124208901, \"value\": 0.0}, \"3\": {\"effect\": 0.1600772266164758, \"value\": -0.4734321676686074}, \"4\": {\"effect\": 0.03873881161587156, \"value\": 1.0}, \"5\": {\"effect\": 0.0008196609744892309, \"value\": 1.0}, \"6\": {\"effect\": 0.04422113782854941, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.17053311448899433, \"value\": 2.0}, \"8\": {\"effect\": -0.07409670149151597, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2641226864468587, \"value\": 0.0}, \"11\": {\"effect\": 0.22675110970200132, \"value\": 3.0}, \"12\": {\"effect\": 0.022057313595968794, \"value\": -1.0430864375317637}, \"13\": {\"effect\": -0.192203243836484, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.011437452573549212, \"value\": 0.0}, \"15\": {\"effect\": -0.6585300406294046, \"value\": 1.0}, \"16\": {\"effect\": 0.19476114136279252, \"value\": 0.6798431096067559}, \"17\": {\"effect\": -0.4251999456721821, \"value\": 0.9}, \"18\": {\"effect\": 0.011119776957586541, \"value\": 1.0}, \"19\": {\"effect\": 0.3002953898987216, \"value\": 1.0}, \"20\": {\"effect\": -0.0575561237913789, \"value\": 0.9}, \"21\": {\"effect\": 0.0020531098770446557, \"value\": 0.6798431096067559}, \"22\": {\"effect\": -0.05452818149236479, \"value\": 0.0066508972706722}, \"23\": {\"effect\": -0.024979909369534006, \"value\": -0.8932683955325513}, \"24\": {\"effect\": 0.06626163998941637, \"value\": 11.0}, \"25\": {\"effect\": 0.02526133817766121, \"value\": 3.0}, \"26\": {\"effect\": 0.5832169404591302, \"value\": -0.6627095362542141}, \"27\": {\"effect\": -0.0023447158931459025, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.05507258260396193, \"value\": -0.139752802330851}, \"29\": {\"effect\": 0.16441713123941964, \"value\": -0.7718761071530612}, \"30\": {\"effect\": 0.11292034653702905, \"value\": 0.033431609266413}, \"31\": {\"effect\": -0.18289985628769978, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.014290775577429513, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.1982762608754553, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.014324231875408967, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.11127074141762103, \"value\": -0.5874717225011025}, \"36\": {\"effect\": 0.007129959616383556, \"value\": -1.0430864375317637}, \"37\": {\"effect\": 0.016946604288604714, \"value\": 0.0}, \"38\": {\"effect\": 0.0013832296093317853, \"value\": 0.0}, \"39\": {\"effect\": 0.1219149909646259, \"value\": 2.0}}}, {\"outValue\": 2.4090923077896877, \"simIndex\": 40.0, \"features\": {\"0\": {\"effect\": -0.30051620736799534, \"value\": 0.0}, \"1\": {\"effect\": -0.23780512893719766, \"value\": 1.0}, \"2\": {\"effect\": 0.041425577935507746, \"value\": 1.0}, \"3\": {\"effect\": 0.12822816701371276, \"value\": -0.4303793050006717}, \"4\": {\"effect\": 0.030312640418221345, \"value\": 1.0}, \"5\": {\"effect\": 0.00016439462459017938, \"value\": 1.0}, \"6\": {\"effect\": 0.04392199728871566, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.14442407467833485, \"value\": 1.0}, \"8\": {\"effect\": -0.07709397515559506, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.23304612074181275, \"value\": 0.0}, \"11\": {\"effect\": 0.30090270813608916, \"value\": 2.0}, \"12\": {\"effect\": -0.07518154266448147, \"value\": 0.1365739938525804}, \"13\": {\"effect\": 0.02408785405269187, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.0087416125280231, \"value\": 0.0}, \"15\": {\"effect\": 0.3081938571378289, \"value\": 0.0}, \"16\": {\"effect\": -0.5160121203559543, \"value\": 0.1193150046967689}, \"17\": {\"effect\": 0.005915965658322157, \"value\": 0.8}, \"18\": {\"effect\": 0.012166456013667412, \"value\": 1.0}, \"19\": {\"effect\": -0.3278949901906086, \"value\": 0.0}, \"20\": {\"effect\": -0.015241552403185844, \"value\": 0.8}, \"21\": {\"effect\": -0.026701818586241828, \"value\": 0.1193150046967689}, \"22\": {\"effect\": -0.06385925025427563, \"value\": 0.0128614106944093}, \"23\": {\"effect\": 0.034424471314478934, \"value\": -0.3724649416606316}, \"24\": {\"effect\": 0.07884077005982505, \"value\": 13.0}, \"25\": {\"effect\": 0.037931377952652015, \"value\": 2.0}, \"26\": {\"effect\": -0.3274331683838538, \"value\": -0.4930388594942424}, \"27\": {\"effect\": -0.0044987822518597256, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.0010284186600766356, \"value\": -0.8027319306707918}, \"29\": {\"effect\": -0.014743651933453263, \"value\": -0.0157367842147424}, \"30\": {\"effect\": 0.15084334423736187, \"value\": 0.1931277299784901}, \"31\": {\"effect\": 0.16908437362269843, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.012397432623588278, \"value\": -0.4303793050006717}, \"33\": {\"effect\": 0.13666151039723184, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.0037257868188799127, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.18133835379077026, \"value\": 0.16014414527477}, \"36\": {\"effect\": -0.004892555120657807, \"value\": 0.1365739938525804}, \"37\": {\"effect\": 0.02247732435692026, \"value\": 0.0}, \"38\": {\"effect\": 0.003377046287466097, \"value\": 0.0}, \"39\": {\"effect\": 0.1308196240678448, \"value\": 2.0}}}, {\"outValue\": -1.8695615662644625, \"simIndex\": 10.0, \"features\": {\"0\": {\"effect\": -0.4105212707476548, \"value\": 0.0}, \"1\": {\"effect\": -0.32703670966937665, \"value\": 1.0}, \"2\": {\"effect\": -0.05951219077117192, \"value\": 0.0}, \"3\": {\"effect\": -0.0029627745824184807, \"value\": 1.1769275679355988}, \"4\": {\"effect\": 0.023920062298907155, \"value\": 1.0}, \"5\": {\"effect\": 0.0005107997335906443, \"value\": 1.0}, \"6\": {\"effect\": 0.06820030975775389, \"value\": 0.9724943033069674}, \"7\": {\"effect\": -0.16120790688186165, \"value\": 1.0}, \"8\": {\"effect\": -0.08308292143682858, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.24200909694837514, \"value\": 0.0}, \"11\": {\"effect\": -1.0262910819321247, \"value\": 1.0}, \"12\": {\"effect\": 0.13813596355589622, \"value\": -0.7307648730674432}, \"13\": {\"effect\": 0.05790144498631133, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01439041030265681, \"value\": 0.0}, \"15\": {\"effect\": -0.6029587683288941, \"value\": 1.0}, \"16\": {\"effect\": -0.5889360616549945, \"value\": 0.0433116266338233}, \"17\": {\"effect\": 0.0006883108283347202, \"value\": 0.8}, \"18\": {\"effect\": 0.01397362052237949, \"value\": 1.0}, \"19\": {\"effect\": -0.2474712969399537, \"value\": 0.0}, \"20\": {\"effect\": -0.013667028298028691, \"value\": 0.8}, \"21\": {\"effect\": -0.05225659783064575, \"value\": 0.0433116266338233}, \"22\": {\"effect\": -0.2508104193547762, \"value\": 0.0001870149936176}, \"23\": {\"effect\": -0.09104764817119307, \"value\": -0.8169371857615849}, \"24\": {\"effect\": 0.08206128133350679, \"value\": 6.0}, \"25\": {\"effect\": -0.0652686182153832, \"value\": 1.0}, \"26\": {\"effect\": -0.37834725277029596, \"value\": 0.5702307148682467}, \"27\": {\"effect\": -0.003601705275597392, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0024977271970444974, \"value\": -0.7186305506267472}, \"29\": {\"effect\": -0.013836509392917664, \"value\": -1.3136878244991792}, \"30\": {\"effect\": -0.329506127328512, \"value\": -1.922494551424788}, \"31\": {\"effect\": -0.29652817694240863, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.01679131931036712, \"value\": 1.1769275679355988}, \"33\": {\"effect\": -0.012659007048981201, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.021489611321214557, \"value\": 0.9724943033069674}, \"35\": {\"effect\": 0.11042931174499736, \"value\": -0.868722982175827}, \"36\": {\"effect\": 0.018538825157142506, \"value\": -0.7307648730674432}, \"37\": {\"effect\": 0.01757301858976455, \"value\": 0.0}, \"38\": {\"effect\": 0.00390523172617578, \"value\": 0.0}, \"39\": {\"effect\": -0.07389773291131939, \"value\": 3.0}}}, {\"outValue\": 5.058904655940424, \"simIndex\": 99.0, \"features\": {\"0\": {\"effect\": 0.5117218386294107, \"value\": 1.0}, \"1\": {\"effect\": 0.30042570364264964, \"value\": 0.0}, \"2\": {\"effect\": -0.046493553017827996, \"value\": 0.0}, \"3\": {\"effect\": -0.0808174309131597, \"value\": 1.0477689799317913}, \"4\": {\"effect\": 0.0249969359674255, \"value\": 1.0}, \"5\": {\"effect\": 0.0010522019871193767, \"value\": 1.0}, \"6\": {\"effect\": 0.07454279046401402, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.09684580085113365, \"value\": 1.0}, \"8\": {\"effect\": -0.06625418854413556, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9911563249222154, \"value\": 1.0}, \"11\": {\"effect\": 0.14207054425288584, \"value\": 3.0}, \"12\": {\"effect\": -0.11597689097916833, \"value\": 0.1166809005745982}, \"13\": {\"effect\": 0.10464986727524347, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.010275876089795003, \"value\": 0.0}, \"15\": {\"effect\": -0.5806936541306162, \"value\": 1.0}, \"16\": {\"effect\": -0.21921632243557795, \"value\": 0.2435472293672471}, \"17\": {\"effect\": 0.19125106787931148, \"value\": 0.5}, \"18\": {\"effect\": 0.030094856597546946, \"value\": 1.0}, \"19\": {\"effect\": 0.2734211403250318, \"value\": 1.0}, \"20\": {\"effect\": 0.029473297241255195, \"value\": 0.5}, \"21\": {\"effect\": 0.002927776752413097, \"value\": 0.2435472293672471}, \"22\": {\"effect\": 0.363898099941779, \"value\": 0.0503824074250401}, \"23\": {\"effect\": 0.3317568376649348, \"value\": 97.19691623774608}, \"24\": {\"effect\": 0.08582987946428498, \"value\": 12.0}, \"25\": {\"effect\": 0.041398870859268765, \"value\": 3.0}, \"26\": {\"effect\": -0.5739989082776435, \"value\": -0.413859210339589}, \"27\": {\"effect\": 0.003347533923364751, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.0070703170566449956, \"value\": -1.6290002964231745}, \"29\": {\"effect\": 0.07990398730124428, \"value\": -0.371471529047616}, \"30\": {\"effect\": 0.11465428931048444, \"value\": -0.507037821783886}, \"31\": {\"effect\": 0.1590884185588161, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.013379434845551269, \"value\": 1.0477689799317913}, \"33\": {\"effect\": 0.026157924155268162, \"value\": 0.7560284263287593}, \"34\": {\"effect\": 0.0007061916190491863, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.03187858750448623, \"value\": -0.7203801481721747}, \"36\": {\"effect\": -0.03653839607645679, \"value\": 0.1166809005745982}, \"37\": {\"effect\": 0.015242408352604635, \"value\": 0.0}, \"38\": {\"effect\": 0.002629596364799333, \"value\": 0.0}, \"39\": {\"effect\": 0.04021052420360726, \"value\": 2.0}}}, {\"outValue\": 3.2539600927318175, \"simIndex\": 47.0, \"features\": {\"0\": {\"effect\": -0.4394378845972825, \"value\": 0.0}, \"1\": {\"effect\": -0.1285649914496711, \"value\": 1.0}, \"2\": {\"effect\": -0.013366092042225249, \"value\": 1.0}, \"3\": {\"effect\": 0.03498771980161859, \"value\": 0.2871684061315919}, \"4\": {\"effect\": 0.02447702883960386, \"value\": 1.0}, \"5\": {\"effect\": 0.0009931559266383573, \"value\": 1.0}, \"6\": {\"effect\": -0.03420745149238223, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.10358583375320618, \"value\": 1.0}, \"8\": {\"effect\": -0.04480089866895458, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2115400878525009, \"value\": 0.0}, \"11\": {\"effect\": 0.5980637233070741, \"value\": 5.0}, \"12\": {\"effect\": -0.01451818267928272, \"value\": 0.2101784389811145}, \"13\": {\"effect\": 0.051921929465989225, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.006827891046824487, \"value\": 0.0}, \"15\": {\"effect\": 0.20798336563967817, \"value\": 0.0}, \"16\": {\"effect\": 0.14799398247419732, \"value\": 0.4996263154817879}, \"17\": {\"effect\": -0.4963441358500688, \"value\": 0.9}, \"18\": {\"effect\": 0.01841836068041865, \"value\": 1.0}, \"19\": {\"effect\": 0.2917692198940484, \"value\": 1.0}, \"20\": {\"effect\": -0.03217521441931816, \"value\": 0.9}, \"21\": {\"effect\": 0.03621768334241207, \"value\": 0.4996263154817879}, \"22\": {\"effect\": -0.08307379023370852, \"value\": 0.0046017739268205}, \"23\": {\"effect\": 0.767154107022251, \"value\": 105.28494410346563}, \"24\": {\"effect\": 0.09144440001777239, \"value\": 15.0}, \"25\": {\"effect\": 0.04093082963615737, \"value\": 5.0}, \"26\": {\"effect\": -0.5613572076706794, \"value\": -0.1876316413262934}, \"27\": {\"effect\": -0.006562043761115099, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.22137711328665405, \"value\": 2.8281067955679404}, \"29\": {\"effect\": -0.09073195066580123, \"value\": 0.9523207498417148}, \"30\": {\"effect\": 0.04932745901799678, \"value\": 1.1077698514664904}, \"31\": {\"effect\": 0.11163281206809593, \"value\": -0.3945864777926284}, \"32\": {\"effect\": 0.0037397077749778324, \"value\": 0.2871684061315919}, \"33\": {\"effect\": 0.019784272035151974, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.021978047919116457, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.29538845063450736, \"value\": -0.7645422650469426}, \"36\": {\"effect\": -0.020698141007202592, \"value\": 0.2101784389811145}, \"37\": {\"effect\": 0.01758468607233333, \"value\": 0.0}, \"38\": {\"effect\": 0.0010693315392994497, \"value\": 0.0}, \"39\": {\"effect\": 0.04914286202590997, \"value\": 1.0}}}, {\"outValue\": 4.825451629649756, \"simIndex\": 25.0, \"features\": {\"0\": {\"effect\": 0.5126122438660613, \"value\": 1.0}, \"1\": {\"effect\": 0.30695637332679304, \"value\": 0.0}, \"2\": {\"effect\": 0.03307266550800765, \"value\": 1.0}, \"3\": {\"effect\": 0.04669232755054891, \"value\": -1.2053308330235164}, \"4\": {\"effect\": 0.02993737190663009, \"value\": 1.0}, \"5\": {\"effect\": 0.001166263349235485, \"value\": 1.0}, \"6\": {\"effect\": 0.04122293358944754, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.6897378368519098, \"value\": 6.0}, \"8\": {\"effect\": -0.03613008083253248, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.1727707968643211, \"value\": 0.0}, \"11\": {\"effect\": 0.17771354640363052, \"value\": 2.0}, \"12\": {\"effect\": 0.07248542285911096, \"value\": -0.665117665250102}, \"13\": {\"effect\": 0.1177142203733905, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.008969325874600717, \"value\": 0.0}, \"15\": {\"effect\": 0.2815089898915584, \"value\": 0.0}, \"16\": {\"effect\": 0.2059016231046445, \"value\": 0.5377895408054849}, \"17\": {\"effect\": 0.08552016139408096, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.049829795602622975, \"value\": 1.0}, \"19\": {\"effect\": 0.2300449364831663, \"value\": 1.0}, \"20\": {\"effect\": 0.011355056600998717, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.04529401508201218, \"value\": 0.5377895408054849}, \"22\": {\"effect\": 0.17262399068466117, \"value\": 0.0265708705755777}, \"23\": {\"effect\": -0.08269887139001132, \"value\": -0.9369378598141014}, \"24\": {\"effect\": 0.02940541154496455, \"value\": 11.0}, \"25\": {\"effect\": 0.029619136463367324, \"value\": 2.0}, \"26\": {\"effect\": -0.5915621574310933, \"value\": 0.5815420933189115}, \"27\": {\"effect\": 0.007918812591017713, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.05203037170654013, \"value\": -0.2136809213498082}, \"29\": {\"effect\": -0.08128771424491295, \"value\": -1.6496266684962078}, \"30\": {\"effect\": -0.2214745762459717, \"value\": -1.845624939261468}, \"31\": {\"effect\": -0.1999703781689482, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.008905985113500077, \"value\": -1.2053308330235164}, \"33\": {\"effect\": 0.020130480036522527, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0009732554852236486, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.0823568486758066, \"value\": -0.6788394604596062}, \"36\": {\"effect\": 0.022782362898959373, \"value\": -0.665117665250102}, \"37\": {\"effect\": 0.033796419724923144, \"value\": 0.0}, \"38\": {\"effect\": 0.0021444142332995167, \"value\": 0.0}, \"39\": {\"effect\": -0.09269060554072041, \"value\": 3.0}}}, {\"outValue\": 3.531679538635859, \"simIndex\": 27.0, \"features\": {\"0\": {\"effect\": 0.38676153935314483, \"value\": 1.0}, \"1\": {\"effect\": 0.35582975959255625, \"value\": 0.0}, \"2\": {\"effect\": 0.023066234922411465, \"value\": 1.0}, \"3\": {\"effect\": -0.7700454342601466, \"value\": 2.29630199730193}, \"4\": {\"effect\": 0.02568102211691697, \"value\": 1.0}, \"5\": {\"effect\": 0.0007733402795340376, \"value\": 1.0}, \"6\": {\"effect\": -0.0431455724295809, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2595600374866086, \"value\": 2.0}, \"8\": {\"effect\": -0.10614302542585377, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.224215263299208, \"value\": 0.0}, \"11\": {\"effect\": 0.16482523724250356, \"value\": 3.0}, \"12\": {\"effect\": 0.12843991339759503, \"value\": -0.5696308175157875}, \"13\": {\"effect\": 0.057192711591443145, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01786000089444537, \"value\": 0.0}, \"15\": {\"effect\": 0.34303447910591534, \"value\": 0.0}, \"16\": {\"effect\": 0.2051939732154017, \"value\": 0.5981929020957328}, \"17\": {\"effect\": 0.0898096399740916, \"value\": 0.7000000000000001}, \"18\": {\"effect\": -0.12990857885849202, \"value\": 0.0}, \"19\": {\"effect\": -0.37650923241891426, \"value\": 0.0}, \"20\": {\"effect\": 0.014675823049382704, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.011508562870212121, \"value\": 0.5981929020957328}, \"22\": {\"effect\": -0.054809842101773996, \"value\": 0.0021440040551625}, \"23\": {\"effect\": 0.33975207348339753, \"value\": 18.90561103555649}, \"24\": {\"effect\": 0.023028103009478634, \"value\": 4.0}, \"25\": {\"effect\": 0.027313404383168854, \"value\": 3.0}, \"26\": {\"effect\": -0.612369009192441, \"value\": -0.0066495861156569}, \"27\": {\"effect\": -0.0006739785460080758, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.0350371762165089, \"value\": -0.5013047873604283}, \"29\": {\"effect\": 0.057612823105077954, \"value\": -1.2199670542273366}, \"30\": {\"effect\": 0.16654349921176945, \"value\": -0.6240618079971808}, \"31\": {\"effect\": 0.12270695172867405, \"value\": 3.599973443281323}, \"32\": {\"effect\": -0.06906511971374062, \"value\": 2.29630199730193}, \"33\": {\"effect\": -0.016030047119121836, \"value\": -0.4819151924735424}, \"34\": {\"effect\": -0.0001180225786233829, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.0052771543126193515, \"value\": -0.6595051235525008}, \"36\": {\"effect\": 0.020401426134947942, \"value\": -0.5696308175157875}, \"37\": {\"effect\": 0.02077067546695903, \"value\": 0.0}, \"38\": {\"effect\": 0.000683359063313612, \"value\": 0.0}, \"39\": {\"effect\": 0.1305018701788934, \"value\": 2.0}}}, {\"outValue\": 2.7467859510436217, \"simIndex\": 30.0, \"features\": {\"0\": {\"effect\": 0.517436889707741, \"value\": 1.0}, \"1\": {\"effect\": -0.2691260951091109, \"value\": 1.0}, \"2\": {\"effect\": 0.034275003575232714, \"value\": 1.0}, \"3\": {\"effect\": -0.06237491822850912, \"value\": 0.344572223022173}, \"4\": {\"effect\": 0.03971464492272421, \"value\": 1.0}, \"5\": {\"effect\": -1.2667243417204192e-05, \"value\": 1.0}, \"6\": {\"effect\": -0.007044465208312094, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.1341672311670601, \"value\": 1.0}, \"8\": {\"effect\": -0.04461707871589291, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.19158097665512905, \"value\": 0.0}, \"11\": {\"effect\": 0.5777402550415996, \"value\": 5.0}, \"12\": {\"effect\": 0.0022356907371265636, \"value\": -1.1883060184610337}, \"13\": {\"effect\": 0.03791036291169905, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.015129797121234294, \"value\": 0.0}, \"15\": {\"effect\": 0.2596138723437746, \"value\": 0.0}, \"16\": {\"effect\": -0.39221158132050554, \"value\": 0.2060838792736372}, \"17\": {\"effect\": -0.031985131477962614, \"value\": 0.8}, \"18\": {\"effect\": 0.035852852497715464, \"value\": 1.0}, \"19\": {\"effect\": 0.2747922683146814, \"value\": 1.0}, \"20\": {\"effect\": -0.015815536860673107, \"value\": 0.8}, \"21\": {\"effect\": -0.037796144144229465, \"value\": 0.2060838792736372}, \"22\": {\"effect\": -0.06571119567224956, \"value\": 0.0138691399622683}, \"23\": {\"effect\": -0.28092332142123505, \"value\": -1.4846086848638758}, \"24\": {\"effect\": 0.03438382238883184, \"value\": 5.0}, \"25\": {\"effect\": 0.01645888429289832, \"value\": 5.0}, \"26\": {\"effect\": -0.7071359097985713, \"value\": -0.1763202628756286}, \"27\": {\"effect\": -0.005175706126067581, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.08003582800051745, \"value\": 0.0620134065367428}, \"29\": {\"effect\": -0.0018402352476433554, \"value\": -1.261832491404238}, \"30\": {\"effect\": 0.0921096158664831, \"value\": -0.5450759857533607}, \"31\": {\"effect\": 0.06778087326752628, \"value\": -0.3750053017089326}, \"32\": {\"effect\": -0.00571296085936057, \"value\": 0.344572223022173}, \"33\": {\"effect\": -0.031525321965838175, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0011616984314958556, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.04739907603689863, \"value\": -0.5797121844480827}, \"36\": {\"effect\": -0.003242681412120552, \"value\": -1.1883060184610337}, \"37\": {\"effect\": 0.024793941723286417, \"value\": 0.0}, \"38\": {\"effect\": 0.0011736670727075663, \"value\": 0.0}, \"39\": {\"effect\": 0.05815803567910201, \"value\": 2.0}}}, {\"outValue\": 4.665267782535713, \"simIndex\": 83.0, \"features\": {\"0\": {\"effect\": -0.2832024765788286, \"value\": 0.0}, \"1\": {\"effect\": -0.19206458283903174, \"value\": 1.0}, \"2\": {\"effect\": 0.05940834246968572, \"value\": 1.0}, \"3\": {\"effect\": 0.21881395083689031, \"value\": -0.0716054494345398}, \"4\": {\"effect\": 0.03179936356692852, \"value\": 1.0}, \"5\": {\"effect\": 0.0011879599178546956, \"value\": 1.0}, \"6\": {\"effect\": 0.01964892198762165, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.22727642626028702, \"value\": 2.0}, \"8\": {\"effect\": -0.04274988214237537, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9346824306435495, \"value\": 1.0}, \"11\": {\"effect\": 0.4986227948392716, \"value\": 5.0}, \"12\": {\"effect\": -0.15709403220293314, \"value\": 0.4081147170970374}, \"13\": {\"effect\": 0.04441636970601197, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.006231600465680078, \"value\": 0.0}, \"15\": {\"effect\": 0.2705372824885094, \"value\": 0.0}, \"16\": {\"effect\": -0.48962712662637975, \"value\": 0.1106106362302945}, \"17\": {\"effect\": -0.3643903785314527, \"value\": 0.9}, \"18\": {\"effect\": 0.01556957555201239, \"value\": 1.0}, \"19\": {\"effect\": 0.3180002236761585, \"value\": 1.0}, \"20\": {\"effect\": -0.04160557980519368, \"value\": 0.9}, \"21\": {\"effect\": -0.028481400968772337, \"value\": 0.1106106362302945}, \"22\": {\"effect\": -0.044863192651588356, \"value\": 0.0086511959416975}, \"23\": {\"effect\": 0.45871867824758583, \"value\": 21.35749812227217}, \"24\": {\"effect\": 0.0667325039948562, \"value\": 17.0}, \"25\": {\"effect\": 0.03752795565082723, \"value\": 5.0}, \"26\": {\"effect\": 0.005034169506829874, \"value\": -0.5043502379449072}, \"27\": {\"effect\": -0.004939751305810888, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.04997571543320016, \"value\": 0.5120867880481232}, \"29\": {\"effect\": 0.09502506533715105, \"value\": -1.0657916044049605}, \"30\": {\"effect\": 0.17465000485145404, \"value\": -0.6478046696744966}, \"31\": {\"effect\": 0.14998808964294186, \"value\": -0.3880594190980632}, \"32\": {\"effect\": 0.014426845996791953, \"value\": -0.0716054494345398}, \"33\": {\"effect\": 0.07408801234874617, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.006904648813172628, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1100040040739924, \"value\": -0.5468654746906229}, \"36\": {\"effect\": -0.037051407985401165, \"value\": 0.4081147170970374}, \"37\": {\"effect\": 0.02335725366885368, \"value\": 0.0}, \"38\": {\"effect\": 0.0016418097712217077, \"value\": 0.0}, \"39\": {\"effect\": -0.15439914837825236, \"value\": 3.0}}}, {\"outValue\": 5.516403862613346, \"simIndex\": 66.0, \"features\": {\"0\": {\"effect\": 0.4118144110699234, \"value\": 1.0}, \"1\": {\"effect\": 0.3823490236163765, \"value\": 0.0}, \"2\": {\"effect\": -0.004906060362073015, \"value\": 0.0}, \"3\": {\"effect\": 0.11979459005204582, \"value\": -0.4590812134459622}, \"4\": {\"effect\": 0.037946927416656506, \"value\": 1.0}, \"5\": {\"effect\": 0.000112951639136221, \"value\": 1.0}, \"6\": {\"effect\": 0.0511913707373446, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.19045450212756834, \"value\": 2.0}, \"8\": {\"effect\": 0.1445813568728216, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21539699348780098, \"value\": 0.0}, \"11\": {\"effect\": 0.24116481694336966, \"value\": 2.0}, \"12\": {\"effect\": -0.011099231182984745, \"value\": 3.233928617234408}, \"13\": {\"effect\": -0.24772461508515797, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.009987295424776924, \"value\": 0.0}, \"15\": {\"effect\": 0.2985871008609082, \"value\": 0.0}, \"16\": {\"effect\": 0.20068636283953803, \"value\": 0.4811823553005151}, \"17\": {\"effect\": -0.049555303369498156, \"value\": 0.8}, \"18\": {\"effect\": 0.030474136865687236, \"value\": 1.0}, \"19\": {\"effect\": 0.2146583676010911, \"value\": 1.0}, \"20\": {\"effect\": -0.010448945391689071, \"value\": 0.8}, \"21\": {\"effect\": 0.005335595057787525, \"value\": 0.4811823553005151}, \"22\": {\"effect\": 0.13200377890927364, \"value\": 0.0215093655207356}, \"23\": {\"effect\": -0.023336483286834093, \"value\": -0.605074282328782}, \"24\": {\"effect\": -0.30468672814085745, \"value\": 3.0}, \"25\": {\"effect\": 0.028248862655350825, \"value\": 2.0}, \"26\": {\"effect\": 0.6760679674784106, \"value\": -0.7645119423101971}, \"27\": {\"effect\": -0.0015189594712338875, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.008117153917145566, \"value\": -0.6285566813482152}, \"29\": {\"effect\": -0.05161779836056095, \"value\": 0.1434285770316744}, \"30\": {\"effect\": 0.11855503498906864, \"value\": 0.3790147994780415}, \"31\": {\"effect\": -0.15240329889515153, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.023449587521543358, \"value\": -0.4590812134459622}, \"33\": {\"effect\": 0.2214330587538358, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.002024620830603924, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.06606485528838618, \"value\": 1.0895357679400168}, \"36\": {\"effect\": 0.062264541417662043, \"value\": 3.233928617234408}, \"37\": {\"effect\": 0.03774069344508563, \"value\": 0.0}, \"38\": {\"effect\": 0.0020902529482452106, \"value\": 0.0}, \"39\": {\"effect\": -0.023292811616195404, \"value\": 1.0}}}, {\"outValue\": 5.629898264483467, \"simIndex\": 93.0, \"features\": {\"0\": {\"effect\": 0.37418772599074984, \"value\": 1.0}, \"1\": {\"effect\": -0.4309699873353969, \"value\": 1.0}, \"2\": {\"effect\": -0.011888335785654873, \"value\": 0.0}, \"3\": {\"effect\": 0.024539385254434633, \"value\": -0.7461002978988677}, \"4\": {\"effect\": 0.03779102628207477, \"value\": 1.0}, \"5\": {\"effect\": -0.00016115814948234304, \"value\": 1.0}, \"6\": {\"effect\": 0.04726548725121046, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.086173434952501, \"value\": 1.0}, \"8\": {\"effect\": 0.1808414378903074, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.6322485101923142, \"value\": 1.0}, \"11\": {\"effect\": 0.439761851530654, \"value\": 5.0}, \"12\": {\"effect\": 0.08877264416317938, \"value\": -0.4731493151175738}, \"13\": {\"effect\": 0.10570381016444523, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.012563881018758582, \"value\": 0.0}, \"15\": {\"effect\": 0.21611856040467534, \"value\": 0.0}, \"16\": {\"effect\": 0.1214858067257988, \"value\": 0.9987182381174642}, \"17\": {\"effect\": 0.2580950933789692, \"value\": 0.1}, \"18\": {\"effect\": 0.015521397146064615, \"value\": 1.0}, \"19\": {\"effect\": 0.23351530102357976, \"value\": 1.0}, \"20\": {\"effect\": 0.07603555094566485, \"value\": 0.1}, \"21\": {\"effect\": 0.030613662407133525, \"value\": 0.9987182381174642}, \"22\": {\"effect\": -0.5787116270443347, \"value\": 3.35122213790062}, \"23\": {\"effect\": 0.43573086692215185, \"value\": 49.07401604230266}, \"24\": {\"effect\": 0.007399841421509693, \"value\": 10.0}, \"25\": {\"effect\": 0.02608841056814146, \"value\": 5.0}, \"26\": {\"effect\": -0.24939756564266005, \"value\": 1.6900571814840597}, \"27\": {\"effect\": 0.007664978419833697, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.003651656629262873, \"value\": 0.2108433545602651}, \"29\": {\"effect\": 0.016837393656021424, \"value\": -0.0850582934858596}, \"30\": {\"effect\": 0.1761874317365371, \"value\": -0.655815634901328}, \"31\": {\"effect\": 0.1179188654412655, \"value\": -0.3684782430143673}, \"32\": {\"effect\": 0.010276607019388668, \"value\": -0.7461002978988677}, \"33\": {\"effect\": 0.15411635429389703, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.0024966987710279913, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.06903325568268677, \"value\": -0.3439182011556325}, \"36\": {\"effect\": 0.029199091577863677, \"value\": -0.4731493151175738}, \"37\": {\"effect\": 0.0249724467901479, \"value\": 0.0}, \"38\": {\"effect\": 0.0026812265493454924, \"value\": 0.0}, \"39\": {\"effect\": 0.09645793432636941, \"value\": 2.0}}}, {\"outValue\": 6.192032346833923, \"simIndex\": 68.0, \"features\": {\"0\": {\"effect\": 0.49205812267695026, \"value\": 1.0}, \"1\": {\"effect\": -0.27353788673015983, \"value\": 1.0}, \"2\": {\"effect\": -0.024660150131469567, \"value\": 0.0}, \"3\": {\"effect\": 0.16277421887050483, \"value\": -0.5451869387818339}, \"4\": {\"effect\": 0.03568881083680491, \"value\": 1.0}, \"5\": {\"effect\": 0.0008864687929990781, \"value\": 1.0}, \"6\": {\"effect\": 0.05139768956306203, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.08672027346352826, \"value\": 1.0}, \"8\": {\"effect\": 0.24700535471411075, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.20693886514073137, \"value\": 0.0}, \"11\": {\"effect\": 0.1874832585932184, \"value\": 4.0}, \"12\": {\"effect\": 0.6986010733660638, \"value\": -1.2867768301870457}, \"13\": {\"effect\": 0.09372271871196527, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.011885346258021623, \"value\": 0.0}, \"15\": {\"effect\": 0.2787382308771286, \"value\": 0.0}, \"16\": {\"effect\": 0.20317637395511706, \"value\": 0.4142159600918499}, \"17\": {\"effect\": -0.03237031397993012, \"value\": 0.8}, \"18\": {\"effect\": 0.024015167792373525, \"value\": 1.0}, \"19\": {\"effect\": 0.36403145213988936, \"value\": 1.0}, \"20\": {\"effect\": -0.025584472097296067, \"value\": 0.8}, \"21\": {\"effect\": -0.029025154086837972, \"value\": 0.4142159600918499}, \"22\": {\"effect\": -0.017532307090187955, \"value\": 0.0074448698104111}, \"23\": {\"effect\": -0.06188294950707965, \"value\": -0.9092391068806444}, \"24\": {\"effect\": 0.01585990496634581, \"value\": 6.0}, \"25\": {\"effect\": 0.020703324919408562, \"value\": 4.0}, \"26\": {\"effect\": 0.9821739942841379, \"value\": -0.8776257268168449}, \"27\": {\"effect\": -0.004652878852984834, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.051889793121880405, \"value\": -1.4174289712920645}, \"29\": {\"effect\": 0.01983375824652123, \"value\": -1.2651411187262174}, \"30\": {\"effect\": -0.1671876345782067, \"value\": -1.9107905951685125}, \"31\": {\"effect\": 0.0277935905446478, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.014577235220493952, \"value\": -0.5451869387818339}, \"33\": {\"effect\": 0.2151847458428399, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.004227135118557414, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.16175196814478313, \"value\": 0.188739950573121}, \"36\": {\"effect\": 0.010313785093258757, \"value\": -1.2867768301870457}, \"37\": {\"effect\": 0.023611211812592483, \"value\": 0.0}, \"38\": {\"effect\": 0.002939054648661139, \"value\": 0.0}, \"39\": {\"effect\": -0.08784515219427266, \"value\": 3.0}}}, {\"outValue\": 2.8504873200121534, \"simIndex\": 78.0, \"features\": {\"0\": {\"effect\": 0.44502515777499996, \"value\": 1.0}, \"1\": {\"effect\": 0.30209861227749857, \"value\": 0.0}, \"2\": {\"effect\": 0.04153221318853906, \"value\": 1.0}, \"3\": {\"effect\": -0.006916722214990713, \"value\": 0.2154136350183655}, \"4\": {\"effect\": 0.032727602457562815, \"value\": 1.0}, \"5\": {\"effect\": -0.0017178119933259008, \"value\": 1.0}, \"6\": {\"effect\": 0.07529694494610555, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.08167205403880237, \"value\": 3.0}, \"8\": {\"effect\": -0.06597970384487475, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9253422296566967, \"value\": 1.0}, \"11\": {\"effect\": 0.2886523260510812, \"value\": 2.0}, \"12\": {\"effect\": 0.006865026197437276, \"value\": -0.8799630726523097}, \"13\": {\"effect\": -0.6839060043656668, \"value\": 2.187874078283813}, \"14\": {\"effect\": 0.012468123151252227, \"value\": 0.0}, \"15\": {\"effect\": 0.3349278778548572, \"value\": 0.0}, \"16\": {\"effect\": -0.44730903353150603, \"value\": 0.1564632172356464}, \"17\": {\"effect\": -0.465296218151172, \"value\": 0.9}, \"18\": {\"effect\": 0.009897452438242992, \"value\": 1.0}, \"19\": {\"effect\": 0.2065393841970562, \"value\": 1.0}, \"20\": {\"effect\": -0.05687310516953271, \"value\": 0.9}, \"21\": {\"effect\": -0.027910829823067806, \"value\": 0.1564632172356464}, \"22\": {\"effect\": -0.013666633167509431, \"value\": 0.0105618046708123}, \"23\": {\"effect\": -0.26406436341928474, \"value\": -1.4355360095965857}, \"24\": {\"effect\": -0.5471748787321613, \"value\": 2.0}, \"25\": {\"effect\": 0.03138484140061254, \"value\": 2.0}, \"26\": {\"effect\": 0.0879041739482958, \"value\": -0.5948412655502254}, \"27\": {\"effect\": -0.03794829750583707, \"value\": 2.187874078283813}, \"28\": {\"effect\": -0.00163970046915242, \"value\": -0.7866647783930796}, \"29\": {\"effect\": -0.08890772322349731, \"value\": 0.4994477862816683}, \"30\": {\"effect\": 0.11308503440223558, \"value\": 0.0801793399739205}, \"31\": {\"effect\": -0.27399800824258713, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.013890688671018524, \"value\": 0.2154136350183655}, \"33\": {\"effect\": -0.010965727432393737, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.007107359491466289, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.07727845638822525, \"value\": -0.6009311120340071}, \"36\": {\"effect\": 0.0011582779485896394, \"value\": -0.8799630726523097}, \"37\": {\"effect\": 0.03544851599757556, \"value\": 0.0}, \"38\": {\"effect\": 0.0011942645565370764, \"value\": 0.0}, \"39\": {\"effect\": 0.11974030330004944, \"value\": 2.0}}}, {\"outValue\": 1.7413733111953897, \"simIndex\": 46.0, \"features\": {\"0\": {\"effect\": -0.3558011575115563, \"value\": 0.0}, \"1\": {\"effect\": 0.29140823670538957, \"value\": 0.0}, \"2\": {\"effect\": -0.03337673097206762, \"value\": 0.0}, \"3\": {\"effect\": 0.19480909987203746, \"value\": -0.2868697627742189}, \"4\": {\"effect\": 0.0372220435117263, \"value\": 1.0}, \"5\": {\"effect\": 0.00017188153677632296, \"value\": 1.0}, \"6\": {\"effect\": 0.01196710018358927, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10175326501244901, \"value\": 1.0}, \"8\": {\"effect\": -0.06218867427254543, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2465557919593051, \"value\": 0.0}, \"11\": {\"effect\": 0.15955696946370757, \"value\": 3.0}, \"12\": {\"effect\": 0.0002018470607563801, \"value\": -0.2045925558648142}, \"13\": {\"effect\": 0.05410031811660129, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.010774956090883536, \"value\": 0.0}, \"15\": {\"effect\": -0.7324639600582434, \"value\": 1.0}, \"16\": {\"effect\": -0.4566406598947908, \"value\": 0.1403616920368182}, \"17\": {\"effect\": -0.4183249410516525, \"value\": 0.9}, \"18\": {\"effect\": 0.013202715645820802, \"value\": 1.0}, \"19\": {\"effect\": 0.24331498319376194, \"value\": 1.0}, \"20\": {\"effect\": -0.053420317680193806, \"value\": 0.9}, \"21\": {\"effect\": -0.034756432476637684, \"value\": 0.1403616920368182}, \"22\": {\"effect\": 0.30031729762008297, \"value\": 0.035233677867892}, \"23\": {\"effect\": 0.3488360816477981, \"value\": 27.307914162737696}, \"24\": {\"effect\": -0.010818238498026718, \"value\": 6.0}, \"25\": {\"effect\": 0.03184599726443122, \"value\": 3.0}, \"26\": {\"effect\": -0.7072395457841725, \"value\": -0.2441885335796173}, \"27\": {\"effect\": 0.0010316662789136403, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.03782130014870948, \"value\": -0.4966656237784947}, \"29\": {\"effect\": -0.08187106730313211, \"value\": 0.8210038965543722}, \"30\": {\"effect\": 0.030402396937107275, \"value\": 0.6722033952479106}, \"31\": {\"effect\": 0.28177552781797843, \"value\": -0.3597754980882803}, \"32\": {\"effect\": 0.017865220352055358, \"value\": -0.2868697627742189}, \"33\": {\"effect\": 0.005308381466503079, \"value\": 0.7560284263287593}, \"34\": {\"effect\": 0.0018857503573677997, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.03953120277007192, \"value\": 1.4026538641361106}, \"36\": {\"effect\": 0.03101896200204376, \"value\": -0.2045925558648142}, \"37\": {\"effect\": 0.016910174409881747, \"value\": 0.0}, \"38\": {\"effect\": 0.0010443339608481312, \"value\": 0.0}, \"39\": {\"effect\": -0.03716653256271128, \"value\": 1.0}}}, {\"outValue\": 1.956603620254223, \"simIndex\": 56.0, \"features\": {\"0\": {\"effect\": -0.37598393198961544, \"value\": 0.0}, \"1\": {\"effect\": -0.27867586575854525, \"value\": 1.0}, \"2\": {\"effect\": -0.022844009881825663, \"value\": 0.0}, \"3\": {\"effect\": -0.016429064772899127, \"value\": 1.0190670714865009}, \"4\": {\"effect\": 0.036664558901403105, \"value\": 1.0}, \"5\": {\"effect\": 3.196835510852306e-05, \"value\": 1.0}, \"6\": {\"effect\": -0.05659194898918181, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.13109518466642014, \"value\": 1.0}, \"8\": {\"effect\": -0.061443981417857306, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.20618788277087335, \"value\": 0.0}, \"11\": {\"effect\": 0.22866774138069185, \"value\": 3.0}, \"12\": {\"effect\": 0.08380388257493339, \"value\": -0.6312994066775323}, \"13\": {\"effect\": 0.019692621784992786, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.017316564259703224, \"value\": 0.0}, \"15\": {\"effect\": -0.7806185154690187, \"value\": 1.0}, \"16\": {\"effect\": 0.1737203061094596, \"value\": 0.9970402809198936}, \"17\": {\"effect\": -0.4267229106793679, \"value\": 0.9}, \"18\": {\"effect\": -0.0032672886057831165, \"value\": 1.0}, \"19\": {\"effect\": 0.3509092959179172, \"value\": 1.0}, \"20\": {\"effect\": -0.06933603128674297, \"value\": 0.9}, \"21\": {\"effect\": 0.044121767381980544, \"value\": 0.9970402809198936}, \"22\": {\"effect\": -0.041552261681621294, \"value\": 0.0161529339663407}, \"23\": {\"effect\": -0.11465492081249505, \"value\": -0.7820004376862214}, \"24\": {\"effect\": 0.08425293118591783, \"value\": 12.0}, \"25\": {\"effect\": 0.02628451674938045, \"value\": 3.0}, \"26\": {\"effect\": 0.63425313630019, \"value\": -0.6853322931555437}, \"27\": {\"effect\": -0.0049682639189346164, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.03291532027532395, \"value\": -1.434248427856879}, \"29\": {\"effect\": -0.03235420341146244, \"value\": 0.547713384554009}, \"30\": {\"effect\": 0.11852957564877516, \"value\": -0.5380101793780183}, \"31\": {\"effect\": -0.22427703809222874, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.023799854730939506, \"value\": 1.0190670714865009}, \"33\": {\"effect\": -0.044992716861711655, \"value\": -0.9770926399944632}, \"34\": {\"effect\": -0.012704939393539895, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.08614500363612504, \"value\": 1.2274223303847962}, \"36\": {\"effect\": -0.018370476938949214, \"value\": -0.6312994066775323}, \"37\": {\"effect\": 0.019339028395191457, \"value\": 0.0}, \"38\": {\"effect\": 0.0013270808037665368, \"value\": 0.0}, \"39\": {\"effect\": 0.0999040714559923, \"value\": 2.0}}}, {\"outValue\": 3.5646355550631044, \"simIndex\": 90.0, \"features\": {\"0\": {\"effect\": -0.36511964312674594, \"value\": 0.0}, \"1\": {\"effect\": -0.3137517503226883, \"value\": 1.0}, \"2\": {\"effect\": 0.028509333343343216, \"value\": 1.0}, \"3\": {\"effect\": 0.19880908184178264, \"value\": -0.0859564036571851}, \"4\": {\"effect\": 0.03386577037902398, \"value\": 1.0}, \"5\": {\"effect\": 0.0010086698735187654, \"value\": 1.0}, \"6\": {\"effect\": 0.043002316822908296, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.12712375362429285, \"value\": 1.0}, \"8\": {\"effect\": -0.07334920915937612, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8282032890569716, \"value\": 1.0}, \"11\": {\"effect\": 0.27891115156392393, \"value\": 2.0}, \"12\": {\"effect\": -0.08339193123968237, \"value\": 0.1395579578442777}, \"13\": {\"effect\": 0.032213984179203216, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.012301546561586428, \"value\": 0.0}, \"15\": {\"effect\": 0.264166698590578, \"value\": 0.0}, \"16\": {\"effect\": -0.47582103742974124, \"value\": 0.0708682914508214}, \"17\": {\"effect\": 0.24736595721444551, \"value\": 0.3}, \"18\": {\"effect\": 0.01755571999415812, \"value\": 1.0}, \"19\": {\"effect\": -0.1846528787311031, \"value\": 0.0}, \"20\": {\"effect\": 0.038730121979019094, \"value\": 0.3}, \"21\": {\"effect\": -0.018965341829111942, \"value\": 0.0708682914508214}, \"22\": {\"effect\": 0.14110643990984134, \"value\": 0.0233797415018459}, \"23\": {\"effect\": -0.10150620939879232, \"value\": -0.6636277991569788}, \"24\": {\"effect\": 0.03716358437068891, \"value\": 9.0}, \"25\": {\"effect\": 0.023179545097135937, \"value\": 2.0}, \"26\": {\"effect\": -0.48814682780898866, \"value\": -0.0179609645663217}, \"27\": {\"effect\": -0.0006408537592304743, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.03835330882004491, \"value\": 2.3694793192071253}, \"29\": {\"effect\": -0.054493178565033495, \"value\": 1.130205306510044}, \"30\": {\"effect\": 0.156799280375328, \"value\": 0.2320548469976098}, \"31\": {\"effect\": 0.44139416759815603, \"value\": 0.5409586017617283}, \"32\": {\"effect\": 0.008187743046717225, \"value\": -0.0859564036571851}, \"33\": {\"effect\": 0.08151307951937574, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.0013717075823675257, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.14161542028483554, \"value\": -0.3052557541788284}, \"36\": {\"effect\": -0.009894749590229493, \"value\": 0.1395579578442777}, \"37\": {\"effect\": 0.024257294202955446, \"value\": 0.0}, \"38\": {\"effect\": 0.004998799483929666, \"value\": 0.0}, \"39\": {\"effect\": 0.18542018434801139, \"value\": 2.0}}}, {\"outValue\": 3.5385934393162457, \"simIndex\": 73.0, \"features\": {\"0\": {\"effect\": 0.5315292319844903, \"value\": 1.0}, \"1\": {\"effect\": -0.2508311865059214, \"value\": 1.0}, \"2\": {\"effect\": 0.05485898013177789, \"value\": 1.0}, \"3\": {\"effect\": -0.0945106727880706, \"value\": 1.0477689799317913}, \"4\": {\"effect\": -1.042228240295632, \"value\": 2.0}, \"5\": {\"effect\": 0.0010460776527952194, \"value\": 1.0}, \"6\": {\"effect\": -0.026996098557515766, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10915473159563444, \"value\": 1.0}, \"8\": {\"effect\": -0.13977576658313784, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21788759278138334, \"value\": 0.0}, \"11\": {\"effect\": 0.48033545997556054, \"value\": 5.0}, \"12\": {\"effect\": 0.05997397523846569, \"value\": -0.221501685151099}, \"13\": {\"effect\": 0.18636132861414564, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.007395052031604933, \"value\": 0.0}, \"15\": {\"effect\": 0.2515778750193758, \"value\": 0.0}, \"16\": {\"effect\": 0.25283285416070483, \"value\": 0.7247549367845437}, \"17\": {\"effect\": 0.17833693384771518, \"value\": 0.2}, \"18\": {\"effect\": 0.02135288366597567, \"value\": 1.0}, \"19\": {\"effect\": -0.45189607587282027, \"value\": 0.0}, \"20\": {\"effect\": 0.02182593442834213, \"value\": 0.2}, \"21\": {\"effect\": 0.0910739927343902, \"value\": 0.7247549367845437}, \"22\": {\"effect\": -0.645992251633916, \"value\": 69.91814651603755}, \"23\": {\"effect\": 0.4029401701011383, \"value\": 100.0235465738382}, \"24\": {\"effect\": 0.08212676199493496, \"value\": 13.0}, \"25\": {\"effect\": 0.03734061392522971, \"value\": 5.0}, \"26\": {\"effect\": 0.8380283276342603, \"value\": -0.922871240619504}, \"27\": {\"effect\": 0.003048940094295114, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.14794275546152136, \"value\": -0.0499642908133406}, \"29\": {\"effect\": 0.0054049684775933065, \"value\": 0.1172725726794637}, \"30\": {\"effect\": 0.08483421513763217, \"value\": 0.3570155927744334}, \"31\": {\"effect\": -0.28817095215441907, \"value\": -0.3989378502556719}, \"32\": {\"effect\": -0.012393020485930436, \"value\": 1.0477689799317913}, \"33\": {\"effect\": 0.027318452605736152, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.0007945036300811651, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.4580322247736989, \"value\": -0.7587545978451201}, \"36\": {\"effect\": 0.020996969378566332, \"value\": -0.221501685151099}, \"37\": {\"effect\": 0.02184508741565347, \"value\": 0.0}, \"38\": {\"effect\": 0.0018442845846916387, \"value\": 0.0}, \"39\": {\"effect\": -0.06810949702473837, \"value\": 1.0}}}, {\"outValue\": 3.397722597258955, \"simIndex\": 42.0, \"features\": {\"0\": {\"effect\": -0.35644123090849006, \"value\": 0.0}, \"1\": {\"effect\": -0.2446704306328012, \"value\": 1.0}, \"2\": {\"effect\": -0.01153792311408467, \"value\": 0.0}, \"3\": {\"effect\": 0.11830755458368435, \"value\": -0.502134076113898}, \"4\": {\"effect\": 0.027752895602140917, \"value\": 1.0}, \"5\": {\"effect\": 0.000218104872152839, \"value\": 1.0}, \"6\": {\"effect\": 0.03591802716311485, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.5898720666980797, \"value\": 4.0}, \"8\": {\"effect\": 0.14455278952884137, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.18413460396516562, \"value\": 0.0}, \"11\": {\"effect\": 0.22978656835241756, \"value\": 2.0}, \"12\": {\"effect\": -0.070481354412094, \"value\": 0.0908198793132213}, \"13\": {\"effect\": 0.26040650389172687, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.006378994339653692, \"value\": 0.0}, \"15\": {\"effect\": 0.300064261055867, \"value\": 0.0}, \"16\": {\"effect\": 0.14929124759423662, \"value\": 0.4000087856537531}, \"17\": {\"effect\": 0.20276443815543926, \"value\": 0.4}, \"18\": {\"effect\": 0.01424465022651611, \"value\": 1.0}, \"19\": {\"effect\": -0.2688996539862533, \"value\": 0.0}, \"20\": {\"effect\": 0.021366662312238407, \"value\": 0.4}, \"21\": {\"effect\": -0.002094207803292372, \"value\": 0.4000087856537531}, \"22\": {\"effect\": -0.026240358393067858, \"value\": 0.0141369580639306}, \"23\": {\"effect\": -0.06761729824957712, \"value\": -0.6056601420283743}, \"24\": {\"effect\": 0.022293784691789494, \"value\": 9.0}, \"25\": {\"effect\": 0.04601109246070104, \"value\": 2.0}, \"26\": {\"effect\": -0.6315528161018826, \"value\": -0.1310747490729695}, \"27\": {\"effect\": 0.02285916882756911, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.04430817756091421, \"value\": 0.2223196339099332}, \"29\": {\"effect\": -0.10648802258108028, \"value\": 0.9392691923695023}, \"30\": {\"effect\": 0.22064684744431787, \"value\": 0.3038042941265529}, \"31\": {\"effect\": 0.026519219151411363, \"value\": -0.3706539292458891}, \"32\": {\"effect\": 0.008297298772454973, \"value\": -0.502134076113898}, \"33\": {\"effect\": 0.08380741758216467, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.0034468023609132018, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.0472156590475146, \"value\": 1.6270283483843555}, \"36\": {\"effect\": -0.012583818295855182, \"value\": 0.0908198793132213}, \"37\": {\"effect\": 0.02064742963482941, \"value\": 0.0}, \"38\": {\"effect\": 0.0032975296551559065, \"value\": 0.0}, \"39\": {\"effect\": -0.0868057395862478, \"value\": 1.0}}}, {\"outValue\": 2.4262146764813233, \"simIndex\": 18.0, \"features\": {\"0\": {\"effect\": 0.5653599661814288, \"value\": 1.0}, \"1\": {\"effect\": -0.3112917296319996, \"value\": 1.0}, \"2\": {\"effect\": 0.00034280436896694987, \"value\": 1.0}, \"3\": {\"effect\": 0.07884847935595704, \"value\": -0.5882398014497696}, \"4\": {\"effect\": 0.035597576498956944, \"value\": 1.0}, \"5\": {\"effect\": 0.00029459362410819086, \"value\": 1.0}, \"6\": {\"effect\": 0.0515543958096632, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12024262762344669, \"value\": 1.0}, \"8\": {\"effect\": -0.10398332337853494, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.2313980373757065, \"value\": 0.0}, \"11\": {\"effect\": 0.23851108554291292, \"value\": 3.0}, \"12\": {\"effect\": 0.06577867915067698, \"value\": -0.4940370630594551}, \"13\": {\"effect\": -0.183546331319397, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.010672165724132215, \"value\": 0.0}, \"15\": {\"effect\": 0.31521895353320223, \"value\": 0.0}, \"16\": {\"effect\": 0.5106179310204978, \"value\": 0.9919814384154968}, \"17\": {\"effect\": -0.3142982489695546, \"value\": 0.9}, \"18\": {\"effect\": -0.07961583100211858, \"value\": 0.0}, \"19\": {\"effect\": -0.31553483304050256, \"value\": 0.0}, \"20\": {\"effect\": -0.08227873544447595, \"value\": 0.9}, \"21\": {\"effect\": 0.04718412010187231, \"value\": 0.9919814384154968}, \"22\": {\"effect\": -0.5159035092810159, \"value\": 25.54738303404452}, \"23\": {\"effect\": 0.08427294044497469, \"value\": -0.4755397614288425}, \"24\": {\"effect\": 0.10400870203518736, \"value\": 9.0}, \"25\": {\"effect\": 0.017843245892921, \"value\": 3.0}, \"26\": {\"effect\": -0.6381920249807137, \"value\": 0.0838414414896612}, \"27\": {\"effect\": 0.00800649353952919, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.016507533807752005, \"value\": -0.4709390566393988}, \"29\": {\"effect\": 0.0034350129692697702, \"value\": -0.199687142453285}, \"30\": {\"effect\": 0.16787166712506532, \"value\": -0.4721433118165544}, \"31\": {\"effect\": -0.17876886342277123, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.01296115371870216, \"value\": -0.5882398014497696}, \"33\": {\"effect\": -0.0625639783581523, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0025919241190429086, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09078954957692337, \"value\": 0.2752363485371405}, \"36\": {\"effect\": 0.018543542613768706, \"value\": -0.4940370630594551}, \"37\": {\"effect\": 0.03077983580252956, \"value\": 0.0}, \"38\": {\"effect\": 0.0007790231571429677, \"value\": 0.0}, \"39\": {\"effect\": 0.17403519277649734, \"value\": 2.0}}}, {\"outValue\": 5.572792641511743, \"simIndex\": 21.0, \"features\": {\"0\": {\"effect\": 0.5885828009602253, \"value\": 1.0}, \"1\": {\"effect\": 0.24926112397812342, \"value\": 0.0}, \"2\": {\"effect\": -0.01890516409913273, \"value\": 0.0}, \"3\": {\"effect\": 0.06673230886397903, \"value\": -0.9183117485706108}, \"4\": {\"effect\": 0.05215704451776587, \"value\": 1.0}, \"5\": {\"effect\": -3.3686804167755595e-05, \"value\": 1.0}, \"6\": {\"effect\": 0.0433835619960439, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.4368130340605902, \"value\": 5.0}, \"8\": {\"effect\": -0.0633629982183286, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.217511375388435, \"value\": 0.0}, \"11\": {\"effect\": 0.4900070882204619, \"value\": 5.0}, \"12\": {\"effect\": 0.17410819085963497, \"value\": -1.235054787664292}, \"13\": {\"effect\": 0.13032072970722583, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.013531947049469232, \"value\": 0.0}, \"15\": {\"effect\": 0.21046265169129427, \"value\": 0.0}, \"16\": {\"effect\": 0.1845229431432435, \"value\": 0.4934185957400509}, \"17\": {\"effect\": 0.313566600725567, \"value\": 0.2}, \"18\": {\"effect\": 0.03212548949009033, \"value\": 1.0}, \"19\": {\"effect\": -0.37028244527817444, \"value\": 0.0}, \"20\": {\"effect\": 0.046261963786519596, \"value\": 0.2}, \"21\": {\"effect\": 0.05999165973279747, \"value\": 0.4934185957400509}, \"22\": {\"effect\": 0.34025150927823195, \"value\": 0.0385331774791204}, \"23\": {\"effect\": -0.08084660804132456, \"value\": -0.8211700893282886}, \"24\": {\"effect\": -0.009515609848564215, \"value\": 5.0}, \"25\": {\"effect\": 0.01223440432336133, \"value\": 5.0}, \"26\": {\"effect\": 0.29579406210053316, \"value\": -0.6400867793528845}, \"27\": {\"effect\": 0.004352386625314997, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.054704333240474655, \"value\": -0.4613704105692202}, \"29\": {\"effect\": -0.07212551771599131, \"value\": 0.8322693856691558}, \"30\": {\"effect\": -0.11145098663040913, \"value\": -1.8656643984257488}, \"31\": {\"effect\": 0.12844626293364417, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.014971269602741389, \"value\": -0.9183117485706108}, \"33\": {\"effect\": 0.17357229480460526, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0004901613849846317, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.07372107462899895, \"value\": -0.4290302096020846}, \"36\": {\"effect\": -0.10537667900901607, \"value\": -1.235054787664292}, \"37\": {\"effect\": -0.25513028793926606, \"value\": 1.0}, \"38\": {\"effect\": 0.002320753685112228, \"value\": 0.0}, \"39\": {\"effect\": -0.07933768346651446, \"value\": 1.0}}}, {\"outValue\": 3.0880184704507228, \"simIndex\": 44.0, \"features\": {\"0\": {\"effect\": -0.32868018848223407, \"value\": 0.0}, \"1\": {\"effect\": 0.24617491328882293, \"value\": 0.0}, \"2\": {\"effect\": 0.039104456550789445, \"value\": 1.0}, \"3\": {\"effect\": 0.08218246680150457, \"value\": -0.8896098401253204}, \"4\": {\"effect\": 0.02384449749774571, \"value\": 1.0}, \"5\": {\"effect\": 0.0008706634543855203, \"value\": 1.0}, \"6\": {\"effect\": 0.028344619274049843, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.13453549273359888, \"value\": 1.0}, \"8\": {\"effect\": -0.03838559827081337, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21385300564630771, \"value\": 0.0}, \"11\": {\"effect\": 0.5685286507025245, \"value\": 5.0}, \"12\": {\"effect\": -0.24544540022884487, \"value\": 0.3703178398688712}, \"13\": {\"effect\": 0.22203139304887456, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.006718697879171063, \"value\": 0.0}, \"15\": {\"effect\": 0.25289512731235136, \"value\": 0.0}, \"16\": {\"effect\": 0.19245502368709844, \"value\": 0.7662394195194531}, \"17\": {\"effect\": 0.22350174984975385, \"value\": 0.2}, \"18\": {\"effect\": 0.020375921493241092, \"value\": 1.0}, \"19\": {\"effect\": 0.3192315522619906, \"value\": 1.0}, \"20\": {\"effect\": 0.06607755711021637, \"value\": 0.2}, \"21\": {\"effect\": 0.07033652907785627, \"value\": 0.7662394195194531}, \"22\": {\"effect\": -0.028583876960407196, \"value\": 0.0159383173283264}, \"23\": {\"effect\": -0.2009877521001882, \"value\": -1.131641786557652}, \"24\": {\"effect\": 0.045439465162769005, \"value\": 11.0}, \"25\": {\"effect\": 0.0433123566456216, \"value\": 5.0}, \"26\": {\"effect\": -0.5623215807850872, \"value\": 0.4344941734602693}, \"27\": {\"effect\": 0.007548289661759183, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.028572374271097406, \"value\": -0.5359883621549663}, \"29\": {\"effect\": 0.10462295455605804, \"value\": -0.860430305587644}, \"30\": {\"effect\": -0.20260661471071545, \"value\": -0.776694796514561}, \"31\": {\"effect\": 0.10451108505713831, \"value\": -0.3902351053295849}, \"32\": {\"effect\": 0.012601270960602132, \"value\": -0.8896098401253204}, \"33\": {\"effect\": -0.393315414250854, \"value\": 1.5813241721969604}, \"34\": {\"effect\": 0.001540939670190383, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.012885998893939814, \"value\": -0.784634332826866}, \"36\": {\"effect\": -0.04364594005556511, \"value\": 0.3703178398688712}, \"37\": {\"effect\": 0.016784044729150776, \"value\": 0.0}, \"38\": {\"effect\": 0.0021347857979319646, \"value\": 0.0}, \"39\": {\"effect\": -0.14790223405144712, \"value\": 3.0}}}, {\"outValue\": 5.6790708304752116, \"simIndex\": 61.0, \"features\": {\"0\": {\"effect\": -0.35207656697662576, \"value\": 0.0}, \"1\": {\"effect\": 0.3694973262225501, \"value\": 0.0}, \"2\": {\"effect\": 0.07247608983889546, \"value\": 1.0}, \"3\": {\"effect\": 0.18474217336591595, \"value\": -0.1577111747704115}, \"4\": {\"effect\": 0.036876704973881194, \"value\": 1.0}, \"5\": {\"effect\": 0.0007664980372015912, \"value\": 1.0}, \"6\": {\"effect\": 0.06287448386377441, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.11433351814210824, \"value\": 1.0}, \"8\": {\"effect\": -0.07570061905578598, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21499414983043774, \"value\": 0.0}, \"11\": {\"effect\": 0.24603153547446086, \"value\": 3.0}, \"12\": {\"effect\": 0.08650314788102237, \"value\": -0.5179087749930338}, \"13\": {\"effect\": 0.24578804273590174, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.006568168396803845, \"value\": 0.0}, \"15\": {\"effect\": 0.2883279382782204, \"value\": 0.0}, \"16\": {\"effect\": -0.4190513857179753, \"value\": 0.1046006086375311}, \"17\": {\"effect\": 0.18365410823001954, \"value\": 0.2}, \"18\": {\"effect\": 0.010278718408953273, \"value\": 1.0}, \"19\": {\"effect\": -0.3403849521120789, \"value\": 0.0}, \"20\": {\"effect\": 0.0381833524270268, \"value\": 0.2}, \"21\": {\"effect\": -0.006238467804292262, \"value\": 0.1046006086375311}, \"22\": {\"effect\": -0.09114085791452534, \"value\": 0.0042674325733836}, \"23\": {\"effect\": 0.5169117734068204, \"value\": 51.36713515430231}, \"24\": {\"effect\": -0.061581749367092035, \"value\": 4.0}, \"25\": {\"effect\": 0.028406646347969546, \"value\": 3.0}, \"26\": {\"effect\": 1.0248282870282472, \"value\": -0.8663143483661802}, \"27\": {\"effect\": 0.006537908090221099, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.0038456417246565313, \"value\": 1.1830620014078956}, \"29\": {\"effect\": 0.08366387832029487, \"value\": -0.4130522388976846}, \"30\": {\"effect\": 0.18367753840892198, \"value\": 0.2962333108970576}, \"31\": {\"effect\": 0.368005272337793, \"value\": 1.1153397668834728}, \"32\": {\"effect\": 0.013473549821656088, \"value\": -0.1577111747704115}, \"33\": {\"effect\": 0.1876035163476058, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.0018817607517405712, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.037478984246975794, \"value\": -0.6473329644311107}, \"36\": {\"effect\": 0.027963758753866738, \"value\": -0.5179087749930338}, \"37\": {\"effect\": 0.026582962091783933, \"value\": 0.0}, \"38\": {\"effect\": 0.0039556438360834915, \"value\": 0.0}, \"39\": {\"effect\": 0.17841075787210267, \"value\": 2.0}}}, {\"outValue\": 2.9056645949580275, \"simIndex\": 89.0, \"features\": {\"0\": {\"effect\": -0.3015954411520944, \"value\": 0.0}, \"1\": {\"effect\": -0.3360513971280784, \"value\": 1.0}, \"2\": {\"effect\": 0.03690121809921977, \"value\": 1.0}, \"3\": {\"effect\": -0.2762275033760354, \"value\": 1.50699951505644}, \"4\": {\"effect\": 0.03355001460377584, \"value\": 1.0}, \"5\": {\"effect\": 0.0019283411494851498, \"value\": 1.0}, \"6\": {\"effect\": -0.1485177295734739, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.1574767235393114, \"value\": 1.0}, \"8\": {\"effect\": -0.05021549985618282, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.8118921656745701, \"value\": 1.0}, \"11\": {\"effect\": 0.12754867232398398, \"value\": 3.0}, \"12\": {\"effect\": -0.16202375728919585, \"value\": 1.9925995966883192}, \"13\": {\"effect\": 0.024895905682752163, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010837359657386655, \"value\": 0.0}, \"15\": {\"effect\": 0.25020201012306886, \"value\": 0.0}, \"16\": {\"effect\": 0.1726072096975347, \"value\": 0.7052369127470163}, \"17\": {\"effect\": 0.2901024754361037, \"value\": 0.2}, \"18\": {\"effect\": 0.01250050588980582, \"value\": 1.0}, \"19\": {\"effect\": -0.3537847238457646, \"value\": 0.0}, \"20\": {\"effect\": 0.051600948693952736, \"value\": 0.2}, \"21\": {\"effect\": 0.02696062848233108, \"value\": 0.7052369127470163}, \"22\": {\"effect\": 0.1271877205628815, \"value\": 0.0205999593675372}, \"23\": {\"effect\": -0.2934369662761499, \"value\": -1.3580328226840268}, \"24\": {\"effect\": 0.05373773778396935, \"value\": 7.0}, \"25\": {\"effect\": 0.03202927256763305, \"value\": 3.0}, \"26\": {\"effect\": -0.49693206984605026, \"value\": -0.4477933456915833}, \"27\": {\"effect\": -0.00100424876837165, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.17532467396333487, \"value\": 2.108388302074217}, \"29\": {\"effect\": -0.05994743767558147, \"value\": 0.87730427622897}, \"30\": {\"effect\": 0.07967733759579858, \"value\": -0.1775915438878483}, \"31\": {\"effect\": 0.07378126719310037, \"value\": -0.3728296154774109}, \"32\": {\"effect\": -0.018026172280290683, \"value\": 1.50699951505644}, \"33\": {\"effect\": 0.11654213470955921, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.0024948255110498023, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.006483833018791343, \"value\": -0.717388302089682}, \"36\": {\"effect\": -0.024902114122078312, \"value\": 1.9925995966883192}, \"37\": {\"effect\": 0.02401885923448649, \"value\": 0.0}, \"38\": {\"effect\": 0.0030339369017393382, \"value\": 0.0}, \"39\": {\"effect\": 0.1464984603720236, \"value\": 2.0}}}, {\"outValue\": 1.60753417185219, \"simIndex\": 14.0, \"features\": {\"0\": {\"effect\": 0.556302888309391, \"value\": 1.0}, \"1\": {\"effect\": 0.3662454129720598, \"value\": 0.0}, \"2\": {\"effect\": -0.03923522820110702, \"value\": 0.0}, \"3\": {\"effect\": 0.21444626267986353, \"value\": -0.3155716712195094}, \"4\": {\"effect\": 0.03986953748586685, \"value\": 1.0}, \"5\": {\"effect\": -0.0006352069241417421, \"value\": 1.0}, \"6\": {\"effect\": 0.060263339293160176, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10115040120763306, \"value\": 1.0}, \"8\": {\"effect\": -0.04892114586103067, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.26496854594638564, \"value\": 0.0}, \"11\": {\"effect\": -0.892050298394964, \"value\": 1.0}, \"12\": {\"effect\": 0.038776730962063057, \"value\": -0.7496633116815263}, \"13\": {\"effect\": -0.2701048063993235, \"value\": 1.3563280592606042}, \"14\": {\"effect\": 0.013503945897624325, \"value\": 0.0}, \"15\": {\"effect\": -0.6747050663410351, \"value\": 1.0}, \"16\": {\"effect\": 0.1982375876666141, \"value\": 0.8318992447104098}, \"17\": {\"effect\": 0.02282669487210307, \"value\": 0.8}, \"18\": {\"effect\": -0.06927632420298056, \"value\": 0.0}, \"19\": {\"effect\": -0.3158830016395553, \"value\": 0.0}, \"20\": {\"effect\": -0.03989578584309309, \"value\": 0.8}, \"21\": {\"effect\": 0.055469772140781644, \"value\": 0.8318992447104098}, \"22\": {\"effect\": -0.07736472462995696, \"value\": 0.0051960473695625}, \"23\": {\"effect\": -0.16016023152814898, \"value\": -1.1125551095741466}, \"24\": {\"effect\": -0.7135569613160514, \"value\": 1.0}, \"25\": {\"effect\": -0.07413637879720915, \"value\": 1.0}, \"26\": {\"effect\": 0.6104017310378298, \"value\": -0.6740209147048789}, \"27\": {\"effect\": -0.0019139177456913381, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.05462676801747166, \"value\": 0.4649091653346371}, \"29\": {\"effect\": -0.06969432437973956, \"value\": 0.3566612200769836}, \"30\": {\"effect\": 0.110267332870781, \"value\": -0.1456030087276265}, \"31\": {\"effect\": 0.16831330180554036, \"value\": -0.3336672633100191}, \"32\": {\"effect\": 0.009305661901788019, \"value\": -0.3155716712195094}, \"33\": {\"effect\": -0.01851503757764115, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0012547349790494476, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1113282777533578, \"value\": -0.4586300152232994}, \"36\": {\"effect\": 0.0067695824294507064, \"value\": -0.7496633116815263}, \"37\": {\"effect\": 0.011045796282510137, \"value\": 0.0}, \"38\": {\"effect\": 0.0008807735201311188, \"value\": 0.0}, \"39\": {\"effect\": 0.2100493356340686, \"value\": 2.0}}}, {\"outValue\": 3.3259285146417383, \"simIndex\": 19.0, \"features\": {\"0\": {\"effect\": 0.5175834709085029, \"value\": 1.0}, \"1\": {\"effect\": -0.3602253541525896, \"value\": 1.0}, \"2\": {\"effect\": 0.04846655327148462, \"value\": 1.0}, \"3\": {\"effect\": 0.07212629963717827, \"value\": -0.6312926641177055}, \"4\": {\"effect\": 0.029670495924038125, \"value\": 1.0}, \"5\": {\"effect\": 0.0007771444948124061, \"value\": 1.0}, \"6\": {\"effect\": 0.058722092397418435, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.133740805352425, \"value\": 1.0}, \"8\": {\"effect\": -0.09527458720180844, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.23848410497405573, \"value\": 0.0}, \"11\": {\"effect\": 0.2725486520958036, \"value\": 2.0}, \"12\": {\"effect\": -0.12198010834650444, \"value\": 0.2947240854125388}, \"13\": {\"effect\": 0.11569190663186334, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.008988024139704318, \"value\": 0.0}, \"15\": {\"effect\": 0.2796121800114072, \"value\": 0.0}, \"16\": {\"effect\": 0.37934782990567717, \"value\": 0.8523239092128007}, \"17\": {\"effect\": 0.03820946678673532, \"value\": 0.8}, \"18\": {\"effect\": 0.03208479433466705, \"value\": 1.0}, \"19\": {\"effect\": -0.37010530166869116, \"value\": 0.0}, \"20\": {\"effect\": -0.011063220585569647, \"value\": 0.8}, \"21\": {\"effect\": 0.06517942229366183, \"value\": 0.8523239092128007}, \"22\": {\"effect\": -0.4812470611189771, \"value\": 20.498378252464185}, \"23\": {\"effect\": -0.1076215756428624, \"value\": -0.9279533460845792}, \"24\": {\"effect\": 0.06494519574987849, \"value\": 12.0}, \"25\": {\"effect\": 0.03193831165073735, \"value\": 2.0}, \"26\": {\"effect\": 0.3360253609046683, \"value\": -0.617464022451555}, \"27\": {\"effect\": 0.010182823014137206, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.0032426752221155247, \"value\": -0.8190826818501851}, \"29\": {\"effect\": 0.03589967102096344, \"value\": -1.1013434472637695}, \"30\": {\"effect\": 0.2431615714958117, \"value\": -0.5733070177633218}, \"31\": {\"effect\": -0.1914193695651595, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.010082776780865272, \"value\": -0.6312926641177055}, \"33\": {\"effect\": 0.0031149574479796683, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.003068916367523303, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.05866218460454423, \"value\": -0.5675613587251344}, \"36\": {\"effect\": -0.0008041771403809098, \"value\": 0.2947240854125388}, \"37\": {\"effect\": 0.033824180702440414, \"value\": 0.0}, \"38\": {\"effect\": 0.0020787941384752063, \"value\": 0.0}, \"39\": {\"effect\": -0.11144338415127471, \"value\": 3.0}}}, {\"outValue\": 2.6872082587775705, \"simIndex\": 50.0, \"features\": {\"0\": {\"effect\": -0.3408956408629205, \"value\": 0.0}, \"1\": {\"effect\": 0.2972082565662928, \"value\": 0.0}, \"2\": {\"effect\": -0.039018838820842, \"value\": 0.0}, \"3\": {\"effect\": 0.2503066500719367, \"value\": -0.1003073578798304}, \"4\": {\"effect\": 0.04513363566763603, \"value\": 1.0}, \"5\": {\"effect\": 0.0011180203803760546, \"value\": 1.0}, \"6\": {\"effect\": 0.01769944566347717, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.14434286706286353, \"value\": 1.0}, \"8\": {\"effect\": -0.036103789230021006, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.141812258176989, \"value\": 0.0}, \"11\": {\"effect\": 0.5006005333228442, \"value\": 5.0}, \"12\": {\"effect\": 0.026088806569167122, \"value\": -0.1289988014084818}, \"13\": {\"effect\": 0.05197131141784971, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.010959853115858969, \"value\": 0.0}, \"15\": {\"effect\": -0.7486034389583124, \"value\": 1.0}, \"16\": {\"effect\": 0.31867367181391526, \"value\": 0.9204548732601774}, \"17\": {\"effect\": 0.09958795885549294, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.017424688398805267, \"value\": 1.0}, \"19\": {\"effect\": 0.2603912735437566, \"value\": 1.0}, \"20\": {\"effect\": -0.007556265259438064, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.02447335033313671, \"value\": 0.9204548732601774}, \"22\": {\"effect\": -0.07617448756293792, \"value\": 0.0146867125070176}, \"23\": {\"effect\": -0.17393325357114248, \"value\": -1.1507835419731294}, \"24\": {\"effect\": 0.08042695317337668, \"value\": 12.0}, \"25\": {\"effect\": 0.022420600147147345, \"value\": 5.0}, \"26\": {\"effect\": -0.2431798291642247, \"value\": 3.251027407675799}, \"27\": {\"effect\": 0.00024602223760330084, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.004588095944203633, \"value\": 0.597135480026874}, \"29\": {\"effect\": -0.005057639940762642, \"value\": -1.4351292463444678}, \"30\": {\"effect\": 0.14194921507972516, \"value\": -0.487589998950607}, \"31\": {\"effect\": -0.41244758337708226, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.018341701239195506, \"value\": -0.1003073578798304}, \"33\": {\"effect\": -0.0490253321616202, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.00047499816747590827, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.09993637952460958, \"value\": -0.5998969118938438}, \"36\": {\"effect\": 0.01702453363681749, \"value\": -0.1289988014084818}, \"37\": {\"effect\": 0.03086796558121032, \"value\": 0.0}, \"38\": {\"effect\": 0.0011962387036542244, \"value\": 0.0}, \"39\": {\"effect\": 0.06387209289075786, \"value\": 2.0}}}, {\"outValue\": 1.5147689337850698, \"simIndex\": 53.0, \"features\": {\"0\": {\"effect\": 0.5799056054969719, \"value\": 1.0}, \"1\": {\"effect\": -0.24755319939785192, \"value\": 1.0}, \"2\": {\"effect\": -0.0028568954090378534, \"value\": 0.0}, \"3\": {\"effect\": 0.13509571693649497, \"value\": -0.0142016325439587}, \"4\": {\"effect\": 0.030627960493721167, \"value\": 1.0}, \"5\": {\"effect\": 0.0012956093886847845, \"value\": 1.0}, \"6\": {\"effect\": -0.02524476156318757, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11325591481660409, \"value\": 1.0}, \"8\": {\"effect\": -0.03847052714363964, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22681472040277814, \"value\": 0.0}, \"11\": {\"effect\": 0.27033936254958063, \"value\": 2.0}, \"12\": {\"effect\": 0.10176072446112557, \"value\": -0.583555982810375}, \"13\": {\"effect\": -0.5319976327995742, \"value\": 2.187874078283813}, \"14\": {\"effect\": 0.010639587753906648, \"value\": 0.0}, \"15\": {\"effect\": -0.7286339145634158, \"value\": 1.0}, \"16\": {\"effect\": -0.28847738747154966, \"value\": 0.2019664079944557}, \"17\": {\"effect\": 0.09603387549032334, \"value\": 0.7000000000000001}, \"18\": {\"effect\": 0.019979784437663652, \"value\": 1.0}, \"19\": {\"effect\": 0.28296334297580195, \"value\": 1.0}, \"20\": {\"effect\": 0.006610300085091376, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.08604685571545263, \"value\": 0.2019664079944557}, \"22\": {\"effect\": -0.06797638709040306, \"value\": 0.0121383355598789}, \"23\": {\"effect\": -0.050503949971014664, \"value\": -0.7504790566717457}, \"24\": {\"effect\": 0.10950139671779405, \"value\": 11.0}, \"25\": {\"effect\": 0.03508723166057621, \"value\": 2.0}, \"26\": {\"effect\": -0.5577235463512897, \"value\": 0.4458055519109341}, \"27\": {\"effect\": -0.05676683333241697, \"value\": 2.187874078283813}, \"28\": {\"effect\": -0.060353108353240585, \"value\": -1.5458201344803708}, \"29\": {\"effect\": 0.007273528081814245, \"value\": -1.373035455450852}, \"30\": {\"effect\": 0.21622744794629487, \"value\": -0.4577450618366232}, \"31\": {\"effect\": -0.27478853761867655, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.015088534661373467, \"value\": -0.0142016325439587}, \"33\": {\"effect\": -0.04244973828343277, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.002019847149650718, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.16767590180641237, \"value\": 0.7697870997683016}, \"36\": {\"effect\": 0.01808367865725237, \"value\": -0.583555982810375}, \"37\": {\"effect\": 0.01965641489510694, \"value\": 0.0}, \"38\": {\"effect\": 0.0018933837577116493, \"value\": 0.0}, \"39\": {\"effect\": -0.12450257315274806, \"value\": 3.0}}}, {\"outValue\": 3.7046917798368426, \"simIndex\": 69.0, \"features\": {\"0\": {\"effect\": -0.20733168587428946, \"value\": 0.0}, \"1\": {\"effect\": -0.17747613103619728, \"value\": 1.0}, \"2\": {\"effect\": -0.033727973379099926, \"value\": 0.0}, \"3\": {\"effect\": 0.26639512821690314, \"value\": -0.3586245338874453}, \"4\": {\"effect\": 0.034581806110855186, \"value\": 1.0}, \"5\": {\"effect\": -0.0012006859573195792, \"value\": 1.0}, \"6\": {\"effect\": 0.013978777986935776, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2995988423600247, \"value\": 2.0}, \"8\": {\"effect\": -0.06020143673002505, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.1987734810412888, \"value\": 0.0}, \"11\": {\"effect\": 0.2540850236042393, \"value\": 3.0}, \"12\": {\"effect\": 0.15352108419811497, \"value\": -0.7745296782790041}, \"13\": {\"effect\": 0.0740042316627222, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.009486988556612648, \"value\": 0.0}, \"15\": {\"effect\": 0.2571939461408703, \"value\": 0.0}, \"16\": {\"effect\": -0.6078040304011367, \"value\": 0.0575583905238937}, \"17\": {\"effect\": -0.3764406745532692, \"value\": 0.9}, \"18\": {\"effect\": 0.034850532231742844, \"value\": 1.0}, \"19\": {\"effect\": 0.3472039786579497, \"value\": 1.0}, \"20\": {\"effect\": -0.03696248567286684, \"value\": 0.9}, \"21\": {\"effect\": -0.03437896757568878, \"value\": 0.0575583905238937}, \"22\": {\"effect\": -0.08558813474138606, \"value\": 0.011676425130783}, \"23\": {\"effect\": -0.16653921996386695, \"value\": -1.0517937600727676}, \"24\": {\"effect\": 0.032098946116145353, \"value\": 10.0}, \"25\": {\"effect\": 0.0054403843244479515, \"value\": 3.0}, \"26\": {\"effect\": 0.6691205318014566, \"value\": -0.7532005638595324}, \"27\": {\"effect\": -0.004117877741109522, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.027955460783076484, \"value\": -0.8182004300901746}, \"29\": {\"effect\": 0.014491913623008484, \"value\": 0.01169646689064}, \"30\": {\"effect\": 0.13600163741360358, \"value\": -0.0632797988384604}, \"31\": {\"effect\": 0.08978735063796464, \"value\": -0.3771809879404544}, \"32\": {\"effect\": 0.0069290449315070005, \"value\": -0.3586245338874453}, \"33\": {\"effect\": 0.15313815856774216, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0076100847658596765, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.162314892921389, \"value\": 1.050737350366422}, \"36\": {\"effect\": 0.015694518890432288, \"value\": -0.7745296782790041}, \"37\": {\"effect\": -0.30983117458674947, \"value\": 1.0}, \"38\": {\"effect\": 0.0027876842529259848, \"value\": 0.0}, \"39\": {\"effect\": 0.08127953008272845, \"value\": 2.0}}}, {\"outValue\": 2.447598316209552, \"simIndex\": 45.0, \"features\": {\"0\": {\"effect\": -0.36881331324331423, \"value\": 0.0}, \"1\": {\"effect\": -0.30002082421922244, \"value\": 1.0}, \"2\": {\"effect\": 0.02752605667467805, \"value\": 1.0}, \"3\": {\"effect\": -0.007392020150273409, \"value\": -0.6456436183403508}, \"4\": {\"effect\": 0.02509085997990185, \"value\": 1.0}, \"5\": {\"effect\": 0.0007173692699313034, \"value\": 1.0}, \"6\": {\"effect\": 0.029682064451580014, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.08972689587095664, \"value\": 1.0}, \"8\": {\"effect\": -0.053391730073679894, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.19602808125460436, \"value\": 0.0}, \"11\": {\"effect\": 0.17945463808184978, \"value\": 2.0}, \"12\": {\"effect\": -0.3081541931013969, \"value\": 0.6816447496692926}, \"13\": {\"effect\": 0.05358990409702641, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.009376662422897341, \"value\": 0.0}, \"15\": {\"effect\": 0.27639448034211667, \"value\": 0.0}, \"16\": {\"effect\": 0.20183876360604103, \"value\": 0.5523226174179785}, \"17\": {\"effect\": -0.031113815859594558, \"value\": 0.8}, \"18\": {\"effect\": 0.01840350427637974, \"value\": 1.0}, \"19\": {\"effect\": 0.2853959424281048, \"value\": 1.0}, \"20\": {\"effect\": -0.010900999058413303, \"value\": 0.8}, \"21\": {\"effect\": 0.05507349670060143, \"value\": 0.5523226174179785}, \"22\": {\"effect\": 0.2152465281112963, \"value\": 0.0276923340184357}, \"23\": {\"effect\": -0.12513819014861569, \"value\": -0.952606816436472}, \"24\": {\"effect\": 0.03983390426164125, \"value\": 5.0}, \"25\": {\"effect\": 0.04545226708806889, \"value\": 2.0}, \"26\": {\"effect\": -0.23194462874668437, \"value\": 1.1018655020494912}, \"27\": {\"effect\": -0.0072074786993026815, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.044278814221103205, \"value\": -0.912011911014789}, \"29\": {\"effect\": 0.05024880356053784, \"value\": -1.9643719451595736}, \"30\": {\"effect\": -0.3517657030741038, \"value\": -1.8685154231988124}, \"31\": {\"effect\": 0.09034127675605921, \"value\": -0.3706539292458891}, \"32\": {\"effect\": 0.020292753222128847, \"value\": -0.6456436183403508}, \"33\": {\"effect\": 0.14379336127782277, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.003807436940384854, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.0012067867672862966, \"value\": -0.736868733023555}, \"36\": {\"effect\": -0.05497642356261892, \"value\": 0.6816447496692926}, \"37\": {\"effect\": 0.033883658468472126, \"value\": 0.0}, \"38\": {\"effect\": 0.001987284007384416, \"value\": 0.0}, \"39\": {\"effect\": -0.09161255711678576, \"value\": 3.0}}}, {\"outValue\": 0.647177367667314, \"simIndex\": 23.0, \"features\": {\"0\": {\"effect\": 0.5205522245496826, \"value\": 1.0}, \"1\": {\"effect\": -0.3498000197593061, \"value\": 1.0}, \"2\": {\"effect\": -0.021066791773208967, \"value\": 0.0}, \"3\": {\"effect\": -0.07036742699185788, \"value\": 1.076470888377082}, \"4\": {\"effect\": 0.035616804926922374, \"value\": 1.0}, \"5\": {\"effect\": -0.00030037669431046067, \"value\": 1.0}, \"6\": {\"effect\": 0.08987124493344344, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.07699828656409119, \"value\": 1.0}, \"8\": {\"effect\": -0.0661445656842305, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.21169678896761407, \"value\": 0.0}, \"11\": {\"effect\": 0.24452104573540548, \"value\": 2.0}, \"12\": {\"effect\": 0.16545196561659417, \"value\": -0.8550967060548319}, \"13\": {\"effect\": -0.018356557948233345, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.010305260935419013, \"value\": 0.0}, \"15\": {\"effect\": 0.1786247067417114, \"value\": 0.0}, \"16\": {\"effect\": -0.29229696367601654, \"value\": 0.2807515028667204}, \"17\": {\"effect\": 0.07650352433351085, \"value\": 0.6000000000000001}, \"18\": {\"effect\": 0.02737229905395324, \"value\": 1.0}, \"19\": {\"effect\": -0.3383917408634301, \"value\": 0.0}, \"20\": {\"effect\": -0.01007420497167757, \"value\": 0.6000000000000001}, \"21\": {\"effect\": -0.025890848913891866, \"value\": 0.2807515028667204}, \"22\": {\"effect\": -0.06546993601355956, \"value\": 0.0035527499046989}, \"23\": {\"effect\": -0.20752412678145332, \"value\": -1.292209625207026}, \"24\": {\"effect\": -0.017960773287103354, \"value\": 4.0}, \"25\": {\"effect\": -0.009918507459631774, \"value\": 2.0}, \"26\": {\"effect\": -0.11922475711524672, \"value\": 2.413985402326605}, \"27\": {\"effect\": -0.005243518699340502, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.04407311093034668, \"value\": -0.136440740260222}, \"29\": {\"effect\": 0.07756758061113168, \"value\": -0.5830737003029167}, \"30\": {\"effect\": -0.22340073750365955, \"value\": -1.9041863948255853}, \"31\": {\"effect\": -0.4233144168094217, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.0036812697204323982, \"value\": 1.076470888377082}, \"33\": {\"effect\": -0.02193108122893117, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0054424175694466215, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.3883328759570226, \"value\": 5.774991204210308}, \"36\": {\"effect\": 0.017606671169780326, \"value\": -0.8550967060548319}, \"37\": {\"effect\": -0.6941530750552247, \"value\": 1.0}, \"38\": {\"effect\": 0.00112338955923451, \"value\": 0.0}, \"39\": {\"effect\": -0.09734141237840299, \"value\": 3.0}}}, {\"outValue\": 5.943128708894214, \"simIndex\": 86.0, \"features\": {\"0\": {\"effect\": -0.24616731563911545, \"value\": 0.0}, \"1\": {\"effect\": 0.4089476324269118, \"value\": 0.0}, \"2\": {\"effect\": -0.019687875431961394, \"value\": 0.0}, \"3\": {\"effect\": 0.055468101717309766, \"value\": 0.028851230123977}, \"4\": {\"effect\": 0.030142065889355175, \"value\": 1.0}, \"5\": {\"effect\": 0.0010617798635156152, \"value\": 1.0}, \"6\": {\"effect\": -0.0186717439759153, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.3411661351396228, \"value\": 2.0}, \"8\": {\"effect\": 0.18917852793424053, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7979137632079433, \"value\": 1.0}, \"11\": {\"effect\": 0.21743980198842688, \"value\": 2.0}, \"12\": {\"effect\": 0.0355192947760297, \"value\": -0.17574757061174}, \"13\": {\"effect\": 0.04879791768926182, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.005697492793499571, \"value\": 0.0}, \"15\": {\"effect\": 0.25440338068673174, \"value\": 0.0}, \"16\": {\"effect\": 0.24320938050607338, \"value\": 0.3748539984757265}, \"17\": {\"effect\": 0.22344130393451866, \"value\": 0.5}, \"18\": {\"effect\": 0.017921118247362935, \"value\": 1.0}, \"19\": {\"effect\": 0.27156218958757433, \"value\": 1.0}, \"20\": {\"effect\": 0.036955215592342036, \"value\": 0.5}, \"21\": {\"effect\": -0.0020275235024877804, \"value\": 0.3748539984757265}, \"22\": {\"effect\": -0.010552035280036136, \"value\": 0.0169191896061718}, \"23\": {\"effect\": -0.06658065882716113, \"value\": -0.6526972349943726}, \"24\": {\"effect\": 0.04821701335518465, \"value\": 7.0}, \"25\": {\"effect\": 0.04044593152779833, \"value\": 2.0}, \"26\": {\"effect\": 0.01093422874340254, \"value\": -0.5722185086488959}, \"27\": {\"effect\": 0.003029013532631502, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.05912081163718933, \"value\": 1.7067494260371807}, \"29\": {\"effect\": -0.21610134562093744, \"value\": 0.8851042740114154}, \"30\": {\"effect\": 0.06919421048860258, \"value\": 0.6507816238631844}, \"31\": {\"effect\": 0.1003628726523315, \"value\": -0.3880594190980632}, \"32\": {\"effect\": 0.00888192600128343, \"value\": 0.028851230123977}, \"33\": {\"effect\": 0.06403831746632212, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.0017035804085701886, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.02249311976552531, \"value\": -0.675624240333203}, \"36\": {\"effect\": 0.014514546152811388, \"value\": -0.17574757061174}, \"37\": {\"effect\": 0.013756013273748055, \"value\": 0.0}, \"38\": {\"effect\": 0.0032714592537409033, \"value\": 0.0}, \"39\": {\"effect\": -0.027297120886063526, \"value\": 1.0}}}, {\"outValue\": 2.796124611362386, \"simIndex\": 32.0, \"features\": {\"0\": {\"effect\": 0.5901006258736318, \"value\": 1.0}, \"1\": {\"effect\": -0.16877987744712336, \"value\": 1.0}, \"2\": {\"effect\": -0.012708428132297441, \"value\": 0.0}, \"3\": {\"effect\": 0.26819520725932244, \"value\": -1.965931406823716}, \"4\": {\"effect\": -0.19435519358680886, \"value\": 0.0}, \"5\": {\"effect\": -0.0011102257767588684, \"value\": 1.0}, \"6\": {\"effect\": 0.05909511138293162, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09221695976905309, \"value\": 1.0}, \"8\": {\"effect\": 0.13218025559719201, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22779031091144106, \"value\": 0.0}, \"11\": {\"effect\": 0.32967236203887407, \"value\": 2.0}, \"12\": {\"effect\": 0.10660555013851178, \"value\": -0.8361982674407489}, \"13\": {\"effect\": 0.05581634163330036, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010217236334773732, \"value\": 0.0}, \"15\": {\"effect\": 0.3979444538300431, \"value\": 0.0}, \"16\": {\"effect\": -0.16318033062103254, \"value\": 0.2726349603313193}, \"17\": {\"effect\": -0.04301944295181729, \"value\": 0.8}, \"18\": {\"effect\": 0.023537186937270863, \"value\": 1.0}, \"19\": {\"effect\": -0.3293288037822015, \"value\": 0.0}, \"20\": {\"effect\": -0.016416584923043848, \"value\": 0.8}, \"21\": {\"effect\": -0.022995709788103166, \"value\": 0.2726349603313193}, \"22\": {\"effect\": 0.4019176143497725, \"value\": 0.0424752529889124}, \"23\": {\"effect\": -0.0620144138509709, \"value\": -0.8683455899673869}, \"24\": {\"effect\": -0.3391956076993219, \"value\": 2.0}, \"25\": {\"effect\": 0.029746742256033208, \"value\": 2.0}, \"26\": {\"effect\": -0.550671546468956, \"value\": -0.4025478318889242}, \"27\": {\"effect\": 0.02000557237195191, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0793745759621968, \"value\": -1.1202412658637315}, \"29\": {\"effect\": -0.007968088046005111, \"value\": -1.383518351325267}, \"30\": {\"effect\": -0.14381815259955907, \"value\": -1.1480916340465366}, \"31\": {\"effect\": -0.2354345591629638, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.023818718371287035, \"value\": -1.965931406823716}, \"33\": {\"effect\": 0.01772896864203985, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0032352051389933833, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.11863562560238872, \"value\": 0.231507410387458}, \"36\": {\"effect\": 0.017915901120970773, \"value\": -0.8361982674407489}, \"37\": {\"effect\": 0.046633805055582685, \"value\": 0.0}, \"38\": {\"effect\": 0.0020787941384752063, \"value\": 0.0}, \"39\": {\"effect\": -0.08000403704933753, \"value\": 3.0}}}, {\"outValue\": 6.8030627879864785, \"simIndex\": 75.0, \"features\": {\"0\": {\"effect\": 0.49122168308592595, \"value\": 1.0}, \"1\": {\"effect\": 0.4096427177088759, \"value\": 0.0}, \"2\": {\"effect\": -0.02294326285626055, \"value\": 0.0}, \"3\": {\"effect\": 0.10665150064795587, \"value\": -1.3201384668046785}, \"4\": {\"effect\": 0.03405107009448475, \"value\": 1.0}, \"5\": {\"effect\": -0.00044872992357703146, \"value\": 1.0}, \"6\": {\"effect\": 0.10319728432142687, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09665578888430541, \"value\": 1.0}, \"8\": {\"effect\": 0.13194127155933852, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7367058503798892, \"value\": 1.0}, \"11\": {\"effect\": 0.21029015666928724, \"value\": 3.0}, \"12\": {\"effect\": 0.0773469363497654, \"value\": -0.746679347689829}, \"13\": {\"effect\": 0.05317670934579093, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010992472686759926, \"value\": 0.0}, \"15\": {\"effect\": 0.24138443358350467, \"value\": 0.0}, \"16\": {\"effect\": -0.5274611637978248, \"value\": 0.1088545509851735}, \"17\": {\"effect\": 0.22301614130982197, \"value\": 0.5}, \"18\": {\"effect\": -0.12768948934129856, \"value\": 0.0}, \"19\": {\"effect\": 0.19882073515627335, \"value\": 1.0}, \"20\": {\"effect\": 0.014857137076987069, \"value\": 0.5}, \"21\": {\"effect\": -0.03979057145422957, \"value\": 0.1088545509851735}, \"22\": {\"effect\": 0.3711008416326323, \"value\": 0.0353553689809371}, \"23\": {\"effect\": -0.05443584498090815, \"value\": -1.829432435912942}, \"24\": {\"effect\": -0.274982860129638, \"value\": 3.0}, \"25\": {\"effect\": 0.0185651826147741, \"value\": 3.0}, \"26\": {\"effect\": 0.8662538038442733, \"value\": -0.7871346992115267}, \"27\": {\"effect\": 0.001051591551615288, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.013125136583453595, \"value\": 0.6381354078143412}, \"29\": {\"effect\": -0.06803583170626683, \"value\": 0.2920513124968045}, \"30\": {\"effect\": 0.11014511020192656, \"value\": 0.3750470315055309}, \"31\": {\"effect\": 0.22015838341868582, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.03779379234188967, \"value\": -1.3201384668046785}, \"33\": {\"effect\": 0.16978705658163876, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.003780261827177533, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.2429454931168072, \"value\": 0.4565241875266769}, \"36\": {\"effect\": 0.03824804743359826, \"value\": -0.746679347689829}, \"37\": {\"effect\": 0.012747683267838273, \"value\": 0.0}, \"38\": {\"effect\": 0.0010046964246947737, \"value\": 0.0}, \"39\": {\"effect\": -0.04592303157433633, \"value\": 1.0}}}, {\"outValue\": 4.792029315960843, \"simIndex\": 26.0, \"features\": {\"0\": {\"effect\": 0.5278071300942769, \"value\": 1.0}, \"1\": {\"effect\": 0.26381605598115826, \"value\": 0.0}, \"2\": {\"effect\": -0.005765054495778758, \"value\": 1.0}, \"3\": {\"effect\": 0.06518547038862647, \"value\": 0.1006060012372034}, \"4\": {\"effect\": 0.026076955842680542, \"value\": 1.0}, \"5\": {\"effect\": -0.00010814316214317229, \"value\": 1.0}, \"6\": {\"effect\": -0.015564498078811434, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.7953029551835573, \"value\": 6.0}, \"8\": {\"effect\": -0.07255741251022471, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.1978788460730953, \"value\": 0.0}, \"11\": {\"effect\": 0.16257921020569288, \"value\": 3.0}, \"12\": {\"effect\": 0.013391551865390105, \"value\": -0.0752874495579299}, \"13\": {\"effect\": 0.07419872945370608, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.021962620915612352, \"value\": 0.0}, \"15\": {\"effect\": 0.2426813987901087, \"value\": 0.0}, \"16\": {\"effect\": 0.14296605066611956, \"value\": 0.7059286336704218}, \"17\": {\"effect\": -0.4107118769514124, \"value\": 0.9}, \"18\": {\"effect\": 0.041026477079947415, \"value\": 1.0}, \"19\": {\"effect\": -0.2327301451950899, \"value\": 0.0}, \"20\": {\"effect\": -0.06802525666950375, \"value\": 0.9}, \"21\": {\"effect\": -0.0028802777221148277, \"value\": 0.7059286336704218}, \"22\": {\"effect\": 0.15508610718898427, \"value\": 0.0293169624376109}, \"23\": {\"effect\": 0.24827795840593556, \"value\": 11.156380872167569}, \"24\": {\"effect\": 0.04852690040579396, \"value\": 5.0}, \"25\": {\"effect\": 0.02876081017722829, \"value\": 3.0}, \"26\": {\"effect\": -0.5337038044961926, \"value\": 0.1177755768416555}, \"27\": {\"effect\": -0.0015188117855670386, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.08486124400677436, \"value\": -0.7162901022658115}, \"29\": {\"effect\": 0.16721937911454032, \"value\": -1.2018157562573255}, \"30\": {\"effect\": -0.08092964373374593, \"value\": -0.7156273456130745}, \"31\": {\"effect\": 0.22487145918226134, \"value\": 3.506418935325887}, \"32\": {\"effect\": 0.0059851825993752035, \"value\": 0.1006060012372034}, \"33\": {\"effect\": 0.014127126067382404, \"value\": 1.6638537467837806}, \"34\": {\"effect\": 0.0008286786442677944, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.00962023833386707, \"value\": -0.1925333403764098}, \"36\": {\"effect\": 0.04215131546412867, \"value\": -0.0752874495579299}, \"37\": {\"effect\": 0.027475672423007014, \"value\": 0.0}, \"38\": {\"effect\": 0.0013189191313563164, \"value\": 0.0}, \"39\": {\"effect\": 0.06687130740471221, \"value\": 2.0}}}, {\"outValue\": 3.130222359396526, \"simIndex\": 31.0, \"features\": {\"0\": {\"effect\": 0.47529793105506357, \"value\": 1.0}, \"1\": {\"effect\": -0.29760919782089434, \"value\": 1.0}, \"2\": {\"effect\": -0.013952023530048204, \"value\": 0.0}, \"3\": {\"effect\": 0.07728478292846178, \"value\": -0.7891531605668035}, \"4\": {\"effect\": 0.03598073929767137, \"value\": 1.0}, \"5\": {\"effect\": -0.0010761824678748022, \"value\": 1.0}, \"6\": {\"effect\": 0.030301899683108386, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.15725111768047062, \"value\": 1.0}, \"8\": {\"effect\": 0.1636603768841232, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.1978493908131371, \"value\": 0.0}, \"11\": {\"effect\": 0.28545165442606873, \"value\": 2.0}, \"12\": {\"effect\": 0.08410766579557388, \"value\": -0.9396423524862564}, \"13\": {\"effect\": 0.10681626933535243, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.01013272752633888, \"value\": 0.0}, \"15\": {\"effect\": 0.26727262992535206, \"value\": 0.0}, \"16\": {\"effect\": -0.195705947895449, \"value\": 0.2532843528317163}, \"17\": {\"effect\": 0.20051006574185426, \"value\": 0.4}, \"18\": {\"effect\": 0.015076939380551293, \"value\": 1.0}, \"19\": {\"effect\": 0.23300703586819854, \"value\": 1.0}, \"20\": {\"effect\": 0.016216567647844463, \"value\": 0.4}, \"21\": {\"effect\": -0.016677333580659082, \"value\": 0.2532843528317163}, \"22\": {\"effect\": -0.033411825470250095, \"value\": 0.0061921003178911}, \"23\": {\"effect\": -0.19743053464324636, \"value\": -1.1395690241202407}, \"24\": {\"effect\": 0.02051674501997354, \"value\": 10.0}, \"25\": {\"effect\": 0.01968088798455817, \"value\": 2.0}, \"26\": {\"effect\": -0.5577604654164022, \"value\": 0.3553145243056159}, \"27\": {\"effect\": 0.02230420858071205, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.05126065975110163, \"value\": -1.1344333991473083}, \"29\": {\"effect\": 0.030481062249986392, \"value\": -1.2655525188165888}, \"30\": {\"effect\": 0.14190133379645617, \"value\": -0.5276744178586049}, \"31\": {\"effect\": -0.33478766790075404, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.010381489680247644, \"value\": -0.7891531605668035}, \"33\": {\"effect\": -0.04459220878398074, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.003947057926367168, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.07948593978995443, \"value\": -0.3859064619628272}, \"36\": {\"effect\": 0.022978818434082282, \"value\": -0.9396423524862564}, \"37\": {\"effect\": 0.04199265697702853, \"value\": 0.0}, \"38\": {\"effect\": 0.0020524546741013477, \"value\": 0.0}, \"39\": {\"effect\": 0.08029267230364169, \"value\": 2.0}}}, {\"outValue\": 3.836680730658243, \"simIndex\": 80.0, \"features\": {\"0\": {\"effect\": -0.3782422297187165, \"value\": 0.0}, \"1\": {\"effect\": 0.30507760145106955, \"value\": 0.0}, \"2\": {\"effect\": -0.012268974223842846, \"value\": 0.0}, \"3\": {\"effect\": -0.4821498935598158, \"value\": 1.9949319586263796}, \"4\": {\"effect\": 0.0393275695297672, \"value\": 1.0}, \"5\": {\"effect\": 0.00010349944756621494, \"value\": 1.0}, \"6\": {\"effect\": -0.1474120470183852, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.116743351302296, \"value\": 1.0}, \"8\": {\"effect\": 0.29697113231312267, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.7607337591393983, \"value\": 1.0}, \"11\": {\"effect\": -0.8995600702833613, \"value\": 1.0}, \"12\": {\"effect\": 0.06695429285163608, \"value\": -1.064968840137544}, \"13\": {\"effect\": 0.005399003411968274, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.015325215024732188, \"value\": 0.0}, \"15\": {\"effect\": 0.3104544551033695, \"value\": 0.0}, \"16\": {\"effect\": 0.21729991670557028, \"value\": 0.4654272493085154}, \"17\": {\"effect\": 0.013169888331755274, \"value\": 0.8}, \"18\": {\"effect\": 0.006969593519190655, \"value\": 1.0}, \"19\": {\"effect\": -0.3327369481722442, \"value\": 0.0}, \"20\": {\"effect\": -0.017229989293994497, \"value\": 0.8}, \"21\": {\"effect\": 0.015655652890922564, \"value\": 0.4654272493085154}, \"22\": {\"effect\": 0.18406140677649754, \"value\": 0.0288035730020428}, \"23\": {\"effect\": 0.42496537411771135, \"value\": 103.3505499972026}, \"24\": {\"effect\": 0.06818659129519755, \"value\": 5.0}, \"25\": {\"effect\": -0.13173350412217677, \"value\": 1.0}, \"26\": {\"effect\": -0.124111457521132, \"value\": 1.1923565296548095}, \"27\": {\"effect\": 0.005747391980815182, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.05503926068031078, \"value\": -0.0123642355236906}, \"29\": {\"effect\": 0.058216597470826505, \"value\": -0.7674116465923634}, \"30\": {\"effect\": 0.18185938272345561, \"value\": 0.4947555498955592}, \"31\": {\"effect\": 0.6366640234988151, \"value\": 0.5648911503084676}, \"32\": {\"effect\": -0.07632363554721058, \"value\": 1.9949319586263796}, \"33\": {\"effect\": 0.13365513596053824, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.030881480906026923, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.15625197947236577, \"value\": -0.5618131067135683}, \"36\": {\"effect\": 0.0038852505136354643, \"value\": -1.064968840137544}, \"37\": {\"effect\": 0.01619897451731561, \"value\": 0.0}, \"38\": {\"effect\": 0.0027551509893257073, \"value\": 0.0}, \"39\": {\"effect\": 0.1163025110978891, \"value\": 2.0}}}, {\"outValue\": 4.296323293648909, \"simIndex\": 74.0, \"features\": {\"0\": {\"effect\": 0.5662592377406833, \"value\": 1.0}, \"1\": {\"effect\": -0.267761528863194, \"value\": 1.0}, \"2\": {\"effect\": -0.036797936417728896, \"value\": 0.0}, \"3\": {\"effect\": -0.0523294474623731, \"value\": 0.7751008497015311}, \"4\": {\"effect\": 0.027805510115449916, \"value\": 1.0}, \"5\": {\"effect\": 0.0011244391575008054, \"value\": 1.0}, \"6\": {\"effect\": 0.0007021781267810342, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.10434603431560334, \"value\": 1.0}, \"8\": {\"effect\": -0.07622043471106241, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9069055170513696, \"value\": 1.0}, \"11\": {\"effect\": 0.2574149252653844, \"value\": 4.0}, \"12\": {\"effect\": -0.0242263798748898, \"value\": -0.0693195215745352}, \"13\": {\"effect\": 0.042293900181320024, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.010535247049594874, \"value\": 0.0}, \"15\": {\"effect\": -0.489817946325033, \"value\": 1.0}, \"16\": {\"effect\": -0.4594275518225675, \"value\": 0.1075886224745157}, \"17\": {\"effect\": -0.3710005254083646, \"value\": 0.9}, \"18\": {\"effect\": 0.01856198608925049, \"value\": 1.0}, \"19\": {\"effect\": 0.31124636332324496, \"value\": 1.0}, \"20\": {\"effect\": -0.09085800972291741, \"value\": 0.9}, \"21\": {\"effect\": -0.05841087059467375, \"value\": 0.1075886224745157}, \"22\": {\"effect\": -0.04219136535385095, \"value\": 0.0057433033054355}, \"23\": {\"effect\": -0.16312034676577758, \"value\": -0.941312941937396}, \"24\": {\"effect\": -0.06366998494834922, \"value\": 4.0}, \"25\": {\"effect\": 0.043404691926940055, \"value\": 4.0}, \"26\": {\"effect\": 1.0942568659227427, \"value\": -0.8436915914648505}, \"27\": {\"effect\": -0.004934804080311794, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.022433425179092394, \"value\": -1.4908807882717507}, \"29\": {\"effect\": 0.1926787328205834, \"value\": -0.9283012959153636}, \"30\": {\"effect\": 0.16414738403606802, \"value\": -0.5779350877899657}, \"31\": {\"effect\": 0.13736060195986974, \"value\": -0.3793566741719761}, \"32\": {\"effect\": 0.009538488263303519, \"value\": 0.7751008497015311}, \"33\": {\"effect\": -0.03480013831018275, \"value\": 1.4162650230233202}, \"34\": {\"effect\": 0.0070439189656459145, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.012549615075510782, \"value\": -0.6794748654777818}, \"36\": {\"effect\": 0.0030032138845868493, \"value\": -0.0693195215745352}, \"37\": {\"effect\": 0.013211665558106843, \"value\": 0.0}, \"38\": {\"effect\": 0.002529494477530947, \"value\": 0.0}, \"39\": {\"effect\": -0.07533013500461785, \"value\": 3.0}}}, {\"outValue\": 2.3081936111004118, \"simIndex\": 52.0, \"features\": {\"0\": {\"effect\": 0.5867902719345423, \"value\": 1.0}, \"1\": {\"effect\": 0.3592915450039416, \"value\": 0.0}, \"2\": {\"effect\": -0.02709878589356754, \"value\": 0.0}, \"3\": {\"effect\": -0.03300129750032045, \"value\": 0.9903651630412104}, \"4\": {\"effect\": 0.03122726691854163, \"value\": 1.0}, \"5\": {\"effect\": 0.0005399749029379283, \"value\": 1.0}, \"6\": {\"effect\": 0.12378104833248196, \"value\": 0.9724943033069674}, \"7\": {\"effect\": -0.10803066774975106, \"value\": 1.0}, \"8\": {\"effect\": -0.042672594243429535, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.22409224116549992, \"value\": 0.0}, \"11\": {\"effect\": 0.2347051751702858, \"value\": 3.0}, \"12\": {\"effect\": 0.09139845421283156, \"value\": -0.6084223494078528}, \"13\": {\"effect\": 0.06636075958410617, \"value\": 0.5247820402373953}, \"14\": {\"effect\": 0.01097764374345372, \"value\": 0.0}, \"15\": {\"effect\": -0.7374559434016272, \"value\": 1.0}, \"16\": {\"effect\": 0.15062102087281706, \"value\": 0.7138169041128101}, \"17\": {\"effect\": -0.41219288703245993, \"value\": 0.9}, \"18\": {\"effect\": 0.02714317355788539, \"value\": 1.0}, \"19\": {\"effect\": 0.2637616506009506, \"value\": 1.0}, \"20\": {\"effect\": -0.10611118529873825, \"value\": 0.9}, \"21\": {\"effect\": 0.03103804202855617, \"value\": 0.7138169041128101}, \"22\": {\"effect\": -0.3540807869950405, \"value\": 1.6610289078174356}, \"23\": {\"effect\": -0.0023001208249558056, \"value\": -0.5029596538861232}, \"24\": {\"effect\": 0.05652411058681898, \"value\": 6.0}, \"25\": {\"effect\": 0.005599718383947255, \"value\": 3.0}, \"26\": {\"effect\": -0.6133300669275742, \"value\": -0.3799250749875946}, \"27\": {\"effect\": -0.00021634765138413568, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.003732646116835367, \"value\": -0.2457768425498273}, \"29\": {\"effect\": 0.0030102246993878668, \"value\": -0.9864457995552764}, \"30\": {\"effect\": 0.15475619625275833, \"value\": -0.5668619970726538}, \"31\": {\"effect\": -0.3481631950576595, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.005365031333751546, \"value\": 0.9903651630412104}, \"33\": {\"effect\": -0.015552102791500147, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.022422503572348436, \"value\": 0.9724943033069674}, \"35\": {\"effect\": 0.17828016713920558, \"value\": 0.6096497732444289}, \"36\": {\"effect\": 0.019400678568688597, \"value\": -0.6084223494078528}, \"37\": {\"effect\": 0.022167294608687545, \"value\": 0.0}, \"38\": {\"effect\": 0.0010579522016826185, \"value\": 0.0}, \"39\": {\"effect\": -0.021421606277883993, \"value\": 3.0}}}, {\"outValue\": 3.4534655427726744, \"simIndex\": 92.0, \"features\": {\"0\": {\"effect\": -0.30617144673165103, \"value\": 0.0}, \"1\": {\"effect\": -0.2849812830329353, \"value\": 1.0}, \"2\": {\"effect\": -0.00698630419910443, \"value\": 0.0}, \"3\": {\"effect\": -0.4591274762603609, \"value\": 1.6218071488376022}, \"4\": {\"effect\": 0.03855205028443919, \"value\": 1.0}, \"5\": {\"effect\": 0.0021760572687190903, \"value\": 1.0}, \"6\": {\"effect\": -0.03353387910113696, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.26304544084543446, \"value\": 2.0}, \"8\": {\"effect\": 0.17360814168102842, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.822660670611012, \"value\": 1.0}, \"11\": {\"effect\": 0.2429130832323132, \"value\": 3.0}, \"12\": {\"effect\": -0.12492402676416844, \"value\": 2.255188427957684}, \"13\": {\"effect\": 0.022351541725221993, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.013733107042797945, \"value\": 0.0}, \"15\": {\"effect\": 0.3063674665604425, \"value\": 0.0}, \"16\": {\"effect\": -0.4862175900990428, \"value\": 0.1185511143371529}, \"17\": {\"effect\": 0.2705564639664468, \"value\": 0.3}, \"18\": {\"effect\": 0.01246483590578903, \"value\": 1.0}, \"19\": {\"effect\": -0.2350183508410242, \"value\": 0.0}, \"20\": {\"effect\": 0.037136022528170776, \"value\": 0.3}, \"21\": {\"effect\": -0.009625261077189643, \"value\": 0.1185511143371529}, \"22\": {\"effect\": 0.10014639258235628, \"value\": 0.0208286958620848}, \"23\": {\"effect\": 0.3844569879468123, \"value\": 47.96542129224834}, \"24\": {\"effect\": 0.03559011728817579, \"value\": 19.0}, \"25\": {\"effect\": 0.03562879374546918, \"value\": 3.0}, \"26\": {\"effect\": -0.601194756699145, \"value\": -0.2554999120302821}, \"27\": {\"effect\": -0.0014931006343528036, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.02406249350160522, \"value\": -0.2490525918650297}, \"29\": {\"effect\": 0.1539332211879469, \"value\": -0.5435734871918722}, \"30\": {\"effect\": 0.06111280380518913, \"value\": 0.26600614042487}, \"31\": {\"effect\": 0.42814701082553275, \"value\": 0.9913256516867326}, \"32\": {\"effect\": -0.02759901987393223, \"value\": 1.6218071488376022}, \"33\": {\"effect\": 0.045907814281615854, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0011474138801826276, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.07411555712431049, \"value\": -0.378853786070493}, \"36\": {\"effect\": -0.04783472078565722, \"value\": 2.255188427957684}, \"37\": {\"effect\": 0.020350676834441823, \"value\": 0.0}, \"38\": {\"effect\": 0.004000604091576616, \"value\": 0.0}, \"39\": {\"effect\": -0.2591870774440651, \"value\": 3.0}}}, {\"outValue\": 4.708786885464568, \"simIndex\": 95.0, \"features\": {\"0\": {\"effect\": 0.5240748484758447, \"value\": 1.0}, \"1\": {\"effect\": -0.31312649363174777, \"value\": 1.0}, \"2\": {\"effect\": -0.012984739098849932, \"value\": 0.0}, \"3\": {\"effect\": 0.06410666901252728, \"value\": -0.6169417098950603}, \"4\": {\"effect\": 0.036186498325756426, \"value\": 1.0}, \"5\": {\"effect\": 0.0005167222569715716, \"value\": 1.0}, \"6\": {\"effect\": 0.07880433188386754, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.1133837351948558, \"value\": 1.0}, \"8\": {\"effect\": 0.11813473219088386, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.6407439796604386, \"value\": 1.0}, \"11\": {\"effect\": 0.4074738678261841, \"value\": 5.0}, \"12\": {\"effect\": 0.04442701252687351, \"value\": -0.3020687129269269}, \"13\": {\"effect\": 0.11907613750200206, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.01233557968205453, \"value\": 0.0}, \"15\": {\"effect\": 0.289902860940036, \"value\": 0.0}, \"16\": {\"effect\": 0.20047044266090883, \"value\": 0.5237567592219091}, \"17\": {\"effect\": -0.06002540096442463, \"value\": 0.8}, \"18\": {\"effect\": 0.026450422881059112, \"value\": 1.0}, \"19\": {\"effect\": 0.22691097539295807, \"value\": 1.0}, \"20\": {\"effect\": -0.0020359782584053582, \"value\": 0.8}, \"21\": {\"effect\": 0.039986075698468855, \"value\": 0.5237567592219091}, \"22\": {\"effect\": 0.09587107856525168, \"value\": 0.0196961019721107}, \"23\": {\"effect\": -0.26157363395869015, \"value\": -1.4475018465688156}, \"24\": {\"effect\": 0.022576932679378894, \"value\": 9.0}, \"25\": {\"effect\": 0.025070765878149017, \"value\": 5.0}, \"26\": {\"effect\": -0.23016478187003753, \"value\": 1.9615302643000143}, \"27\": {\"effect\": 0.021910650263413836, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.0063863673455248435, \"value\": -0.7239059823643473}, \"29\": {\"effect\": -0.08018612203419112, \"value\": 0.7844967114616924}, \"30\": {\"effect\": 0.10727827904526943, \"value\": 0.2444030520155753}, \"31\": {\"effect\": -0.3468052955343395, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.012334794963034263, \"value\": -0.6169417098950603}, \"33\": {\"effect\": -0.0350101510476351, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.003426474276786353, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.005174111804855502, \"value\": -0.6682359576202958}, \"36\": {\"effect\": 0.011566789595558635, \"value\": -0.3020687129269269}, \"37\": {\"effect\": 0.03085249139465233, \"value\": 0.0}, \"38\": {\"effect\": 0.0013119547825191109, \"value\": 0.0}, \"39\": {\"effect\": 0.08964341133819632, \"value\": 2.0}}}, {\"outValue\": 4.5504160381055385, \"simIndex\": 71.0, \"features\": {\"0\": {\"effect\": -0.28020212491032875, \"value\": 0.0}, \"1\": {\"effect\": -0.378170026182061, \"value\": 1.0}, \"2\": {\"effect\": -0.014557105894325833, \"value\": 0.0}, \"3\": {\"effect\": 0.11990537816916488, \"value\": -0.4734321676686074}, \"4\": {\"effect\": 0.030076677217811904, \"value\": 1.0}, \"5\": {\"effect\": 0.0011014400534991168, \"value\": 1.0}, \"6\": {\"effect\": 0.02672281519332258, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.11053218797358627, \"value\": 1.0}, \"8\": {\"effect\": 0.16070370968606376, \"value\": 1.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": -0.18866446769113454, \"value\": 0.0}, \"11\": {\"effect\": 0.2178372764478416, \"value\": 3.0}, \"12\": {\"effect\": -0.17944392268314924, \"value\": 3.156345553450277}, \"13\": {\"effect\": 0.2115502934030372, \"value\": -1.1383099978090228}, \"14\": {\"effect\": 0.008951747918343718, \"value\": 0.0}, \"15\": {\"effect\": 0.2727306535222178, \"value\": 0.0}, \"16\": {\"effect\": 0.1500114785235339, \"value\": 0.429990206102383}, \"17\": {\"effect\": 0.18667120925196992, \"value\": 0.1}, \"18\": {\"effect\": 0.0024636697138821044, \"value\": 1.0}, \"19\": {\"effect\": 0.23413547684805563, \"value\": 1.0}, \"20\": {\"effect\": 0.05014700175883316, \"value\": 0.1}, \"21\": {\"effect\": 0.009028123066420691, \"value\": 0.429990206102383}, \"22\": {\"effect\": -0.16528318607648318, \"value\": 0.0014794841291957}, \"23\": {\"effect\": 0.371879764928543, \"value\": 0.0894729701827194}, \"24\": {\"effect\": 0.024020983577230096, \"value\": 7.0}, \"25\": {\"effect\": 0.02291448924411824, \"value\": 3.0}, \"26\": {\"effect\": 0.4436088065802281, \"value\": -0.7305778069582027}, \"27\": {\"effect\": 0.025441813351789567, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.01562671713609772, \"value\": 1.9192059847381795}, \"29\": {\"effect\": -0.13822605236368504, \"value\": 2.1089877315981087}, \"30\": {\"effect\": 0.11610123341309021, \"value\": 0.7826706341107407}, \"31\": {\"effect\": 0.05001375572433498, \"value\": -0.3684782430143673}, \"32\": {\"effect\": 0.010077118828709878, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.12735187058782121, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.003998147411538756, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.14397377119193688, \"value\": 0.3677589325600016}, \"36\": {\"effect\": 0.032049833907651766, \"value\": 3.156345553450277}, \"37\": {\"effect\": 0.02611705348987424, \"value\": 0.0}, \"38\": {\"effect\": 0.002009535448467851, \"value\": 0.0}, \"39\": {\"effect\": -0.00315291553316922, \"value\": 1.0}}}, {\"outValue\": 3.8795802341164083, \"simIndex\": 88.0, \"features\": {\"0\": {\"effect\": -0.3006949289766616, \"value\": 0.0}, \"1\": {\"effect\": 0.2868080321619794, \"value\": 0.0}, \"2\": {\"effect\": 0.03505020565100044, \"value\": 1.0}, \"3\": {\"effect\": -0.05624214424864658, \"value\": 0.976014208818565}, \"4\": {\"effect\": 0.021305797874516225, \"value\": 1.0}, \"5\": {\"effect\": 0.0006596570609096295, \"value\": 1.0}, \"6\": {\"effect\": -0.10340898962368038, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.1062239103842774, \"value\": 1.0}, \"8\": {\"effect\": -0.08855652845614095, \"value\": 0.0}, \"9\": {\"effect\": 0.0, \"value\": 0.0}, \"10\": {\"effect\": 0.9490130431539986, \"value\": 1.0}, \"11\": {\"effect\": 0.17923165022303872, \"value\": 3.0}, \"12\": {\"effect\": -0.007360278361930827, \"value\": -1.0410971282039654}, \"13\": {\"effect\": 0.03985435014139005, \"value\": -0.3067639787858137}, \"14\": {\"effect\": 0.009139152293183324, \"value\": 0.0}, \"15\": {\"effect\": 0.24117954707396128, \"value\": 0.0}, \"16\": {\"effect\": 0.3274056443768818, \"value\": 0.8818652294081765}, \"17\": {\"effect\": -0.49943362843021327, \"value\": 0.9}, \"18\": {\"effect\": 0.0065889269657830275, \"value\": 1.0}, \"19\": {\"effect\": -0.32539332687475064, \"value\": 0.0}, \"20\": {\"effect\": -0.0742018909293708, \"value\": 0.9}, \"21\": {\"effect\": 0.04464693231768323, \"value\": 0.8818652294081765}, \"22\": {\"effect\": -0.0925075499325498, \"value\": 0.0162885309260045}, \"23\": {\"effect\": 0.4958047780400253, \"value\": 38.12314775259958}, \"24\": {\"effect\": 0.09899668336027283, \"value\": 14.0}, \"25\": {\"effect\": 0.03337791552386398, \"value\": 3.0}, \"26\": {\"effect\": -0.6246343422039071, \"value\": -0.1536975059742991}, \"27\": {\"effect\": -0.0008105745388527069, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.01660359509810096, \"value\": -1.658707311212152}, \"29\": {\"effect\": 0.08012681063607228, \"value\": -0.6607633823261981}, \"30\": {\"effect\": 0.14272583722944862, \"value\": 0.3218407827586891}, \"31\": {\"effect\": 0.10535030126143978, \"value\": -0.3793566741719761}, \"32\": {\"effect\": -0.011805894550826486, \"value\": 0.976014208818565}, \"33\": {\"effect\": 0.15627912077852377, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.04421956186141318, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.02557584252460313, \"value\": -0.1650233528165174}, \"36\": {\"effect\": 0.04925856738809837, \"value\": -1.0410971282039654}, \"37\": {\"effect\": 0.014705599305332752, \"value\": 0.0}, \"38\": {\"effect\": 0.000839125619946398, \"value\": 0.0}, \"39\": {\"effect\": -0.005727829339248805, \"value\": 1.0}}}], \"plot_cmap\": \"RdBu\", \"ordering_keys\": null, \"ordering_keys_time_format\": null}),\n",
       "    document.getElementById('iDAYXZN6MMII9BVP2IFR5')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceArrayVisualizer at 0x2c11bea8e10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar SHAP force plot para una muestra de datos\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][:100, :], features=X_test.iloc[:100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c03ec9c",
   "metadata": {},
   "source": [
    "Este gráfico proporciona información sobre cómo cada característica contribuye a la diferencia entre la salida del modelo y la media de las predicciones del modelo para las primeras 100 instancias del \"X_test\".\n",
    "\n",
    "- Eje y (\"f(x)\"): Representa la predicción del modelo. Cada punto en el gráfico indica la contribución de una instancia específica a la predicción final del modelo. La posición vertical del punto muestra si la contribución fue positiva o negativa y en qué medida.\n",
    "- Eje x (\"sample order by similarity\"): Los puntos en el eje x están ordenados por similitud. Las instancias que son similares entre sí (en términos de características relevantes para el modelo) están agrupadas cercanas entre sí en el eje x. Esto proporciona una perspectiva sobre cómo las contribuciones de SHAP varían a medida que pasamos de una instancia a otra en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb5694",
   "metadata": {},
   "source": [
    "##### Bloque 3: Visualizar el resumen de los efectos de todas las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93c4d527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar el resumen de los efectos de todas las características\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d017a7",
   "metadata": {},
   "source": [
    "En el gráfico anterior, indicamos el valor SHAP para cada variable, es decir, la contribución de cada variable en nuestro modelo. Esta clasificado en colores (\"class 0\" en azul, representando los casos dondo no hay fraude bancario y \"class 1\" en rojo representando los casos donde sí hay fraude. \n",
    "\n",
    "Interpretación de las características más relevantes:\n",
    "- Current_address_months_count: Con una media del valor SHAP de aproximadamente 0.5, podemos decir que tiene un impacto positivo en la predicción de ambas clases. Un valor alto contribuye a la predicción de fraude y viceversa.\n",
    "- Phone_home_valid: Similar al anterior, con una media SHAP de 0.4. \n",
    "- Device_os_1: La presencia de esta variable tiene un impacto positivo en la predicción de fraude.\n",
    "- Housing_status:  Un housing_status ligeramente inferior a 0.4 en el valor SHAP indica que el tipo de vivienda tiene un impacto positivo en la predicción de fraude.\n",
    "\n",
    "También encontramos un impacto positivo en las siguientes variables \"has_other_cards\"; \"keep_alive_session\"; \"email_is_free\"; \"name_email_similarity\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae3d29",
   "metadata": {},
   "source": [
    "#### Bloque 4: Visualizar SHAP summary plot para todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c16298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar SHAP summary plot para todos los datos\n",
    "shap.summary_plot(shap_values[0], features=X_test, max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec823c4",
   "metadata": {},
   "source": [
    "El \"SHAP summary plot\" que resume los efectos de cada característica en todas las predicciones. \n",
    "Podemos observar lo siguiente:\n",
    "- current_address_months_count:\n",
    "    - Los valores negativos (en azul) sugieren que tener un current_address_months_count menor contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos (en rojo) indican que un current_address_months_count mayor contribuye a una predicción más alta de fraude.\n",
    "- phone_home_valid:\n",
    "    - Los valores negativos sugieren que tener un número de teléfono de hogar no válido contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que tener un número de teléfono de hogar válido contribuye a una predicción más alta de fraude.\n",
    "- device_os_1:\n",
    "    - Los valores negativos sugieren que ciertos sistemas operativos (probablemente representados por 1) contribuyen a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que otros sistemas operativos tienen un impacto positivo en la predicción de fraude.\n",
    "- housing_status:\n",
    "    - Los valores negativos sugieren que ciertos tipos de vivienda contribuyen a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que otros tipos de vivienda tienen un impacto positivo en la predicción de fraude.\n",
    "- has_other_cards:\n",
    "    - Los valores negativos sugieren que tener otras tarjetas de crédito contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que no tener otras tarjetas de crédito tiene un impacto positivo en la predicción de fraude.\n",
    "- keep_alive_session:\n",
    "    - Los valores negativos sugieren que no mantener la sesión activa contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que mantener la sesión activa tiene un impacto positivo en la predicción de fraude.\n",
    "- email_is_free:\n",
    "    - Los valores negativos sugieren que el uso de un correo electrónico gratuito contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que tener un correo electrónico no gratuito tiene un impacto positivo en la predicción de fraude.\n",
    "- name_email_similarity:\n",
    "    - Los valores negativos sugieren que una mayor similitud entre el nombre y el correo electrónico contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que una menor similitud tiene un impacto positivo en la predicción de fraude.\n",
    "- income:\n",
    "    - Los valores negativos sugieren que un ingreso más bajo contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que un ingreso más alto tiene un impacto positivo en la predicción de fraude.\n",
    "- intended_balcon_amount:\n",
    "    - Los valores negativos sugieren que un saldo previsto más bajo contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que un saldo previsto más alto tiene un impacto positivo en la predicción de fraude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ceaa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
